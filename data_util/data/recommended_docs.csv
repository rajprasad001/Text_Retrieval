title,text,url,similarity_score
IBM unveils new commercial Q System One quantum computer,"IBM has released the world's first-ever commercial quantum computer, the Q System One. However, more progress is needed before it will take over from today's super computers.
Update 4 March, 2019:
IBM has announced that it has achieved the best performance from a quantum computer to date – a scientific milestone that includes the lowest error rates it has ever measured in the highly unstable realm of quantum computing.
According to IBM Q’s research team: Performance was measured via Quantum Volume; a full-system metric that accounts for gate and measurement errors as well as device cross talk and connectivity, and circuit software compiler efficiency.
IBM’s recently unveiled IBM Q System One quantum computer, with a fourth-generation 20-qubit processor, has produced a Quantum Volume of 16, roughly double that of the current IBM Q 20-qubit IBM Q Network devices, which have a Quantum Volume of 8.
The results mean performance has doubled every year since 2017. The results will be presented at the 2019 American Physical Society (APS) meeting today (4 March, 2019).
If Quantum Volume follows a pseudo-Moore’s Law for Quantum computing and doubles annually for the next decade or so, then quantum computing will be more practical and reach the desired Quantum Advantage status.
Quantum Advantage refers to the point where quantum applications deliver significant advantages to classical computers.
Original article 20 February, 2019:
IBM wants to make its Q System One quantum computer a commercial device that can be rented for use in research by external laboratories and companies.
The Q System One was unveiled at CES 2019, as “the world’s first integrated universal approximate quantum computing system designed for scientific and commercial use”. IBM have stated they plan to open the first IBM Q Quantum Computation Centre for commercial clients later this year in Poughkeepsie, New York.
But what is quantum computing? We’ve attached a video below that explains all:
IBM hopes that one day their Q systems will be able to tackle problems seen as “too complex and exponential in nature for classical systems to handle”. Some examples of possible future applications for quantum computing include finding the optimal path across global systems for ultra-efficient logistics and optimising fleet operations for deliveries, or finding new ways to model financial data and isolating key global risk factors to make better investments.
According to Arvind Krishna, the senior vice president of Hybrid Could and director of IBM Research: “The IBM Q System One is a major step forward in the commercialisation of quantum computing. This new system is critical in expanding quantum computing beyond the walls of the research lab as we work to develop practical quantum applications for business and science.”
The quantum computer is the next step for IBM Q, which aims to introduce programmable universal quantum computing to the public through the cloud-based IBM Q Experience and the IBM Q Network.
Last year, the Q Network chose eight start-ups as collaborators. One of these eight was Q-CTRL, a quantum technology company from the University of Sydney.
Q-CTRL founder and CEO, Professor Michael J. Biercuck, described Q System One as a major step forward in quantum computing.
“The Q System One demonstrates that a functional (though limited) early-stage quantum computer can be engineered with custom components such that it functions in a setting different than a precision research facility,” he says.
“As we move towards commercial-scale quantum computing, moving these machines outside of research environments such that they operate semi-autonomously with minimal expert intervention is a critical step for the technology. IBM Q System One is a major and important step in that direction”.
The Q System One is a 20-qubit machine and is housed in a nine-foot square borosilicate glass box. The machine was designed in collaborations with Map Project Office, Universal Design Studio, and Goppion. The latter is a manufacturer of display cases that protect pieces of historical importance such as the Mona Lisa in the Louvre and the Crown Jewels at the Tower of London.
Biercuck says Q-CTRL aims to assist with the Q System project by providing solutions within the hardware error sphere.
“The field collectively has a number of challenges to overcome, largely related to hardware error,” he says.
“Fortunately Q-CTRL provides solutions that can able an acceleration of efforts and bring forward the threshold of having the first useful quantum computers. Alongside our solutions, however, teams will be making continued advancements in hardware performance and system size, and teams will be looking to realize so-called Quantum Error Correction. This is a special algorithm run on quantum computing hardware that can help identify and correct for any errors that slip through, and is considered an essential element in large scale quantum computing”.
Applications for quantum computing
Speaking on some of the current customers of IBM Q, Biercuck says the practical applications of quantum computing could include improved materials and drug discover, artificial intelligence, financial services and resource efficiency.
“Quantum computers are believed to be useful for a wide variety of problems in chemistry and materials science because the underlying problems are fundamentally quantum mechanical,” he says.
“These are potentially high value applications – imagine ExxonMobil learning how to improve the efficiency of fuel combustion using a quantum computer. This is something my team at The University of Sydney is working on, but is a great example of the kinds of real-world problems that can potentially be impacted via quantum computing”.
The IBM Q Experience is free and available to the public. It has more than 100,000 users who have been responsible for conducting over 6.7 million experiments, with over 130 third-party research papers published.
Another company interested in the work IBM is doing in Quantum computing is Barclays Bank. In December last year, Barclays joined the IBM Q Network, which gives the bank access to IBM’s quantum processors to run experiments and access to IBM’s technical experts and researchers on quantum computing software.
“We are keen to explore quantum computing by running experiments on actual quantum processors, rather than just using quantum simulators running on a classical processor,” said Lee Braine of the Investment Bank CTO Office.
However, as IBM’s quantum computer currently only supports 20 qubits, its applications are limited. In addition, quantum computing systems can operate for only brief periods before they lose information into the environment via a process known as quantum decoherence.
“For quantum computing to be more practical in banking, the number of qubits will need to increase, and the quantum coherence time will need to increase,” Braine said. “Fortunately, ongoing research in quantum computing hardware has been steadily improving those two aspects.”",https://www.themanufacturer.com/articles/ibm-unveil-new-commercial-q-system-one-quantum-computer/,[[0.8534234]]
Intel Introduces cryogenic control chip 'Horse Ridge' to enable control of multiple quantum bits,"Intel has announced the development of a cryogenic control chip it calls ""Horse Ridge."" The chip is can control multiple qubits in a quantum computer. In its announcement, Intel claims that development of the chip represents a major milestone on the path toward a truly viable quantum computer. Also, as part of its announcement, Intel claims that other players in the quantum computer development world have neglected an important part of any such computer—a way to control many qubits at the same time. Intel reports that they developed the new chip in collaboration with TU Delft and TNO using technology developed in-house. They suggest the new chip will dramatically increase the potential for development of truly useful quantum computers.
Quantum computers are based on qubits, which are notoriously unstable. To make them more stable, quantum computer engineers build in redundancies, thus preventing errors from ruining calculations—that is why so many qubits are needed. The qubits are housed in freezers that keep them very near absolute zero. They are controlled by microwave pulses that originate outside of the freezer. This means that each unit has a host of cables sticking out of it connected to an external controller.
Intel's new chip goes inside the freezer with the qubit, eliminating the cable mess. That is why it is called a cryogenic control chip. The new chip is also a lot smaller than others that are currently in use. Taken together, the two features open the door to a single controller to manipulate more than one qubit—Intel claims that Horse Ridge lays the foundation for future controllers that will be able to control thousands or even millions of qubits, making the realization of quantum computers possible. Miniaturization, they claim, is the key. Notably, miniaturization is one of Intel's strong suits.
Intel has made another change to the design of a quantum computer, as well—they have raised the temperature inside the freezer a couple of degrees—enough to keep the heat from Horse Ridge from causing problems with the qubits. They also acknowledge that development of truly useful quantum computers is still a very long way off, calling current development ""mile one"" of a marathon.
© 2019 Science X Network",https://techxplore.com/news/2019-12-intel-cryogenic-chip-horse-ridge.html,[[0.29703531]]
IBM introduces new Watson solutions and services for nine industries and professions,"IBMtechnology
The US-based computer manufacturing company, IBM, has implemented new Watson solutions and services that will cater to a range of different industries and professions.
The solutions are pre-trained for industries such as agriculture, customer service, human resources, supply chain, manufacturing, building management, automotive, marketing, and advertising.
David Kenny, Senior Vice President of IBM Cognitive Solutions, said: “As data flows continue to increase, people are overwhelmed by the amount of information we have to act on every day, but luckily the information explosion coincides with another key technological advance: artificial intelligence.”
“AI is the tool professionals need to take advantage of the data that's now at our fingertips and tailoring general AI for specific industries and professions is a critical way to enable everyone to reach new potential in their daily jobs.”
See more:
In the past few years, IBM has seen a shift from traditional models to the new cognitive computing era with Gabi Zodik, Director and CTO of Development for Watson IoT Consumer Business, aiming for the company to be more people-centric.
“People no longer want to interact only by touch-screen because, really, the most natural thing is to speak to each other,” Mr Zodik said.
“That’s what’s different about what we’re doing at IBM. We are heading towards what we call cognitive IoT, which is much more people-centric. It's driven by analytics, AI and machine learning, and it offers real-time insight and reasoning capabilities that can't be done in any other way.”
The news follows IBM’s confirmation of a new software service that provides businesses with more transparency when making AI decisions in addition to research from IBM’s Institute for Business Value, which showed that 82% of businesses are thinking about AI deployments.",https://www.manufacturingglobal.com/technology/ibm-introduces-new-watson-solutions-and-services-nine-industries-and-professions,[[0.29148478]]
IBM Investing Billions in 'Internet of Things',"NEW YORK - IBM (IW 500/11) announced Tuesday it was pumping $3 billion into a new division focusing on the growing market for connected devices, or the ""Internet of Things.""
The move adds IBM's resources to the fast-growing market for smart devices such as refrigerators, cars, clothing and other objects which can connect to the Internet or be linked to smartphones.
IBM will make its real-time analytics available to makers of these devices to help improve their functionality.
""These resources will be made available on an open platform to provide manufacturers with the ability to design and produce a new generation of connected devices that are better optimized for the IoT,"" IBM said in a statement.
""Our knowledge of the world grows with every connected sensor and device, but too often we are not acting on it, even when we know we can ensure a better result,"" said Bob Picciano, senior vice president at IBM Analytics.
IBM estimates that 90% of all data generated by devices such as smartphones, tablets, connected vehicles and appliances is never analyzed or acted on and that much of the data begins to lose value if not quickly analyzed.
In one example, IBM said it would introduce a cloud-based service that helps insurance companies extract insight from connected vehicles.
In a separate but related announcement, IBM said it would team up with the Weather Company, which operates the Weather Channel, for improved data collection from weather sensors, aircraft, smartphones, buildings and moving vehicles.
The two companies said this data can improve forecasts and help businesses avoid weather-related losses. It can also help utility companies plan for energy needed for extreme heat or cold.
""This deal combines the capabilities of the world's largest and most advanced commercial weather company with the leader in big data and analytics,"" said David Kenny, chairman and chief executive of The Weather Company.
""This is a watershed moment for businesses that have long been impacted by weather but haven't had the rich data or enhanced decision-making ability to drive positive business outcomes.""
Copyright Agence France-Presse, 2015",https://www.industryweek.com/technology-and-iiot/article/22005994/ibm-investing-billions-in-internet-of-things,[[0.2835233]]
An artificial intelligence algorithm can learn the laws of quantum mechanics,"Artificial intelligence can be used to predict molecular wave functions and the electronic properties of molecules. This innovative AI method developed by a team of researchers at the University of Warwick, the Technical University of Berlin and the University of Luxembourg, could be used to speed-up the design of drug molecules or new materials.
Artificial intelligence and machine learning algorithms are routinely used to predict our purchasing behavior and to recognize our faces or handwriting. In scientific research, Artificial Intelligence is establishing itself as a crucial tool for scientific discovery.
In chemistry, AI has become instrumental in predicting the outcomes of experiments or simulations of quantum systems. To achieve this, AI needs to be able to systematically incorporate the fundamental laws of physics.
An interdisciplinary team of chemists, physicists, and computer scientists led by the University of Warwick, and including the Technical University of Berlin, and the University of Luxembourg have developed a deep machine learning algorithm that can predict the quantum states of molecules, so-called wave functions, which determine all properties of molecules.
The AI achieves this by learning to solve fundamental equations of quantum mechanics, as shown in their paper ""Unifying machine learning and quantum chemistry with a deep neural network for molecular wavefunctions,"" published in Nature Communications.
Solving these equations in the conventional way requires massive high-performance computing resources (months of computing time) which is typically the bottleneck to the computational design of new purpose-built molecules for medical and industrial applications. The newly developed AI algorithm can supply accurate predictions within seconds on a laptop or mobile phone.
Dr. Reinhard Maurer from the Department of Chemistry at the University of Warwick says, ""This has been a joint three year effort, which required computer science know-how to develop an artificial intelligence algorithm flexible enough to capture the shape and behavior of wave functions, but also chemistry and physics know-how to process and represent quantum chemical data in a form that is manageable for the algorithm.""
The team came together during an interdisciplinary three-month fellowship program at IPAM (UCLA) on the subject of machine learning in quantum physics.
Prof Dr. Klaus Robert-Muller from the Institute of Software Engineering and Theoretical Computer Science at the Technical University of Berlin says, ""This interdisciplinary work is an important progress as it shows that, AI methods can efficiently perform the most difficult aspects of quantum molecular simulations. Within the next few years, AI methods will establish themselves as essential part of the discovery process in computational chemistry and molecular physics.""
Professor Dr. Alexandre Tkatchenko from the Department of Physics and Materials Research at the University of Luxembourg says, ""This work enables a new level of compound design where both electronic and structural properties of a molecule can be tuned simultaneously to achieve desired application criteria.""
Provided by University of Warwick",https://techxplore.com/news/2019-11-artificial-intelligence-algorithm-laws-quantum.html,[[0.27642887]]
IBM announces $34bn acquisition of Red Hat,"technologyIBMDigital Transformation
The US-based computer manufacturing company, IBM, has announced that it is set to purchase open-source software firm, Red Hat, for $34bn.
The deal will allow the companies to securely move all business applications to the cloud and accelerate hybrid multi-cloud adoption.
Through the agreement, IBM and Red Hat will be able to help clients create cloud-native business applications faster, drive greater portability and security of data and applications throughout a number of public and private clouds.
Ginni Rometty, IBM Chairman, President and Chief Executive Officer, said: “The acquisition of Red Hat is a game-changer. It changes everything about the cloud market. IBM will become the world's #1 hybrid cloud provider, offering companies the only open cloud solution that will unlock the full value of the cloud for their businesses.”
“Most companies today are only 20% along their cloud journey, renting compute power to cut costs,” she added. “The next 80% is about unlocking real business value and driving growth. This is the next chapter of the cloud. It requires shifting business applications to hybrid cloud, extracting more data and optimizing every part of the business, from supply chains to sales.”
See more:
IBM and Red Hat have enjoyed a partnership for 20 years and the two firms will continue to create and develop Red Hat existing partnerships with major cloud providers such as Microsoft Azure, Google Cloud, Alibaba and Amazon Web Services.
Arvind Krishna, Senior Vice President of IBM Hybrid Cloud, said: “IBM is committed to being an authentic multi-cloud provider, and we will prioritise the use of Red Hat technology across multiple clouds.”
“In doing so, IBM will support open source technology wherever it runs, allowing it to scale significantly within commercial settings around the world.”
The deal is anticipated to be completed during the second half of 2019.",https://www.manufacturingglobal.com/technology/ibm-announces-34bn-acquisition-red-hat,[[0.237467]]
IBM and MIT partner on AI research lab,"IBM and the Mass. Institute of Technology plan to expand their ongoing partnership to create the MIT-IBM Watson AI Lab to perform research on artificial intelligence. IBM is making a 10-year, $240 million investment to establish the Cambridge, Mass. center.
The lab will harness the work of 100 scientists, professors and students to develop AI hardware, software and algorithms; increase AI’s role in industries; and consider economic and ethical considerations associated with AI.
“The field of artificial intelligence has experienced incredible growth and progress over the past decade. Yet today’s AI systems, as remarkable as they are, will require new innovations to tackle increasingly difficult real-world problems to improve our work and lives,” said John Kelly III, IBM senior vice president, Cognitive Solutions and Research. “The extremely broad and deep technical capabilities and talent at MIT and IBM are unmatched, and will lead the field of AI for at least the next decade.”
Another goal of the partnership is to help MIT staff and students create companies to commercialize and sell AI technologies and innovations developed in the lab.
“I am delighted by this new collaboration,” MIT President L. Rafael Reif said. “True breakthroughs are often the result of fresh thinking inspired by new kinds of research teams. The combined MIT and IBM talent dedicated to this new effort will bring formidable power to a field with staggering potential to advance knowledge and help solve important challenges.”
The two parties have worked together for a decade on research in areas related to AI, including machine vision and unsupervised data processing. The combined effort will further both their work in the AI field. The lab is calling for joint research proposals in AI algorithms, physics of AI, application of AI to industries and advancing shared prosperity through AI.",https://www.therobotreport.com/ibm-mit-partner-ai-research-lab/,[[0.22158083]]
"AI-Powered IIoT Solution to Help Manage and Monitor Aging Bridges, Tunnels, Highways and Railways","In the industrial setting, monitoring and optimizing assets to improve performance and extend life is a primary goal of IoT, including assets such as spinning turbines, manufacturing machines or fleet vehicles. But what about assets that don’t have moving parts?
IBM has recently announced a collaboration with Sund & Bælt — which owns and operates some of the largest infrastructure in the world — to assist in IBM’s development of an AI-powered IoT solution designed to help prolong the lifespan of aging bridges, tunnels, highways, and railways. The new industry solution, IBM Maximo for Civil Infrastructure, aims to provide industry and task-specific functionality to help organizations manage, monitor and administer their infrastructure assets. Maximo is IBM's Industrial Enterprise Asset Management solution.
Sund & Bælt Utilizes AI to Maintain Some of the World’s Largest Bridges
Sund & Bælt owns and operates some of the largest infrastructure in the world, such as the Storebælt Link and the 16km Øresund Link between Denmark and Sweden. Currently preparing construction for the world's longest immersed tunnel, the 18 km Femern Belt Fixed Link between Denmark and Germany, Sund & Bælt is working to also make this Europe’s smartest tunnel. The Maximo for Civil Infrastructure solution is designed to help organizations more efficiently operate and maintain this crucial public infrastructure.
“As our infrastructure facilities are aging and traffic increases, it is crucial for us to take in new methods for keeping the structures safe and operational at all times while avoiding rising costs,” said Mikkel Hemmingsen, CEO at Sund & Bælt. “Collaborations with tech-partners such as IBM can help us secure the future operation of our link, and at the same time we are pleased that the know-how from our operation can benefit organizations in the industry around the globe through this new IoT solution.”
Deteriorating infrastructure is a global challenge. Organizations struggle with aging facilities, the difficulty of physical inspections and high cost of continued maintenance. According to the American Road & Transportation Builders Association 2019 Bridge Report, in the U.S., 47,052 bridges are considered “structurally deficient.” Today’s announcement leverages Sund & Bælt’s operational expertise with IBM’s Maximo Enterprise Asset Management and Asset Performance Management (APM) solutions, to help extend the lifespan of infrastructure and reduce overall maintenance costs.
How it Works
Maximo for Civil Infrastructure consolidates various sources of data including maintenance and design details, near real-time IoT data generated from sensors placed on structures, wearables from workers, stationary cameras and drones, and weather data from The Weather Company, to help clients identify and measure the impact of damage such as cracks, rust and corrosion, as well as displacement vibrations and stress. By implementing predictive and prescriptive maintenance strategies using IBM Maximo APM coupled with AI visual recognition tools developed by IBM Research, organizations can endeavor to model, map and monitor each structure. This can help them perform rapid assessment to prioritize maintenance decisions that target critical repairs, and address compliance issues in order to help them meet regulatory obligations.
“Bridges, tunnels, and roads provide access to family, job opportunities, education and more, but much of this infrastructure is aging. With Maximo for Civil Infrastructure, IBM is applying IoT and AI technology to help organizations improve the way these structures are monitored and managed,” said Kareem Yusuf, Ph.D., General Manager, IBM Watson IoT. “Sund & Bælt’s industry expertise coupled with IBM’s 30-year investment in Maximo capabilities for the management of physical assets and IBM’s Maximo Asset Performance Management portfolio, can be leveraged to help organizations with their maintenance and operation of aging infrastructure worldwide.”
For more information on IBM Watson IoT, visit www.ibm.com/iot.",https://www.engineering.com/AdvancedManufacturing/ArticleID/19018/AI-Powered-IIoT-Solution-to-Help-Manage-and-Monitor-Aging-Bridges-Tunnels-Highways-and-Railways.aspx,[[0.2196917]]
IBM Tasks Watson IoT with Quality Assurance on the Factory Floor,"IBM’s Watson is a platform of many talents. It beat Jeopardy! champions Brad Rutter and Ken Jennings in 2011, arguably the biggest victory for Team AI since Deep Blue defeated Gary Kasparov in 1997 and AlphaGo’s triumph over Go expert Lee Seedol last year.
Since its Jeopardy! victory, Watson’s cognitive capabilities have been tapped for a variety of applications, including:
Now, the system is coming to factory floors with the launch of a new IBM Watson Internet of Things (IoT) solution, Cognitive Visual Inspection. The solution uses Watson to review and analyze parts, components and products, identifying defects by matching patterns to images of defects that it has previously encountered, analyzed and classified.
The company’s goal is to provide manufacturers with a ‘cognitive assistant’ to minimize defects and increase product quality. Early testing suggests it can do just that.
In a test involving a production cycle that typically takes eight days with half a day required for visual inspection, Watson was reportedly able to reduce inspection time by 80 percent and manufacturing defects by 7-10 percent.
Using an ultra-high definition (UHD) camera and cognitive capabilities from IBM Watson, the solution captures images of products as they move through production and assembly. Working with human inspectors, it can detect defects in products, including scratches or pinhole-size punctures.
The solution, which continuously learns based on human assessment of the defect classifications in the images, is a harbinger of the promises of Industry 4.0.
“By bringing cognition to the factory floor, IBM is helping usher in the fourth industrial revolution where entirely new levels of efficiency, flexibility and product excellence in manufacturing can become an everyday reality,” said Harriet Green, general manager, IBM Watson IoT, customer engagement and education.
The new solution was announced at Hannover Messe 2017.
For more information, visit the IBM website.",https://www.engineering.com/AdvancedManufacturing/ArticleID/14810/IBM-Tasks-Watson-IoT-with-Quality-Assurance-on-the-Factory-Floor.aspx,[[0.1929395]]
IBM collaborates with Herbert Smith Freehills and Australian government to pilot national blockchain,"IBMtechnology
The computer manufacturing company, IBM, law firm Herbert Smith Freehills and the Australian government’s scientific research department are set to trial a national smart-contract platform which is based on IBM’s blockchain, Cryptovest reports.
The new platform, called Australian National Blockchain (ANB), will allow local companies to work together to use smart legal contracts (SLC).
It is hoped that by utilising the SLCs, businesses will have the ability to exchange data to decide whether a contract is legal and what its current status is.
“Blockchain will be to transactions what the internet was to communication – what starts as a tool for sharing information becomes transformational once adoption is widespread,” said Paul Hutchison, blockchain director at IBM.
See more:
“The ANB could be that inflection point for commercial blockchain, spurring innovation and economic development throughout Australia.”
IBM, Herbert Smith Freehills and Data61, who are the digital innovations branch of Australia’s Commonwealth Scientific and Industrial Research Organisation (CSIRO), are set to test the platform by the end of 2018.
It is expected that if the ANB achieves positive results in the pilot, the partners will explore the possibility of expanding the technology to other countries.
The news follows the deal IBM struck in July, which saw the firm agree a A$1bn deal with the Australian government to produce blockchain and automation technology to government agencies.",https://www.manufacturingglobal.com/technology/ibm-collaborates-herbert-smith-freehills-and-australian-government-pilot-national,[[0.18198177]]
Three ways that edge computing can benefit manufacturing,"technologyIoTData
The UK proudly holds the position of being the eighth largest manufacturing nation in the world. According to The Manufacturers’ Organisation EEF, the UK manufacturing sector currently employs 2.6mn people, accounts for 44% of total exports and provides 13% of business investment. These figures are underpinned by an increasingly automated and technology-driven industry, which has come to rely on technologies such as nanotechnology, cloud computing and IoT to achieve increases in speed, customisation, precision and efficiency.
Factory floor employees who used to print off component lists for product assembly, now barcode scan for the designs and quickly locate parts in the warehouse. ‘Smart’ IoT sensors collect data about everything and feed that data into algorithms that can intelligently improve efficiency. We can see this through examples such as automatically adjusted temperature controls, vents, and the ability to automatically close blinds to minimise solar loss in unoccupied areas. In addition, these data-driven algorithms can simultaneously improve both safety and productivity, for example, by slowing machine speeds when workers approach, and increasing those same speeds, and thus production, when no one is close by. The productivity gains are immense, however, increased dependency on technology means storage, compute and servers all have to be lightning fast and super resilient. Unfortunately, this is not always the case.
In many instances manufacturing businesses only contemplate edge computing as a solution to deliver the necessary speed and resilience once their legacy servers reach end-of-life. However, edge computing and cloud computing go hand-in-hand, and should really be at the forefront of thought for IT leaders.
This article discusses three benefits of edge computing and how it is further improving productivity in the manufacturing sector.
Disaster recovery, speed and resiliency
Factory production facilities need reliable on-premises edge computing resources that can gather and process IoT data and maintain production pace. Latency that arises from network bottlenecks or sluggish broadband connections to cloud-based data centres may provide suboptimal performance or introduce a layer of poor reliability that is unacceptable. If the link to the internet goes away, can the factory afford to stop production? Of course not. Sensors and algorithms must reach in real time, and therefore must exist within the factory itself, to avoid such outages.
That’s not to say that cloud-based computing doesn’t have a place in the manufacturing sector; far from it. Edge computing systems should integrate with cloud environments, to create a hybrid edge-cloud infrastructure. Applications, data, logs, and the like generated at the edge can and should be linked back to the cloud, whether private or public. Likewise, resources that exist primarily in the cloud should be tied back to the edge, to ensure production continues even if the cloud disappears for a time.
See also
Security and compliance
Beyond bandwidth and latency, transferring data between manufacturing factory sites, across states or between countries potentially exposes businesses to cyber-attacks and increases the risk of security breaches. Laws and regulations can vary from country to country, making this an even more complex problem for global manufacturers. A proper edge-cloud hybrid environment can help here.
For manufacturing companies with multiple sites, virtualised edge computing resources also provide the means to strengthen disaster recovery strategies by replicating and mirroring data between each of the different sites over a private, secure network. An environment that spans from edge-to-cloud as one unifed system can greatly simplify the security by having a homogeneous environment at both ends (what provides security at the edge also works in the cloud, and vice versa). In this way, manufacturers can create the kind of strong framework that is essential for full enterprise security, regulatory compliance, and audits.
Lower costs
Edge computing also opens the doors to cost-effective IoT adoption and deployment. Until now, many companies in the sector have resisted full-scale IoT adoption because of the upfront costs associated with network bandwidth, data storage and processing power. This has been further complicated by differing proprietary control and management mechanisms from IoT vendors.
Edge computing offers a cost-effective way to scale up IoT adoption, by providing a standard platform for running applications as virtual machines or containers, and can provide the high-availability those applications demand without being housed in a traditional data centre. Only by streamlining in this way can the full value of the edge be obtained, as the edge is not one location, but likely many small deployments, each being a full IT infrastructure in and of itself.
Edge computing solutions also contribute towards cost savings because they are designed to run autonomously - unlike full data centre implementations, they are small enough to run without dedicated IT staff at each site; the infrastructure is easy to implement and a single IT professional can manage it remotely. This saves on headcount, but also keeps IT-related travel costs between sites to a minimum.
Poised for high growth in the future, edge computing will dramatically improve daily operations for many industries, especially manufacturing. The expectation in the near future is that more factories and plants will adopt edge computing because of its ease of use, tooling and low latency. It’s tempting to think that edge computing might even replace the cloud, particularly as many IT professionals believe that a cloud-only model is not as effective for them. But we don’t see it as edge ‘versus’ the cloud; it’s more like edge ‘and’ the cloud. While edge computing has key advantages for the manufacturing sector, including local computation and faster decision-making, the cloud brings the power of large data set computation, predictive and machine learning and artificial intelligence algorithms. Used in conjunction with the right applications and hardware, edge computing and the cloud can produce a powerful and streamlined IT solution for companies in the manufacturing sector.",https://www.manufacturingglobal.com/technology/three-ways-edge-computing-can-benefit-manufacturing,[[0.1790078]]
"Across the enterprise: Tackle Industry 4.0 with edge, fog and cloud computing","According to a 2019 World Economic Forum and McKinsey study, 70 per cent of manufacturers want to implement Industry 4.0 projects to diversify business models, increase market penetration and improve efficiencies.
However, according to that same study, only 15 per cent of manufacturers have a responsive strategy in place.
So, why the disconnect?
Because most don’t know where to start. The idea of using artificially intelligent and integrated systems to control your plant and warehouse sounds daunting and unapproachable, even scary. Who’s going to architect the solutions? Implement and maintain them? Secure them?
If you’ve read one of my previous articles on the subject, you’ll know that I advocate a deliberate approach that breaks down a seemingly impossible journey into manageable stages. First, build a strong digital twin base that’s adaptable to an unknown future state. Second, implement a proof-of-concept for an easy win. Third, take a bigger leap – one that’s capable of delivering significant value. Fourth, continuously enhance, optimize and improve.
Here’s a real-world example.
Achieving ROI with Industry 4.0
My firm works with a manufacturer that extrudes resins used in a variety of applications – from highly regulated aerospace products to sporting equipment.
At its primary production facility, the company was wasting $350,000 annually because of poor product quality. The losses included direct costs of excessive scrap and indirect costs of suboptimal customer service. The company was routinely re-running work orders, causing it to juggle production schedules and miss its promised delivery dates. Customers weren’t happy.
So, we helped our client architect an environment that would allow it to detect and react to quality issues much more quickly. We designed a program intended to reduce unplanned scrap by 80 per cent and improve its perfect order rate KPI to 90 per cent (a weighted formula that accounts for quality, lead times and fill rates). And, since no company is perfect, we designed a contingency process that provided customer service personnel with systematized warnings prompting them to proactively notify customers as soon as unanticipated issues are detected.
An integrated edge, fog and cloud computing architecture
The technology environment involved implementing and interfacing various information technologies (IT) and operational technologies (OT) that include enterprise resource planning (ERP), a warehouse management system (WMS), manufacturing execution system (MES), laboratory information management system (LIMS), programmable logic controllers (PLCs), production equipment and artificial intelligence (AI).
The solution was designed using a three-tiered architecture that includes edge computing, fog computing and cloud computing. What differentiates these tiers is the proximity of computing to the data source and whether that computing is centralized.
Edge computing pushes computing application, data and services to the logical extremes of a network and away from centralized nodes. A company decides to implement edge computing when it has a need for extremely low latency, where there are high costs to transfer the data to the cloud, where connectivity is an issue, or where compliance demands local processing.
Fog computing is a superset of edge computing that bridges the continuum between cloud and edge computing. There’s still a need for data-dense, low-latency processing, but there’s also a need to compute across multiple edge solutions.
Cloud computing is at the end of the spectrum opposite edge, where broadly sourced data is centrally processed. Companies move computing to the cloud when they want centralized computing horsepower that might otherwise be too expensive or complex to set up and manage themselves.
Implementing the three-tiered architecture
The edge-fog-cloud solution proved to a perfect fit for our resin manufacturing client.
At the edge, the company leveraged its existing investments in modern manufacturing equipment control systems.
The architecture included a new fog computing tier that allowed our client to realize big-time Industry 4.0 benefits by automating, interfacing and systematizing what were previously manual, inefficient and costly processes.
Previously, shortly after the start of every work order, an operator would run a product sample to the lab to determine whether the extruders were properly set up to produce product of acceptable tensile strength, melt point, colour and a host of other quality attributes. If the results were outside of customer specifications, machine operators would manually adjust various process controls to get the product within acceptable tolerances.
We designed a system that closed the loop among the LIMS, MES and the equipment control systems using the Internet of Things (IoT) and application programming interfaces (APIs). When lab quality results are posted, the results are capable of automatically triggering changes to equipment process controls to yield product at appropriate quality standards – updating parameters such as flow rates, temperatures and screw RPMs.
The purpose of this fog computing solution is to use the powerful systems for what they’re good at: quick, powerful data analysis and efficient process execution. The automation is far more efficient and scientific than the previous human operator “thumb-in-the-wind” process of guessing how much to adjust the process controls. ERP, machine learning, and business intelligence (BI) operated in the cloud.
ERP would manage all standard back and front office functions, master scheduling and MRP. Bi-directional interfaces were designed to release warehouse and production orders from ERP to the warehouse, laboratory and manufacturing systems. Those systems would close the loop by reporting actuals back to ERP for inventory, costing, financial accounting, customer service, supply chain and other purposes.
Business intelligence was structured to sit atop a data lake into which data from multiple sources would flow.
This three-tiered solution isn’t our client’s end game. Rather, it’s the foundation for its Industry 4.0 program. The company has positioned itself to take advantage of machine learning innovations that its technology vendors are routinely releasing. These innovations will ultimately drive further improvements to product quality, process efficiency and equipment performance.
Industry 4.0 is more approachable than you think
If you’re among the 15 per cent of manufacturers that doesn’t yet have an Industry 4.0 strategy in place, don’t let the above example scare you. The process isn’t as complex as it may seem. The various technology systems are all commercially available – from control systems, ERP, LIMS and AI.
If anywhere, the challenge lies in properly architecting, acquiring, planning and implementing the solutions. Though even here, the barriers aren’t insurmountable. Increasing numbers of companies are pursuing Industry 4.0 programs, which means that you’ll be able to find people with the right expertise to fill whatever gaps you have.
_____
Jonathan Gross is the managing director at Pemeco Consulting. He helps his clients architect and implement technology environments that integrate ERP with the edge.
This article originally appeared in the November/December 2019 issue of Manufacturing AUTOMATION. Read the digital edition.
Print this page
Your email address will not be published. Required fields are marked *
Comment",https://www.automationmag.com/across-the-enterprise-tackle-industry-4-0-with-edge-fog-and-cloud-computing/,[[0.17847507]]
Technologies Of The Year -- IBM Corp.'s Nanotechnology For Semiconductor Processing,"Polymer molecules that self-assemble will enable smaller, more powerful semiconductor devices for the future.
While the first computers occupied the space of a large room, today, computing capability thousands of times greater can be held in the palm of your hand. One reason for this compacting of power is the ability to form smaller and smaller electronically functional structures on the silicon chips that are integrated circuits. But the current technology that helps accomplish the shrinkage, photo-resist lithography, is approaching its limits, being able to form features down to about 100 nanometers in size (a human hair is about 10,000 nanometers in diameter). Recently, IBM Corp. made a quantum leap in miniaturization capability with a science-fiction-sounding technology called polymer self-assembly. Now able to form functional structures of 20 nanometers and less, polymer self-assembly has moved from a research curiosity to application in real-world challenges of semiconductor manufacture. It promises significantly reduced feature size, higher component density, improved performance and lower voltage requirements for microelectronic devices. In addition, polymer self-assembly can be applied without extraordinary changes in current semiconductor manufacturing practices because the materials and processes used are very similar to those employed today in photo-resist lithography. IBM first demonstrated this exciting technology in a working device in December 2003 at its T.J. Watson Research Center, Yorktown Heights, N.Y. Since then, the company has created a semiconductor memory device that can be shrunken to smaller sizes while maintaining performance, can survive 10 times more read/write cycles and operates at half the voltage of current similar units. In 2004 IBM made a decoupling capacitor that occupies one-fourth the space these devices occupy on today's microprocessors. Another breakthrough occurred in March, when IBM researchers learned to harness polymer self-assembly in a way to create more ordered structures allowing construction of far more complex electronics such as memory arrays and microprocessors. As with photo-resist lithography, self-assembling polymers generate ""masks"" that act like stencils in creating the nooks and crannies on silicon wafers that house the active portions of electronic micro-devices. Because it operates at the molecular level, however, this technology creates much finer stencils. While the term self-assembly implies some molecular consciousness, it is actually a common natural phenomenon, as evidenced by the star-like pattern of snowflakes, geese flying in formation and rain forming a droplet. To create polymers that self assemble, IBM researchers connect two different long-chain polymers together to form a copolymer. The individual polymers, like long pieces of spaghetti, are selected because they won't mix with each other, like oil and water. When the copolymer is applied to a surface, the two different kinds of spaghetti try to minimize the area where they are touching. But like two chained prisoners, they can only have so much privacy. The compromise, depending on polymer ratio, film thickness and environmental conditions, results in films with various ordered patterns. In one, the co-polymer form honeycombs, with one polymer defining the hexagonal pattern structure and the other occupying the center ""holes."" The hole polymer can be selectively removed by chemical means, leaving an incredibly fine honeycomb lattice that can act as a mask in semiconductor manufacturing operations. The mask is applied to a silicon wafer coated with silicon dioxide. The dioxide is etched away under the holes in the mask, leaving spots of silicon wafer exposed and the manufacturing process is begun. Self-assembling polymers also can create lines and spaces, useful in the manufacture of transistors and ""wires"" connecting circuitry. As described, self-assembly creates ordered patterns suitable for the internal workings of individual devices. However, it was not until the March breakthrough that IBM could control the position and orientation of the patterns. Integrated circuits are made up of layers of devices and structures that need to be precisely positioned relative to each other. IBM researchers found that self-assembling polymers line up on edges of ""steps,"" which can be created with lithography, directing the molecules into place to generate structure suitable for microchip fabrication processes.",https://www.industryweek.com/innovation/research-development/article/21953268/technologies-of-the-year-ibm-corps-nanotechnology-for-semiconductor-processing,[[0.17040324]]
The Market for PLM Services: Why Accenture thinks they can rattle IBM,"While they might not be the celebrities of the PLM market, the consulting giants still play a crucia...
While they might not be the celebrities of the PLM market, the consulting giants still play a crucial role in big industrial IT. Companies like IBM, Accenture, HP, TCS, Capgemeni and Deloitte are well acquainted with the problems that arise in PLM and ERP implementations.
These large service providers have historically focused on providing installation services and connecting separate systems, but today the PLM services market is undergoing major changes. ""Our recent research in the Aerospace & Defense (A&D) industry shows that those who have long invested in PLM strategies and enabling solutions are looking for more"", claims analyst Stan Przybylinski of CIMdata.
Stan's view is supported by Accenture's Senior Managing Director Eric Schaeffer, ""Yes, we see a major change in the way we deliver our services. We not only work for a client, we work with them to jointly go to market. A good example is the joint venture that we have set up with GE Aviation, called Taleris. That venture is about real time monitoring of critical equipment. We started with aircraft engines, but we now provide mointoring from tip to tail"".
Taleris, a joint venture between GE Aviation
and Accentures is a good example of new
ways to deliver PLM services
PLM developer Dassault acquiered consulting
giant IBM's PLM division in 2009. DS CEO,
Bernard Charles, celebrated the deal with
a glass of Champagne with among others
former PLM division leader, Al Bunshaft.
According to CIMdata this is a general trend across PLM service providers. ""Their clients want help with more than just installing a solution. They want to make the best use of the advanced features like program/project management, supply chain management, etc. Systems integrators that can provide these advanced skills, especially if they are focused on specific industries, will be better positioned for growth going forward"", says Przybylinski.
Growth is one of Accenture's primary goals. Presently they are number 2 behind IBM when it comes to PLM Service revenues (2013). But IBM better watch out; Accenture is eager to become the number one PLM service provider. Accenture invested heavily during the past twelve months to buy the competence they didn't have. They have brought a number of concrete solutions and visionary initiatives to life, such as APLS (Accenture Product Lifecycle Services) and a variant of the Industry 4.0 concept, Digital Industry 4.0.
Will this be enough to rattle IBM's top postion? I spoke with Eric Schaffer and Stan Przybylinski about the challenges Accenture face, what they are doing to meet them, and how the market for PLM services is evolving.
Many believed that IBM's PLM saga was over in 2009. They were wrong
When IBM sold their PLM division to French developer Dassault Systèmes (DS) in 2009 for $ 600 million, many believed that IBM's PLM saga was over. They were wrong.
At the time, IBM had PLM revenues of well over $1B, selling and implementing only DS solutions like Catia (CAx), Enovia (cPDM), and Delmia (Digital Manufacturing). Now, IBM's Software Group is once again approaching revenues of $1B and this global giant was recognized by CIMdata as one of the ""PLM Mindshare Leaders"" in 2013, joining an exclusive group of PLM players including Dassault Systems, Siemens PLM, PTC, Autodesk, SAP and Oracle.
While IBM earns significant revenues from implementing cPDM solutions (collaborative Product Data Management), they lack a comprehensive solution of their own. That could have been a source of concern when IBM cut ties with their only software provider. However, cutting those ties as they sold the PLM division has paid off well. Today IBM is free to work with solutions from all the major PLM and ERP developers, giving them equal footing with the other service providers like Accenture and HP.
HP is the third-largest PLM systems integrator, trailing only IBM and Accenture.
Stan Przybylinski adds that, ""Accenture and HP (primarily supporting Siemens PLM Software) have major global PLM presences and could be positioned to challenge IBM in both services and PLM supporting infrastructure. This list could also include the major EDA solution providers such as Cadence, Synopsys, and Mentor Graphics, whose software tool contributes greatly to the PLM market"".
This is what the PLM Service Providers top ten list looked like last year:
(Source: CIMdata, the numbers are aproximations based on a bar graph)
1. IBM $ 750 million
2. Accenture $ 550 million
3. HP $ 440 million
4. Siemens PLM $ 360 million
5. T-Systems $ 295 millon
6. PTC and SAP PLM $ 290 millon
8. Tata Consultancy Services $ 260 million
9. Dassault Systemes $ 250 million
10. Atos $ 230 million
Not only a leading ERP implementor – Accenture's three competence areas
Eric Schaeffer set out the three competence foundations for Accenture:
ERP: The company is best known as an ERP consultant, systems integrator and outsourcing specialist. ""I believe that we are one of the leading implementors of large SAP solutions. The ability to connect these solutions to PLM and MES is something that Dassault, Siemens PLM and PTC values ​​us highly for"", says Schaeffer.
During the early 2000s, PLM tools progessively
reached acceptance in the key markets
of Automotive and Aerospace. Accenture helped
many of them implement solutions from
Dassault, Siemens PLM and PTC.
PLM:While the 1990s were the golden decade for ERP providers, the first ten years of the 2000s brought a breakthrough for the PLM suppliers. Now the globally active industrial enterprises, particularly in the automotive and aerospace, are talking about ""innovation"" as the key to success. Thus, the IT-supported product development processes, as promised by PLM, have progressively entered the spotlight.
Accenture's present PLM focus, including acquisitions, is on large multi-nationals who are about to, as Schaeffer asserts, ""utilize the power of large-scale change projects in PLM.""
The Digital Enterprise: There are many touch points to consider when it comes to PLM services, but they all have a common theme: the Digital Enterprise. ""Our clients ask us, 'How do we make sure that we can harness the digital transformation waves that are coming? How will that impact the product development lifecycle processes in our company?""
Schaeffer adds that, ""Machine-to-machine communications, more connected products and more software in the products, combined with more digital services around the products"" also are factors behind what he calls, ""a completely new product realization landscape. And we can see many of our clients - often hard core products companies –moving towards these types of services.""
Volkswagen is one of Accenture's
better-known clients.
Three acquisitions that will boost Accenture's PLM services
Accenture typically works with large implementations for large companies. They have few clients and aim for long lasting relationships. Our key industry segments are Automotive, Industrial Equipment, Aerospace & Defense, but also for us ""newer"" industries like Consumer goods, Food & beverage, and Packaging"", says Schaeffer.
The customer list contains well-known company names like GE, Airbus, Eurocopter, Michelin, Volkswagen, Lufthansa (MRO).
Accenture's assignments often start with a basic implemantation of either Siemens Teamcenter, DS Enovia or Delmia, PTCs Windchill or ThingWorx for example, ""But we also provide things like engineering methods and engineering work that has to be done up-front including change management and a wide variety of services. We've been asked by our clients to do not only the horizonal integration from engineering to after sales but also the vertical integration in the manufacturing space; tier 1, 2, 3, 4, the ERP/MES systems and then connect to the PLM systems.""
Prion Group – now a part of Accentures
PLM division – specialize in Siemens PLM
environments.
Accenture has strengened their abilities during the past year to meet these demands:
They bought German Prion Group, primarily specializing in Siemens PLM Teamcenter environments in Automotive, Aerospace & Defense, Industrial equipment and Consumer goods.
Accenture bought PCO Innovation, a Canadian/French company that specializes in Dassault, Siemens, PTC and Autodesk environments. PCO Innovation had 600 people, 300 in Canada/North America, 300 in Europe (France, UK and Germany).
Earlier this year they purchased a part of the Hungarian embedded systems and industrial automation specialist, Evopro Group.
""Well in line with what IBM can offer""
These acquisitions, when added to Accenture's already existing PLM workforce, puts the company's 4,000 consultants as one of the world's largest service providers. In terms of size, Accenture is now well in line with IBM.
""The effects of the ongoing
development are dramatic"",
says Accenture's Senior General
Manager, Eric Schaeffer.
According to CIMdata, ""these acquisitions, and the announcement of Accenture Product Lifecycle Services (APLS) shows their renewed commitment to PLM. This will position them well against IBM and other large competitors, and expand their global team to provide the local resources industrial companies often prefer.""
""Thats right"", Schaeffer comments,""These purchases enhance our end-to-end offering in PLM services, but it's about more than that. Prion adds things like qualified strategic and process consulting, system implementation, data migration and application control. And with Evopro, we improve our ability to help clients maximize their ROI on investments in industrial control software and automation.""
In the latter case the acquisition provides a deepening of the company's newly launched Digital Industry 4.0 initiative. ""Today we see how three global trends transform our customers' value chains: Digitization is one, mobility a second and ""everything as a service"" (""product-as-a-service"") a third"", says Schaeffer. ""This transformation requires digitally based solutions, intelligent processes and services within the framework of ""Digital Industry 4.0"".
100 million Euros on a PLM implementation with no business results
""Unfortunately, several of our clients, while in the midst of deploying their PLM solution, say: 'we've lost track of the real business value of the X million euros we've invested over the past three years'. Some of them even decide to pause the implementation, take a step back to once again take a look at the roadmap and the associated values and reconsider how to realize on the investment"".
""This happened to one of the industrial companies I worked with. It all started when the CEO came to the department and asked: I have spent 100 million euros on the implementation – what are the business results? They couldn't give him a proper answer.""
Their PLM project was mainly driven by the engineering department and from a technical standpoint, Schaeffer explains, ""Neither the IT department, nor any of the business departments were involved. Furthermore, they went into the implementation without having defined the objective of the vision or what the potential was in the way they currently operated. Finally they misjudged or underestimated the impact on the product development process. Ultimately, the integration didn't work. A specific problem was that they underused the capabilities of the solutions they had, which in turned undermined their business case.""
In the joint venture with GE Aviation
Accenture is a part of Taleris. ""Via this
company we can monitor an airplane from
tip to tail"", says Eric Schaeffer
IDC, Gartner and CIMdata talk about a major shift in the PLM Service Provider market.
""It's not only a coming phenomena, it has already happened. There are several examples of major changes in the way we deliver"", says Eric Schaeffer. He asserts that the trend is about sharing risks and revenues in projects, ""In some cases we are even embedded in our clients businessmodel where we are paid per transaction. We have become part of our clients value chain.""
He points out the joint venture with GE Aviation, Taleris, as a good example: ""It's about real time monitoring of critical equipment. We started with aircraft engines, but we are now able to provide tip to tail monitoring. With the underlying analytics we can perform predictive maintenance, rerouting, delaying or accelerating a plane to meet the time requirements of other events in a transportation chain.""
Can Accenture challenge IBM's position as the best revenue performer?
Over the last few years things like systems integration, digitalization, mobility and concepts like product-as-a-service have created an almost countless number of new business opportunities. Unfortunately, nothing in this ""brave new on-line world"" is easy to carry through. Manufacturers will continue to call on service providers to play an important role in the creation of new products and distribution processes.
Many clients of consultants like IBM, Accenture and HP have only recently begun to devote energy to their evolving global customer markets and the way products are realized and shipped or used. In a survey 12 months ago, Accenture learned that, according to the top decision makers, future growth would come from markets that the participants not yet were in.
The purchases of Prion Group
and PCO Innovation ""will
position Accenture well
against IBM and other large
competitors"", claims
CIMdata's Stan Przybylinski.
Undoubtedly concepts like PLM will play a key role in the product realization processes that will be required to drive into these new markets. Equally certain is that the C-level management will take a growing part in decisions regarding IT systems and services that can make the product realization processes bring new products to market faster.
PLM investments are increasingly becoming C-level questions. The price tag alone puts these investments at the center of executive attention. Top level consultants like IBM and Accenture are expert in the art of communicating with C-level executives.
2013 was not a good year for revenue growth for PLM service providers, ""The major systems integrators were highly visible but few enjoyed substantial growth during the year. Companies spent liberally on software, but the services spend was delayed"", says CIMdatas Stan Przybylinski.
If the global economy continues to improve in 2014 it could accelerate the services investment and boost the growth of PLM service providers. With its recent acquisitions (Prion, PCO Innovation, Evopro) and solutions initiatives, Accenture is well positioned to gain a growing share of these growing revenues.
IBM better watch out.",https://www.engineering.com/PLMERP/ArticleID/8263/The-Market-for-PLM-Services-Why-Accenture-thinks-they-can-rattle-IBM.aspx,[[0.16392487]]
"IBM, UCSD project to research AI solutions for healthy living","IBM and University of California San Diego have launched a joint research project to combine technology, artificial intelligence and life science knowledge to improve quality of life for aging populations.
The partnership is part of IBM’s Cognitive Horizons Network — a group of universities working with the company to implement AI — and aims to provide solutions for UCSD’s new Artificial Intelligence for Healthy Living Center.
“This is a very prestigious relationship for UC San Diego, the first university on the West Coast to collaborate with the IBM Cognitive Horizons Network,” UCSD Chancellor Pradeep K. Khosla said in a statement. “Our campus, one of the top 15 research universities in the world, is home to changemakers whose innovation will help advance cognitive wellness to make a difference in our lives.”
The project’s goal involves creating a cognitive framework for living environments that promote independent living and a high quality of life for older adults, including the development of machine learning algorithms that enable sensing, understanding, modeling, personalizing and informing. The framework could include the deployment of robotic systems as well.
“We’re committed to collaborating with the best minds in academia to inspire the next generation of scientists by providing access to leading-edge AI tools and expertise to solve real problems that impact human lives,” IBM senior vice president of Cognitive Solutions and IBM Research Dr. John Kelly III said in the release. “This new collaboration with UC San Diego is the latest example of how we’re executing on this AI vision — and we are thrilled to bring our global AI research resources to Southern California to engage the wealth of local talent.”
Today the world’s population of people over 65 is 617 million. That number is expected to jump to 1.6 billion by 2050 while the population of people over 80 is supposed to triple.
“People might be living longer, but that doesn’t mean they are living better,” Khosla wrote in a blog post. “As people age, cognitive health — the ability to think clearly — can decline. Cognitive decline can determine whether older people live independently, which can, in turn, affect their health and happiness …This is why we must better leverage technology and data to provide opportunities for seniors to continue living meaningful, productive lives.”",https://www.therobotreport.com/ibm-ucsd-project-research-ai-solutions-healthy-living/,[[0.15913449]]
5 Examples of How the Industrial Internet of Things is Changing Manufacturing,"The world is becoming more connected every day, as the Internet of Things (IoT) extends beyond the home and office to manufacturing and the factory floor.
As an example of how industrial IoT (IIoT) connectivity can improve and drive manufacturing, consider Schaeffler, an automotive and industrial supplier. In a partnership with IBM’s Watson IoT platform, the company hopes to extend its business model to include cognitive solutions to its products.
Peter Gutzmer, deputy CEO and CTO at Schaeffler sees a smart, connected future as the essence of Industry 4.0.
""We are entering an age where parts can monitor and evaluate their own performance and even order their own replacement when necessary,” said Gutzmer. “Schaeffler is a world leader in product development and manufacturing, IBM in hybrid cloud and cognitive computing; through this partnership we are ushering the new industrial era.""
More specifically, Schaeffler’s first phase of integration with IBM’s IIoT solutions involve five areas of focus.
1) Optimizing Maintenance in Wind Energy
Schaeffler and IBM will use wind turbines to explore how machine learning can reveal additional insights about the performance of equipment in different operating conditions. Sensors in the equipment and in the bearings themselves will report on the condition of components in real-time. Using wind forecasts from IBM, turbine operators will be able to plan ahead and replace parts during less windy periods.
2) Digitized Monitoring and Optimization of Trains
Using cognitive insights from the cloud, Schaeffler is aiming to enhance its predictive maintenance systems for railways, helping to improve efficiency and safety. Smart bearings will be able to measure their own vibration, temperature, torque and speed triggering alerts and informing railway operators about possible safety issues.
3) Connected Vehicles
The IIoT can also allow Schaeffler to extend the functionality and lifespan of components for the automotive industry. Real time analytics and cognitive systems can turn data from components and systems into valuable insights that can be used by manufacturers to increase the reliability of cars and offer new value-added services to customers. In other words, IIoT can extend quality assurance beyond the factory doors.
4) Industry 4.0 for Machine Tools
In an effort to improve production efficiency, Schaeffler's Industry 4.0 strategy for machine tools includes real time analysis of data and context-driven maintenance, networking and optimization of machines within a production line.
5) Connected Equipment Operations Centers
The connected Industry 4.0 will allow for the monitoring of thousands of machines and pieces of equipment on and off site. Data can be transmitted to an operation center and processed in the cloud. Algorithms and cognitive approaches can analyze that data to make predictions about machine performance and create opportunities for optimization. Irregularities and potential faults can be automatically identified and corresponding actions rapidly initiated.
""This is an era of unprecedented industrial transformation defined by factories, machines and parts capable of self-assessing, triggering actions and exchanging information with each other, and with the people who manufacture and maintain them,"" said Harriet Green, general manager of IBM Watson IoT. ""Schaeffler is leading the way and literally redefining approaches for designing, producing and maintaining machines–making them safer and more reliable.""
Read more about IIoT and Industry 4.0 here and see how this “new industrial revolution” will impact manufacturing in the future.",https://www.engineering.com/AdvancedManufacturing/ArticleID/13321/5-Examples-of-How-the-Industrial-Internet-of-Things-is-Changing-Manufacturing.aspx,[[0.15888894]]
The Next 7-10 Years of IBM’s Watson,"Jeopardy! Was Just The Beginning
IBM’s achievement with their Watson system and software was more than good television:
It’s a major language processing realization. Computing systems will no longer be limited to responding to simple commands.
The data management aspect lends itself to specialization, ie, medical sub-sets, legal data sets, call/support centers databases, etc. John Markoff, in a recent NY Times article on the subject, said “any job that now involves answering questions and conducting commercial transactions by telephone will soon be at risk. It is only necessary to consider how quickly A.T.M.’s displaced human bank tellers to have an idea of what could happen.”
The language processing is amazing, illuminating, and lets one dream of a future where the promises of human-robot (or for that matter, human-device) interaction and instantaneous translation is really going to happen soon.
A staggering amount of horsepower was harnessed to work harmoniously using massively parallel technology on 2,700 processors spread over 90 servers to enable the Jeopardy! win. Historically, this will advance to smaller devices within a few years. Ray Kurzweil, quoted in The Economist, notes that it was only five years after the massive and hugely expensive Deep Blue beat Mr Kasparov in 1997 that Deep Fritz was able to achieve the same level of performance by combining the power of just eight personal computers. In part, that was because of the inexorable effects of Moore’s Law halving the price/performance of computing every 18 months. It was also due to the vast improvements in pattern-recognition software used to make the crucial tree-pruning decisions that determine successful moves and countermoves in chess. Now that the price/performance of computers has accelerated to a halving every 12 months. Mr Kurzweil expects a single server to do the job of Watson’s 90 servers within seven years—and by a PC within a decade. If cloud computing fulfills its promise, then bursts of Watson-like performance could be available to the public at nominal cost even sooner.
And most importantly, right after the Jeopardy! win, IBM announced partnerships with a few hospital groups to provide diagnostic physician assistance using Watson’s DeepQA software and data management methods. And their website displays other areas where Watson might be particularly helpful. IBM is bringing Watson to the marketplace.
It’s important to keep in mind that inside a computer there is no connection from words to human experience or cognition. To Watson, words are just tokens. In parsing a question such as those on Jeopardy!, a computer has to decide what’s the verb, the subject, the object, the preposition and the object of the preposition. It must remove uncertainty from words with multiple meanings, by taking into account any and all contexts it can recognise. When people talk among themselves, they bring so much contextual awareness that answers become obvious. The computer must use logic to “disambiguate” incoming tokens into choices which can be measured (scored) against alternative choices. And it must do all that within seconds.
What about robots and robotics?
The AI system managing a robot gathers facts through sensors or human input, compares this to stored data, and decides what the information signifies. The system then runs through various possible actions and predicts which action will be most successful.
Some robots also have a limited ability to learn. Learning robots recognize if a certain action achieved a desired result and store that information for the next time it encounters the same situation. Naturally, they can’t absorb information like a human but in Japan, roboticists have taught a robot to dance by demonstrating the moves themselves.
It’s important to remember that IBM isn’t the only AI game in town. There are many companies and research facilities developing and providing AI software, the most visible of which is Google.
From Wired’s Danger Room: Back in 1954, IBM announced that its 701 computer crunched a bit of Russian text into its English equivalent. A Georgetown professor who worked on the project predicted the computerized translation of entire books “five, perhaps three years hence.”
Thus was born a scientific (and sci-fi) drive that’s lasted 57 years, from Star Trek to Babel Fish to Google Translate: instantaneous speech translation. But even though no one’s mastered that yet, the Pentagon’s out-there research branch is asking for even more with its Boundless Operational Language Translation, or BOLT. As outlined in Darpa’s fiscal 2012 budget request. For the low, low starting cost of $15 million, Congress can “enable communication regardless of medium (voice or text), and genre (conversation, chat, or messaging).”
Not only will BOLT be a universal translator — the creation of which would be a revolutionary human development — but it will “also enable sophisticated search of stored language information and analysis of the information by increasing the capability of machines for deep language comprehension. In other words, a 701 translator that works.
So What’s The Holdup?
There are many reasons for the delay in robotic training and interaction with humans – some of which can been seen in the mammoth resources it took IBM to achieve their Watson Jeopardy! victory. You cannot place those resources into a robot nor can you rely on a computer controlling a robot (or series of robots) via a wireless communication channel as they go about their various tasks.
Matthias Scheutz, an Associate Professor of Cognitive Science, Computer Science and Informatics and Director of the Human-Robot Interaction Lab at Tufts University, adds research funding to the equation saying:
The fields of robotics and human-robot interaction are growing, with the highest expected growth rates not in industrial, but service robots. Several countries (Japan, South Korea, the EU, etc.) around the world are heavily investing in service and social robotics. In the US, there are very few funding programs specifically targeted at artificial cognitive systems that would enable complex autonomous service robots. My hope is that this will be changing soon given enormous market potential of this area and the heavy investments other countries are making. To keep the US competitive and to enable, not Watson-like, but more modest, more natural interactions between humans and autonomous robots in natural language, we will need interdisciplinary funding programs that are aimed at developing the right kinds of integrated control architectures for these systems, which we are currently still lacking.
Scheutz goes on to say:
Computing power is obviously a critical component for a lot of AI technology (e.g., algorithms that are data-based and need to be trained on large data sets, or algorithms that have to explore large search spaces in a short amount of time). Equally important is the architecture of an intelligent system, the way in which different components operate and interact. And here is where we have made much less progress compared to the hardware side. Consequently, although the performance of Watson is very impressive and clearly a break-through, from an engineering perspective, it does not yet address the problem of human-like natural language processing as we will need it for robots. And while there will likely be applications in the context of recommender systems in the near future, it is not clear to me how the technology used on Watson can be put on a robot and make it have natural task-based dialogues with humans.
The EU, Japan and Korea have roadmaps which lay out the science that needs to be tackled before effective products can be produced. And they have national direction and public-private funding to make their plans happen. America does not yet have such a plan nor any national direction regarding robotics. And this is a critical holdup.
President Obama, in his State of the Union Speech, specifically excluded robotics when he discussed the need for strategic investment in key areas of innovation. How the President could overlook that not a single sector is devoid of the applications of robotics is one question. Another is to ask whether he is aware that 12 of the 13 major robotic manufacturers selling industrial and manufacturing robots in the US are off-shore companies.",https://www.therobotreport.com/the-next-7-10-years-of-ibms-watson/,[[0.15391765]]
IBM and Intel describe an experiential future,"CEOs from IBM and Intel, in keynote presentations at CES in Las Vegas last week, described and gave examples of disruptive changes in how consumers and businesses transact and interact with their purchases.
Intel’s Brian Krzanich described the use of embedded chips and cloud services to enable experience-based transactions, many of which lead to sales but others also lead to enhancing the user’s experience. Krzanich provided many examples but four stood out and made his case:
In a new Guinness World Record for the most unmanned aerial vehicles airborne simultaneously,Â 100 flying drones flew and shone their colored lights in sync with an orchestra playing Beethoven’s Fifth Symphony. Because it was so colorful, and timed to the music, Krzanich characterized the event as a potentially safer and reusable replacement for fireworks shows.
Using augmented reality, the ModiFace mirror enables women to try out different looks and make-up choices (blush, eye shadow, lip stick color, foundation, glosses, etc.)Â and then buy the resulting colors and product selections. Trying on different color combinations is often an embarrassing process done in public in department stores. An augmented reality productÂ such as this one, disrupts the process and provides a better experience.
Krzanich also demonstrated a Yuneec Typhoon H with an onboard RealSense 3D camera and chip, enabling aÂ follow-me collision-avoidingÂ drone available later this year as aÂ consumer product.
A pair of Oakley sunglasses provided the sensors and communication to track, interact, coach and provide data extrapolated from sensors tracking the wearer’s progress, comparing that progress to set goals, and providing spoken coaching and responsive reports along the way – the result being an experience instead of a pair of sunglasses.
As an aside, Intel recently announced its acquisition of Ascending Technologies, the German developer of the collision avoidant autopilot system used in the 100 drones video above. Last yearÂ Intel also made a big investment in Yuneec, whose drones now include onboard Intel RealSense cameras and chips, and Airware, a competing autopilot developer. And this week Intel invested in robotics startup Savioke, maker of the Relay robot which autonomously navigates around hotels delivering toothpaste, towels, Starbucks coffee and other items.
IBM’s CEO, Ginny Rometty, told a packed CES audience that Watson and IBM were changing the nature of data processing from transactional to cognitive. Last year RobertÂ High, CTO of IBM’s Watson Group, described the emerging era of embodied cognitive computing leading to providing cognition as a service, as a 3rd hand such as a lab technician might need, or as a concierge as Jibo and Echo (and human concierges) offer, as an office assistant might provide, and in field settings like search and rescue. The cognition process involves machines interacting with humans in writing, verbally, with tactileÂ and visual cues, and with gestures.Â Cognitive algorithms and cloud computing are the keys to Watson’s feats and they also happen to be where Rometty has pushed IBM since her tenure began.
Rometty described Watson’s progress thus far and demonstrated on stage many areas where applying Watson to an application is changingÂ the nature of the experience. It’s not enough to just be able to hear what a user says. Watson must be able to understand what they want, be able to make that happen, and then interact back with the user in as conversational a tone as possible.Â SoftBank’sÂ Pepper robot is an example of how this works.Â In this excerpt from Rometty’s presentation, she and SoftBank Robotics’ Kenichi Yoshida announced that IBM will provide global distribution and support for SoftBank’s Watson-powered Pepper robot as they scale up to begin selling into China and the U.S. Pepper has already sold 7,000 units in Japan and is in 300 bank branches, and 100 stores.
Bottom line:
These two CES keynote presentations illustrateÂ howÂ artificial intelligence and data synthesis will provideÂ the backbone to enable meaningful and productive interaction between humans and machines –Â not only on screens, but with gestures, visual cues and spoken understandable communication to and from smart devices and robots of all types. And it’s not just aÂ near-term future they foretell — they give examples of where itÂ is already happening.",https://www.therobotreport.com/ibm-and-intel-describe-an-experiential-future/,[[0.15002277]]
"CES: Noise, hype, hustle and business as usual","Massive, exhausting, noisy, crowded, colorful, fun
The key words one heard from passers-by and sales people were: smart; connected; robotic; autonomous; self-driving;Â drones; IoT (Internet of Things);Â healthcare;Â fitness;Â apps;Â sensors;Â cameras;Â China;Â Taiwan;Â AI;Â headsets;Â virtual reality;Â augmented reality; andÂ Mercedes Benz’s concept car.
Exhibitors attempted to show products that corresponded to those buzzwords and visitors were “bombarded with early versions of tomorrow’s tech that are bound to feel janky and incomplete,” said Farhad Manjoo in the NY Times.
Smart shower heads that reduce water flow when you step away to lather up; smart fridge cameras that give a view of what’s inside to your smartphone while you’re at the store or to a flat panel screen on the outside door of the fridge; big TVs (some up to 170″ (432cm)) with curved screens; virtual reality headsets; paneled lighting arrays; follow-me dronesÂ and carriers of all types; ski airbags (similar to boating life vests); Parrot’s new single wing drone (similar to senseFly’s eBee); the new Star Wars BB-8 toy from Sphero;Â wristband follow-me wearables; every type of workout wearable and sensor; avatars with customized faces (can be your face); pet games and food dispensers; makeup mirrors that overlay on your face different makeup combinations; bi-color LED lights for indoor ag farms; huge walls of TV screens showing every type of spectacular scene; face-tracking cameras; and connected cars and their driving, navigation and entertainment systems.
The show was organized by areas with sections for 3D Printing, Apps,Â Augmented Reality,Â Cyber & Personal Security,Â eCommerce,Â Education & Technology,Â Family & Technology,Â Fitness & Technology,Â Gaming & Virtual Reality, HDMI,Â Health & Wellness,Â iProducts,Â Kids & Technology,Â Robotics,Â Smart Home,Â Smart Watches,Â Sports Tech,Â Unmanned Systems, Vehicle Intelligence, andÂ Wearables –Â essentiallyÂ the whole gamut of electronic consumer products.Â Fitness, sports tech, vehicles and their systems, all had particularly mammoth areas.
The biggest exhibit spaces included two Chinese companies: Hisense and TCL. OtherÂ super-large exhibition spaces were for Samsung (the absolute biggest),Â LG,Â Nikon, Canon, Panasonic,Â Sony, Mercedes, Intel and Qualcomm.
Hisense isÂ a Chinese multinational white goods and electronics manufacturer headquartered in Qingdao, Shandong. It is a state-owned enterprise with publicly traded subsidiaries.
TCL Corporation is a Chinese multinational electronics company headquartered in Huizhou, Guangdong.
The most notable companies NOT exhibiting were Apple, Facebook, Amazon, Google and IBM although most had hospitality suites and/or meeting rooms for their ad teams to meet with clients who produced consumer electronic products and IBM’s CEO was one of the keynote presenters (see below).
Labyrinthine warrens of meeting rooms
In a NY Times article, the serious side of the CES spectacle was highlighted:
“A lot of business gets done at CES, often away from the show floor, in the labyrinthine warrens of meeting rooms across the Las Vegas Strip.”
Very true. Even for companies that didn’t exhibit like Twitter andÂ IBM, they all had quiet spaces to demonstrate products, talk pricing and agreements, and generally have time and space for one-on-ones with customers and prospects. Although IBM is no longer in the consumer products business theyÂ had a large meeting room set aside for their customers who were. Twitter created a miniature city in two large ballrooms at one of the hotels. It had shops, restaurants, a bar, theater and an outdoor park. EachÂ was a meeting area for Twitter’s ad sales team to meet and greet customers.
Hourly press events hyped,Â but some made news
There were more than 25 press conferences held at the show. Many were announcing additional products to an existing product line. A few described new products. And some, like Toyota and Intel, provided pertinent information about profound changes about to happen.
Toyota held a press conference led by Gill Pratt of DARPA fame, who now is the CEO of Toyota Research Institute (TRI) wherein he announced their new research staff. One member of that staff was James Kuffner, the previous head of Google’s robotics group known as Replicant. His departure continues the robotics shakeup at Google.Â Details here.
Other press events ranged from entertainingÂ to informative andÂ includedÂ Yamaha VenturesÂ announcingÂ their cooperation with SRI International to jointly turn Yamaha’s MotoBot into a real thinking and navigating robot.
“This project will be able to push several boundaries: visualizing data about human motorcycle operation, further quantifying the relationship between rider input and machine behavior, and then using the resulting know-how to build even better vehicles,” explains Amish Parashar, Director of Strategic Business Development at Yamaha Motor Ventures and Laboratory Silicon Valley Inc.
Keynotes were particularly informative
Intel, IBM, Netflix, General Motors and Volkswagen all had keynote presentations but seats for Intel’s were the most highly prized.
Intel’s CEO Brian Krzanich was theÂ featured speaker and he covered so many topics one really has to watch the whole hour and forty minuteÂ presentation to capture the full impact of all that he described. The import of what he said — that we are moving from a time of transactional systems to oneÂ that is experiential –Â seems predictive of the next few years in electronics, the digital world, robotics and artificial intelligence. Watch the video above or read the condensed version here.
IBM’s CEO Ginni RomettyÂ told a packed CES audience that Watson and IBM were changing the nature of data processing from transactional to cognitive and that this process would change computingÂ and lead to providing cognition as a service. IBM describes the cognitive process as providing the 3rd hand for a lab technician, very similar to the experiential descriptor used by Intel’s CEO. During Rometty’s presentation she described how Watson is working with SoftBank to provide global distribution and support for their Pepper robots. Read the condensed version here.
A bit of cynicism: Lots of overzealous hype
Overzealous marketingÂ can be seen regularly in crowdfunding campaigns. CES was similarly full of examples of ventures claiming to be able to provide something useful when, in fact, they need funding to see whether they can actually do what they are promising. Sometimes these companies hire social media people to help promote those very things usingÂ viral marketing in their arsenal of advertising tools. There are many examples but the 2014 Robot Butler campaign is a paradigm classic.
In a joint marketing campaign for Quirky, which was promoting their array of smart home sensors, switches and products, andÂ subsidiary Wink’s hub that combines them into a smart home, they crafted a catchy video ad suggesting that smart homes were better served by Wink products than by a robotic butler. The video entitled (Like a robot butler, but less awkward) showed a couple in bed being uncomfortable with their robot butler peeking in on them as if it were sentient.Â The ad wasÂ supported by the distribution of a bunch of cardboard shipping boxes for non-existent robot butlers which they dropped off on the streets of San Francisco waiting for trash pickup as if they were the empty boxes of real robot butlers. The promoters hyped sightings of those boxesÂ with lots of blog posts, tweets and other social media and even set up a Robot Butler website.
AdWeek finally exposed the situation:
“Well, it turns out this was just a social media sensation. There is no real Robot Butler, at least not this one, and the whole misleading campaign, was just for an app that controls home appliances.
âThe company behind the app and marketing was called Wink whichÂ is owned by Quirky, a New York-based company that makes Internet-connected devices for the home and other gadgets, and General Electric is an investor in Quirky.
“Quirky is for real and subscribed to Wink’s parody marketing campaign based on the Robot Butler. The problem was there was no indication that the robot was a hoax, it was not selling out of stock as claimed, it would not be ready for shipment to consumers, and it was not being reviewed by reputable news sources.”
Quirky recently filed for bankruptcy; the Wink component is being sold off as IP to Flextronics International; the advertising “parody” (which, in this case, appearedÂ to be a euphemism for “phony”)Â failed;Â and a real robot butler is still many years off.
Bottom line:
CES draws huge traffic to the worlds of digital, electronics, robotics, IoT and consumer products. Everyone wants to learn about products and thematic or even paradigmÂ changes that will affect their lives in the near future, and over 6,000 members of the media from all over the world were there to gather that information. Their observations have been – and will be – top news stories for months to come.
There will be mistakes made in some of those reports as there was in a recent NPR story about Pepper costing $20k when actually it sells for $2k. Nevertheless, the CES experience is a valuable stimulant for all of us in the various industries that make up the robotics industry.
The two keynotes mentioned above, by the CEO’s of Intel and IBM, describe a trend from transactional to cognitive to experiential. This has import to the robot industry in a variety of ways.
by IBM’s Watson being incorporated in SoftBank’s Pepper social robots
by the ever-increasing value of the chips, cameras and systems being offered by Intel, Qualcomm and others
and by theÂ expectation of users to be able to communicate and be understood by their robotic assistants.
There’s no reasonÂ to overdo the promotion of future products by falsification, stealing content or otherwise hyping a product beyond it’s capabilities or possibilities. People read most ofÂ the stories and reports coming out of CES because they want facts about products they may want to buy. They want the truth — and they can handle the truth.",https://www.therobotreport.com/ces-noise-hype-hustle-and-business-as-usual/,[[0.12850818]]
IBM’s Watson Easily Wins Jeopardy!,"Day 3 results: Watson wins handily over Jeopardy!’s two most successful champions – Ken Jennins and Brad Rutter.
The real test will be applying – commercializing – Watson’s underlying analytics for language processing and data management for different industries. On IBM’s Watson website, healthcare, finance, customer services and handling ambiguity are explored.
AI already being used by Google to interpret queries; credit card companies use it to find and track fraud; Netflix uses it to recommend movies; and it’s used to process and audit billions of financial transactions and trades. AI in robotics, particularly in human-robot communication, is lagging and slowing progress.
What can we expect from Watson and IBM in the next decade? Read this.",https://www.therobotreport.com/ibms-watson-easily-wins-jeopardy/,[[0.1257872]]
AI debate machine argues with itself at Cambridge Union,"IBM has a Project Debater AI system that can debate humans on complex topics. A recent event to showcase its capabilities turned into pure drama as the machine proceeded to throw AI under the bus as it took both con and pro positions as to whether or not AI is harmful to humans.
Just stop and think about the premise: A robot can be capable of debating complex topics. What a great idea for an off-Broadway play. A sci-fi movie that wins an Oscar for the human, or maybe for the robot. At the least, a funny commercial for the next Super Bowl commercial break.' Only it was none of these.
A robot debating a human about the dangers of artificial intelligence was the focus of a real event on Nov. 21 at the world's oldest debating society, the Cambridge Union in the UK. The topic of the debate was exactly that: the threat posed, if any, by artificial intelligence. The 300-strong audience was a ""rather typical"" turnout, said an article in the Medium account of Inside IBM Research.
The star of the show was not a world name such as Margaret Thatcher or the Dalai Lama but rather a machine with blue lights. The robot at center stage was IBM's Project Debater.
So, it took the side of arguing against the danger, right? Wrong. It argued both sides as onlookers stared and heard its two opening statements: first, arguing in favor of AI, and then, against AI. The robot had been given arguments drawn from over 1,100 human submissions in preparation for the debate, said New Scientist, and it was analyzing arguments that people had sent in online.
Jeremy Kahn in Fortune: ""After Project Debater presented the opening case for each side at the start of the debate, it was up to the humans on the two teams to elaborate on these points and rebut counter-arguments.""
New Scientist talked about the con arguments. The robot tried to do itself in: (1) It told the audience on the con side that AI can cause a lot of harm as it was unable to make a morally correct decision—morality was unique to humans. Another fault was that (2) AI was only as fair as the humans feeding it and AI could suffer from human bias. Additionally, (3) ""AI companies still have too little expertise on how to properly assess datasets and filter out bias.""
Which side of the debate finally swayed the audience? Donna Lu in New Scientist reported that the robot narrowly convinced audience members ""that AI will do more good than harm."" The team got 51.22 percent of the audience vote.
The article in Medium gave a full account of how the vote went down:
""As the debate ended, it was time for the audience to pick a winner. Instead of casting votes, the room suddenly filled with the whoosh of hundreds of people getting up at once. The audience had three doors to choose from to go through—a 'ayes' door in support of the proposition, a 'noes' door in support of the opposition, and 'abstain' door for those who were wavering. The narrow majority crowded in front of the noes door—meaning that they voted in favor of AI (the final tally: 48.17% ayes, 51.22% noes and 0.61% abstention).""
Underpinning Project Debater is technology that can sort the donated submissions from humans into key themes. The technology can also identify redundancy, said New Scientist, where submissions may have made the same point but just with different words.
This leads to an important point about the Cambridge Union event—IBM showcased a research feat that has a purpose other than mere entertainment. Its technology ""speech-by-crowd AI"" can be used as a tool for collecting feedback from large numbers of people, said New Scientist.
Speech-by-crowd technology makes it possible to collect free-text arguments from audiences and automatically deliver persuasive viewpoints whether to support or argue against a topic.
IBM engineer Noam Slonim, according to New Scientist, said the technology could help establish an ""effective communication channel between the decision maker and the people that are going to be impacted by the decision.""
Elsewhere on an IBM site, Slonim said the aim of his research was the development of Computational Argumentation technologies, an ""exciting and rapidly emerging research field."" He said together with a large team of researchers, they were developing ""a combination of Machine Learning and NLP techniques in this context.""
After chess and Watson, this might be the next grand challenge. Dr. Slonim in an interview earlier this year when he attended the AI for Good global summit in Geneva ,he said he had had this notion of a machine that could debate humans.
Do-able? They didn't know but they proceeded to work on it for six years.
IBM defines Project Debater as the first AI system that can debate humans on complex topics.
""Project Debater digests massive texts, constructs a well-structured speech on a given topic, delivers it with clarity and purpose, and rebuts its opponent. Eventually, Project Debater will help people reason by providing compelling, evidence-based arguments and limiting the influence of emotion, bias, or ambiguity.""
© 2019 Science X Network",https://techxplore.com/news/2019-11-ai-debate-machine-cambridge-union.html,[[0.11936801]]
Are Smartphones the Building Blocks of Industry 4.0?,"How often do you check your phone at work? Maybe you’re reading this article on it right now.
(Don’t worry, we won’t tell.)
Smartphones were a revolution for workplace distractions, but they can also be tools for productivity.
I recently attended the IBM Watson IoT Exchange event in Orlando, the AI giant’s annual conference for its Watson solutions, bringing together users and developers of multiple IBM IoT products including Maximo enterprise asset management (EAM).
As I attended the keynotes and workshops of the Maximo stream, I noticed a trend: several of the featured monitoring, analytics and asset management solutions required or recommended the use of a consumer electronic device, such as a smartphone, consumer tablet or augmented reality headset.
A few of the users I spoke to at the event had reservations about utilizing consumer electronics in the industrial environment. For example, over lunch, one engineer working for a large firm on a military base explained to me that no matter what security features are implemented, there’s just no way he’d ever be able to bring smartphones onto the base to give to maintenance technicians. In a demo of an acoustic monitoring solution, several participants asked about hardware options—such as industrial microphones and ruggedized industrial PCs—citing concerns about the durability of consumer smartphones in the factory environment.
Given the risks and the manufacturers’ tendency to be wary of new tech, why are ideas like bring-your-own-device (BYOD) strategies seemingly gaining traction in industrial enterprises? And why are industrial software solutions providers like IBM, PTC and others recommending the use of these devices?
IBM Watson IoT on the Factory Floor
Engineering.com spoke with Stephan Biller, VP and Chief Innovation Officer at IBM Watson IoT, about using consumer devices in industrial environments. He highlighted the price-performance tradeoff of consumer vs. industrial devices.
“Many of our customers want iOS devices or Android devices because they have them already,” said Biller. “These devices are getting better by the day [because] the consumer technology train goes much faster than the industrial technology train. So, you're getting much better capabilities from a consumer device.”
One of the main concerns with using consumer devices in a factory comes from their fragility. However, Biller calls this a basic cost-benefit decision: “Maybe five years ago people would say, ‘no way I'm going to have an iPad in my factory, it's going to break.’ Okay. So, you're going to buy an industrial device that's ten times as expensive so that it won’t break? How many iPads are breaking? One out of a hundred?”
Counterpoint: Industrial Sensors Should Be Used for Industrial Sensing
Douglas Andrea is CEO of Andrea Electronics, which specializes in digital array microphones and other industrial sensors. These represent the alternatives to strapping an iPhone to a piece of equipment. Andrea also attended the IoT Exchange conference, and was quick to hand a business card to any engineer with doubts about the utility of consumer tech in the factory.
“The IoT market is emerging quickly now, and it’s becoming a reality for large manufacturers or utility plants to start considering monitoring their equipment with IoT sensor devices,” Andrea said. “But there are not a lot of custom sensors out there for industrial IoT. So, that’s why [companies like IBM] are using these devices for proof of concept. They're using smartphones and tablets as makeshift sensors. However, this is obviously very expensive, and companies don't want workers to walk away with these phones because the workers think that they can just take them home and use them for their personal use.”
According to Andrea, consumer devices are useful for these short-lived proof-of-concept tests or trials, but they aren’t the ideal long-term monitoring solution.
“Industrial customers want a low cost solution that gets the data from the machine to the cloud and the dashboard to monitor these things,” he said. “They need quite a few sensors; hundreds, maybe, depending on the size of the operation, or thousands. And if you want to put numerous sensors on one machine, it's just cost prohibitive to making them go out and buy consumer cell phones and strap them on. And it's also the form factor—it’s clumsy. It's not designed for that. So, new forms of low-cost sensors that have the proper form factor for attaching to machinery need to be developed now as the segment emerges.”
Of course, you can do more with a smartphone than collect data. Besides sensor or equipment monitoring solutions, smartphones and tablets also have communication and information access applications that could aid maintenance workers in the field. “That's different,” said Andrea. “I think these field applications make a lot of sense. They can have a tablet device for larger screen. They can also use tools such as augmented reality headsets. So, I think that's going to also develop into more specialized equipment.
“I think right now the smartphone and tablet make sense and work pretty well for a maintenance person using tools such as AI feedback, virtual manuals and instructions to service equipment, getting the most updated information in real-time. However, I think you'll see these devices being sold in the future in high-end and ruggedized versions.”
Smartphones in Factories
Consumer smartphones are communication devices that include several built-in sensors. When an application requires a communication device, they’re great. When the application requires a sensor device, the smartphone is being used for something other than what it was originally designed for, which may not be optimal.
Stephan Biller’s cost-benefit argument is a good one: consumer devices are simple and easy to use, and they may be the best option for some customers. For those users looking for a more specialized sensor device, industrial microphones are an option.
“It's exciting for Andrea as a microphone company and an OEM supplier to see acoustic monitoring as part of the sensors for IoT applications,” said Andrea. “Acoustic analytics is becoming a potential dominant feedback source for AI tools and for speech applications. So, I'm very excited about the growth of applications for microphones in industry.”
For more information on the tools described in this article, check out IBM Maximo Asset Performance Management (APM) Equipment Maintenance Assistant and Acoustic Insights, part of the Maximo Production Quality Insights (PQI) SaaS solution.
For more on industrial IoT, check out The Connected Factory and More: 5 Examples of How IIoT is Changing Manufacturing.",https://www.engineering.com/AdvancedManufacturing/ArticleID/19178/Are-Smartphones-the-Building-Blocks-of-Industry-40.aspx,[[0.11815966]]
Nature can help solve optimization problems,"Today's best digital computers still struggle to solve, in a practical time frame, a certain class of problem: combinatorial optimization problems, or those that involve combing through large sets of possibilities to find the best solution. Quantum computers hold potential to take on these problems, but scaling up the number of quantum bits in these systems remains a hurdle.
Now, MIT Lincoln Laboratory researchers have demonstrated an alternative, analog-based way to accelerate the computing of these problems. ""Our computer works by 'computing with physics' and uses nature itself to help solve these tough optimization problems,"" says Jeffrey Chou, co-lead author of a paper about this work published in Nature's Scientific Reports. ""It's made of standard electronic components, allowing us to scale our computer quickly and cheaply by leveraging the existing microchip industry.""
Perhaps the most well-known combinatorial optimization problem is that of the traveling salesperson. The problem asks to find the shortest route a salesperson can take through a number of cities, starting and ending at the same one. It may seem simple with only a few cities, but the problem becomes exponentially difficult to solve as the number of cities grows, bogging down even the best supercomputers. Yet optimization problems need to be solved in the real world daily; the solutions are used to schedule shifts, minimize financial risk, discover drugs, plan shipments, reduce interference on wireless networks, and much more.
""It has been known for a very long time that digital computers are fundamentally bad at solving these types of problems,"" says Suraj Bramhavar, also a co-lead author. ""Many of the algorithms that have been devised to find solutions have to trade off solution quality for time. Finding the absolute optimum solution winds up taking an unreasonably long time when the problem sizes grow."" Finding better solutions and doing so in dramatically less time could save industries billions of dollars. Thus, researchers have been searching for new ways to build systems designed specifically for optimization.
Finding the beat
Nature likes to optimize energy, or achieve goals in the most efficient and distributed manner. This principle can be witnessed in the synchrony of nature, like heart cells beating together or schools of fish moving as one. Similarly, if you set two pendulum clocks on the same surface, no matter when the individual pendula are set into motion, they will eventually be lulled into a synchronized rhythm, reaching their apex at the same time but moving in opposite directions (or out of phase). This phenomenon was first observed in 1665 by the Dutch scientist Christiaan Huygens. These clocks are an example of coupled oscillators, set up in such a way that energy can be transferred between them.
""We've essentially built an electronic, programmable version of this [clock setup] using coupled nonlinear oscillators,"" Chou says, showing a YouTube video of metronomes displaying a similar phenomenon. ""The idea is that if you set up a system that encodes your problem's energy landscape, then the system will naturally try to minimize the energy by synchronizing, and in doing so, will settle on the best solution. We can then read out this solution.""
The laboratory's prototype is a type of Ising machine, a computer based on a model in physics that describes a network of magnets, each of which have a magnetic ""spin"" orientation that can point only up or down. Each spin's final orientation depends on its interaction with every other spin. The individual spin-to-spin interactions are defined with a specific coupling weight, which denotes the strength of their connection. The goal of an Ising machine is to find, given a specific coupling strength network, the correct configuration of each spin, up or down, that minimizes the overall system energy.
But how does an Ising machine solve an optimization problem? It turns out that optimization problems can be mapped directly onto the Ising model, so that a set of a spins with certain coupling weights can represent each city and the distances between them in the traveling salesperson problem. Thus, finding the lowest-energy configuration of spins in the Ising model translates directly into the solution for the seller's fastest route. However, solving this problem by individually checking each of the possible configurations becomes prohibitively difficult when the problems grow to even modest sizes.
In recent years, there have been efforts to build quantum machines that map to the Ising model, the most notable of which is one from the Canadian company D-Wave Systems. These machines may offer an efficient way to search the large solution space and find the correct answer, although they operate at cryogenic temperatures.
The laboratory's system runs a similar search, but does so using simple electronic oscillators. Each oscillator represents a spin in the Ising model, and similarly takes on a binarized phase, where oscillators that are synchronized, or in phase, represent the ""spin up"" configuration and those that are out of phase represent the ""spin down"" configuration. To set the system up to solve an optimization problem, the problem is first mapped to the Ising model, translating it into programmable coupling weights connecting each oscillator.
With the coupling weights programmed, the oscillators are allowed to run, like the pendulum arm of each clock being released. The system then naturally relaxes to its overall minimum energy state. Electronically reading out each oscillator's final phase, representing ""spin up"" or ""spin down,"" presents the answer to the posed question. When the system ran against more than 2,000 random optimization problems, it came to the correct solution 98 percent of the time.
Previously, researchers at Stanford University demonstrated an Ising machine that uses lasers and electronics to solve optimization problems. That work revealed the potential for a significant speedup over digital computing although, according to Chou, the system may be difficult and costly to scale to larger sizes. The goal of finding a simpler alternative ignited the laboratory's research.
Scaling up
The individual oscillator circuit the team used in their demonstration is similar to circuitry found inside cellphones or Wi-Fi routers. One addition they've made is a crossbar architecture that allows all of the oscillators in the circuit to be directly coupled to each other. ""We have found an architecture that is both scalable to manufacture and can enable full connectivity to thousands of oscillators,"" Chou says. A fully connected system allows it to easily be mapped to a wide variety of optimization problems.
""This work from Lincoln Laboratory makes innovative use of a crossbar architecture in its construction of an analog-electronic Ising machine,"" says Peter McMahon, an assistant professor of applied and engineering physics at Cornell University who was not involved in this research. ""It will be interesting to see how future developments of this architecture and platform perform.""
The laboratory's prototype Ising machine uses four oscillators. The team is now working out a plan to scale the prototype to larger numbers of oscillators, or ""nodes,"" and fabricate it on a printed circuit board. ""If we can get to, say, 500 nodes, there is a chance we can start to compete with existing computers, and at 1,000 nodes we might be able to beat them,"" Bramhavar says.
The team sees a clear path forward to scaling up because the technology is based on standard electronic components. It's also extremely cheap. All the parts for their prototype can be found in a typical undergraduate electrical engineering lab and were bought online for about $20.
""What excites me is the simplicity,"" Bramhavar adds. ""Quantum computers are expected to demonstrate amazing performance, but the scientific and engineering challenges required to scale them up are quite hard. Demonstrating even a small fraction of the performance gains envisioned with quantum computers, but doing so using hardware from the existing electronics industry, would be a huge leap forward. Exploiting the natural behavior of these circuits to solve real problems presents a very compelling alternative for what the next era of computing could be.""
Provided by Massachusetts Institute of Technology
This story is republished courtesy of MIT News (web.mit.edu/newsoffice/), a popular site that covers news about MIT research, innovation and teaching.",https://techxplore.com/news/2019-10-nature-optimization-problems.html,[[0.11635652]]
Robots are software and software is “eating the world”,"(Following is an unedited webinar, presented by Robert Dahlstrom is founder and CEO of Apellix Robotics.)
Today we’re talking about robots, and more specifically software controlled robots and how robots are software.
As we know, robots and certain drones are definitely hardware, but what does hardware require to run and operate? Obviously, the answer is software.
Robots are also machines, as well as hardware. According to the Oxford Dictionary, a machine is an apparatus using or applying mechanical power, and having several parts each with a definite function and together performing a particular task.
But in addition to being machines, robots are programmable machines. Wikipedia defines a robot as a machine, especially one programmable by a computer capable of carrying out a complex series of actions automatically. It’s interesting in this Wikipedia definition that they specifically say a machine programmable by a computer.
These robotic systems are machines, programmable machines, and automated machines. What a machine does is, a machine uses power to apply force, or to control a movement, or to perform an intended action. They can be driven by anything from animals, to people, to wind, or chemical, or thermal, or most commonly electrical power.
These machines include system of mechanisms that takes the actuator input to achieve a specific application or output of forces and/or movement. These include computer sensors quite often that monitor the performance of these machines, that are able to plan movement in these various mechanical systems.
Way back in the beginning of the renaissance in Italy, philosophers defined six simple machines, which were the elemental devices that put a load into motion, calculated the ratio of output force to input force, and these are known today as mechanical advantage.
You can think of something as simple as a lever, and the leverage you can apply from that, so that mechanical advantage put in to an automated hardware machine is what enables us to come up with the robotic systems that we have today. These modern machines are complex systems that consist of structural elements, and mechanisms, control components, interfaces for convenient use, anything from automobiles and airplanes, those are machines, to appliances in our house as well as farm machinery, and more along the robotics area, factory automated systems.
Most of these robotic systems utilize microprocessors. Outside of the small subset of mechanical only robotic systems, the microprocessor is a core component of robotic systems.
Microprocessors run by having embedded software built into them. Without that software, a microprocessor control program will not work. What that enables is, it allows for use of performances unattainable by humans.
One way to think of this is mechanically calculated mathematical profs, such as solving the equation for pi. How arduous that is as a human, and how simple that is for a processor controlled machine like a calculator and/or computer spreadsheet.
This embedded software that’s in these machines and mechanical devices allow us a lot of flexibility in what we can do. By embedding a software controlled microprocessor, it allows to tailor for different needs of a product line. You could upgrade to performance with minimal redesign to the product. What I mean by that is making modifications to the software, to the embedded programs within these microprocessors actually enables additional functionality that is independent of modifications to the hardware of the machine itself.
The microprocessor control systems also provide control strategies that are impractical to implement with electromechanical controls, or with purpose-built electric controls.
Examples of this would include motor-control systems where you can adjust based on timing, or speed, or load, or ambient temperature, or other variables.
This comes back to my core argument here that robots are computers. Because they’re using microprocessors and computers are microprocessors. A microprocessor is defined as a computer processor which incorporates the functions of a computer’s central processing unit, commonly called of CPU, on a single integrated circuit, or multiple integrated circuits.
Given how most robots, most modern-day current robots have multiple processors or have, in addition, have multiple sensors, and those sensors contain processors, therefore, I’m going to say that robots are computers because when you remove the computer aspect form a robotic system you’re left with a not modern robotic system, you’re left with something in essence a mechanical design.
Microprocessors are programmed with software as we know and they don’t work without it. Since robots contain these multiple processors, they’re computers. Here is a picture of a robot called Sophia, she’s a humanoid robot that uses artificial intelligence, developed by Hanson Robotics, and she’s designed to respond the questions and it’s been interviewed from reporters from around the world. The reason she’s notable is just in October of this year, October 2017, she became the first robot to receive citizenship of any country, Saudi Arabia granted her citizenship.
Since robots are hardware, like we started out showing pictures of hardware, since robots are machines, we started out showing pictures of machines and talking about them, and since robots are programmed automated machines utilizing microprocessors, my argument is that robots are software, robots could not work without software.
What about some of the newer software technology such as machine language, visual processing, artificial intelligence, is that software? Absolutely. What about human intelligence, is that software? Some people say yes. The analogy is the human body is the hardware, but the brain is the software, which is the electrical-chemical neurons that focus on things.
It’s interesting to have this cognitive structure to look at things as a hardware being the physical part of something such as a robotic system, and software being the brains of something like a physical component such as a robot.
Now that I’ve been droning on for a bit, I just want to talk a little bit about how drones, what they are, and how certain category of drones are robots, and other drones are just mechanical devices.
There are several definitions of aerial drones, different mechanical, types of aerial robots, or mechanical systems. But what to me makes a drone a robot, and that is a drone that has a ability to do something other than just fly and take pictures. Now, drones, when I’m speaking about drones, this includes more than just the common perception of the drones that fly, but also the ground vehicles and underwater vehicles.
To me, the drones that fly and take pictures that are common in today’s world are not robotic, aerial robotic systems, to me a robot, a typical manufacturing robot, has what’s called an End Effector. However, if you have an aerial robot that uses a drone for the lift platform and you add technology from the robotics domain, such as an end effector, to me then you’re able to call that drone a aerial robot.
Robots are amazing, they can do all sorts of new things in addition to what they’ve been doing historically, including adding safety and life features. For example, there are robotic systems now that are medical, that do medical procedures that are difficult or dangerous for humans to do because we have additional precision with the robotic system that’s not available with the human doing it.
Similarly, with the aerial robotic systems, you have the ability with some drones to do things like, in combination with a ground-based robot for example, control a bulldozer, they actually are systems in use in the world right now where there’s a drone that’s flying in the air, unmanned, autonomous, there’s a bulldozer on the ground, unmanned, autonomous, the two are communicating with each other, and completing tasks.
It’s very interesting how we were able to get to this place where we are in history. There’s been a lot of enabling technology that brought this around. Part of this has been fueled by the ubiquity of cellphones, and the massive economies of scale. Miniaturization of all the computing processing that goes into your cellphone, and the example also of Moore’s Law where computing processing power doubles approximately once every 18 months.
Lots will argue how we got here with software. Without the software that we have, modern software, we wouldn’t be where we are today. One quick example of that is the computer industry. If you’ve been around in the early ’90s, when personal computers were first being utilized in business, you notice that the software has become more complex, and there are those that argue that the software has actually driven the development of the hardware, pushing it to keep up with the capabilities.
The example being the visual operating systems like Microsoft, before that with the text-based displays on a computer, the hardware required to run that software was much simpler, one you bring in the graphical interface for the software, it required additional hardware requirements. Software, in part, drove some of the development of the computer hardware.
There’s a really interesting book that talks about this titled The Second Machine Age. The authors of this book argue that the second machine age involves the automation of a lot of cognitive tasks that make humans and software-driven machines substitutes rather than complements. We’re contrasting this with what’s called the first machine age commonly called the industrial revolution, which helped make labor and machines complementary. This relates to where robotics is now and where we’re going with robots and software development of robots in the future.
This rapid changes of the second machine age where automation of cognitive tasks are starting to occur is enabling a lot of technology that we in the past thought was 10 or 20 years in the future, right now it’s an exciting time of a lot of brilliant technologies.
Part of how we got there is exponential growth. Thinking back to Moore’s Law, and how computer processing doubles every 18 months, there’s an interesting fable called Rice and the Chessboard fable. The fable goes that the inventor of chess showed the game to the emperor of India. The emperor was so impressed that he invited the inventor to name his reward, he said “This is a wonderful game, I will grant you any boon you would like.” The inventor said “Oh, I’m just a humble game maker, I only wish for this, one grain of rice for the first square, two for the second square, four for the third square, and so on.” In essence that’s showing exponentially how things grow and double with each increment.
The emperor agreed thinking that this was a reasonable request. What happens is after 60 doublings you’ve got this huge number, actually, with 32 doublings, halfway through the chessboard, you have more rice than has ever been harvested in the history of the world. If it was stacked in a pile, it would be taller than mount Everest.
It’s kind of non-intuitive and hard for humans to understand how exponential growth works because we’re used to doubling things. One other example would be, if I was to take a step, I know how far that is, if I was to double that and take two steps, that’s also not that far, I know how far that is, if I was to double that, and take four steps, that’s not that far, but what happens is that doubling extends quickly, so that it would actually take 65 million steps to circumnavigate the globe, the world, which is only 27 doublings.
As the graph for exponential growth shows, this is just sort of typical for humans to wrap their heads around, because we don’t have experience with exponential in the physical world that often. As you see, this graph shows what is typically referred to as a hockey stick curve, and it’s the natural exponential function of y equals e x, e to the x power, where x and y are points on the graph.
Where are we now with Moore’s Law? We’re about halfway through the chessboard. Think of things that are very heavy processing microprocessor-based calculations and how everything that we have today will be able to double that same amount of processing in the world, this time next year, or in 18 months. That is leading to a lot of the changes we’ve been seeing with robotics systems.
This exponential growth of computing power has helped enable what’s been referred to as the fourth industrial revolution. The fourth industrial revolution is a collective term embracing a number of automation, data exchange, and manufacturing technologies that draw together what’s been called cyber-physical systems. This includes such as the internet of things, or the internet of services.
The industrial revolution, also called industry 4.0, is characterized as a digital revolution. It’s blurring the lines between physical, digital, and biological spheres. This internet of technologies example is promising to disrupt the global economy and create a lot of growth and prosperity, and there are a lot of businesses that want to participate in the fourth industrial revolution, that are trying to transform their businesses to get onboard by going digital.
Again, none of this works without software. Back in 2011, Marc Andreessen. Marc Andreessen is one of the founders of Netscape, one of the first browsers that was used on the internet, and he co-founded one of the largest general-partners of Silicon Valley venture capital firm Andreessen Horowitz. In 2011, he said “Software is eating the world.” This is a fantastic article to read because it lays out just what I’ve been talking about in this presentation that without the software power that we have, we wouldn’t have been able to advance as rapidly as we have, that we wouldn’t be able to continue to advance as quickly as we are able to now.
This was revisited in 2016 by TechCrunch and they said “Marc Andreessen penned his famous ‘why software is eating the world’ essay in the Wall Street Journal five years ago. Today, the idea that every company needs to become a software company is considered almost cliché.”
As software is eating the world, it’s quite amazing what all the things that software can do, and from a large part software is responsible for robotics, and how we’re able to do just amazing things with robotic systems. As the software increases, as the software becomes more sophisticated with artificial intelligence and neural networking, as the hardware becomes faster, more capable, as the communication between these things becomes more ubiquitous, and easier, and we have things such as swarms of flying drones, and warehouses these autonomous robotic systems that are navigating independently of one another, autonomous cars. All this is exciting, and it shows the value of these robotic systems and specifically the value of the software that enables these robotic systems to do what it is that they’re able to do.
I know I’m droning on about software, but it’s just to me incredibly exciting the things that you can do with software-enabled hardware.
The potential of robotic systems is absolutely incredible. The things that are coming up that we’ll be able to do will be things that we have not thought of in the past. Robots are a young and multifaceted industry, and they’re only now just beginning to show their true potential.
This brings me to what I’m calling the platform, so I can describe the importance of a platform. What do I mean by that? Let’s take the examples of iPhone, or mobile phone. The iPhone is a platform, meaning that you have hardware, and on that hardware you have a platform to run a multitude of software applications. You have a software application that allows phone calls, you have a software application that allows you to check your email, you have software applications, you have the App Store, where you can download all these things that make your phone do things.
When the designers of the iPhone were building it, they put it the camera, and they put in the flash on the camera. But because this is a platform, and because this is software, somebody came up with an idea that the designers of the hardware never would’ve thought of, and that is an app that uses the light on your camera to shine, if you put your finger over it, will shine through your skin and actually show you your blood pumping through your skin and give you your pulse.
That’s something that shows the value of software because that’s something that was never intended to be designed in by the hardware creators, but because there’s a platform that enables the software creation of this, it shows that you can create things that never were conceived of just by modifying software.
The platform is everything from you’ll hear the terms such as Software as a Service, or Platform as a Service, or Infrastructure as a Service, X as a Service, which is meaning everything is a service.
A lot of companies now use this platform, be it an iPhone, or robotic system, or mobile device, they use a platform to provide these various services.
Again, to me, this only happens because of the software. Remember, hardware doesn’t work without software. Software is pushing the boundaries of what hardware can do and incredibly making the hardware even better. Another example of this would be Tesla cars, the electric cars. They made a modification in the software for the algorithm downloaded it to the cars and increased the acceleration of the cars. Same thing with the right hardware on the cars, Tesla could download software and your car can become a self-driving car.
It’s actually interesting, I was talking about iPhones earlier, but in Silicon Valley, some of the venture capital firms even refer to them as software wrapped in plastic.
Workers’ safety, as I touched on earlier in the presentation, is a very critical and important part of robotic systems. Not only can robots work in conditions when humans can’t, where it’s maybe on a factory floor, where it’s hot, or there’s hot welds flying different places, or there’s gases and/or lack of oxygen, none of that really matters to a robotic system. Robotic systems are able to make the world safer for people.
As we continue using robotic systems to innovate towards safety, it’s interesting to think of how we’re able to bring that efficiency of a factory out into the world. That’s what we’re doing now with robotic systems. While robotic systems mainly started in factories for automating tasks on assembly lines, and they’ve gotten more sophisticated, as we continue this development path of faster processors, cheaper processors, better sensors, software that can make sense of all this and put it together in new and novel ways, we’re able to move these robotic systems from the factory out into the real world for real world applications.
The other huge advantage of this is that this enables us to replace human judgment with science, because these robotic systems with various sensors on there are able to make judgments based on scientific data rather than human anecdotal data, or information.
This revolutionary technology of software that came customized and enable robotics to do things they’ve never done before pertains for a very exciting future. Basically software rules. You can say that literally, because software is, in essence, a set of rules controlling something.
Imagine machine operator from the safety of ground operating robotic system that can do something, that’s another example of revolutionary technology, and where we’re moving with this ability of this new hardware, and this new software to do things that were undoable in the past.
A big example of this is the drone, like I spoke of earlier, drone with a End Effector on it is considered by me an aerial robotic system. We’re now able to put these aerial robotic systems manually do tasks that remove workers from harm’s way. One of the common causes of death in the US is falls from height. If we’re able to prevent that, if we’re able to put a robotic system in place to do something that a human is doing that’s dangerous, it just makes a lot of sense.
I was speaking to the CEO, who’s worked in industrial cleaning of oil, and gas, and chemical facilities in his career, and he said “Bob, I’d had to tell five mothers that their sons are never coming home again.” If we can prevent those conversations from happening by putting a robotic system in place, doing the job that a human used to do that was dangerous, then that’s a huge win.
Workers’ safety is incredibly important. There are companies, especially in oil and gas, infrastructure, and maritime, and other energy companies that actually start out every meaning with a safety briefing. It can be the business executives meeting in a conference room, but they start out with a safety briefing.
A lot of industrial companies are very concerned about safety. OSHA, the Occupational Safety and Health Administration of the United States has what’s called a hierarchy of fall protection given that falls are the number one cause of death and workplace injury in the United States. The OSHA hierarchy of fall protection, they say, starts with eliminating the hazards and risks of falling by engineering them out and away from the workplace. That to me is a perfect example of what modern robotics technology can do.
Software-controlled aerial robotic systems would be able to implement that hierarchy that OSHA hierarchy of fall protection by eliminating the hazards of falling, or the risk of falling, by having the operator stay on the ground, having the aerial robotic system go up and do the work in their place.
Again, some of the benefits of this, in addition, are that you’re able to replace human judgment for science. You could increase the safety and the productivity, possibly reduce the cost and the labor, and eventually provide measured standardized quality with sustainable benefits.
One example, and you’re seeing here on this slide, is a picture of an aerial robotic system that’s spray painting the side of a building. I painted houses working my way through college, and what you learn over time is the proper distance to stay from the wall with your spray head when you’re painting to get the optimal amount of paint on the wall. That’s actually called transfer efficiency ratio.
What you learn is, if you move from the sunny side of the building to the shady side of the building, you move that distance because the variable has changed. You learn it’s a more humid day, you move that distance. These were all things that were intuitive to a painter that they learn over time. An average painter can cover 400 square feet per hour, most novice painters start out painting 200 square feet per hour, but expert painters paint 600 square feet per hour.
A robotic system would be able to do this automatically. The sensors on, they would be able to say “here’s the barometric pressure, here’s the relative humidity, here’s the temperature, here’s the surface temperature of the structure being painted, here’s the viscosity of the paint, here’s the characteristics of the coating material.” And then adjust for it. It’s a simple look up table that software can utilize very easily.
This brings to mind the legend of John Henry of Man versus Machine. It’s interesting that this picture on this slide is from Bing for Labor Day. They have an image of a lot of people rappelling down a structure painting it. But the legend of John Henry is that in the late 1920s, I’m sorry, in the 1870s, at the Chesapeake and Ohio Railway Bend there was a tunnel that needed to be built for the railroad to go through the mountain around the bend of the river.
John Henry was the best tunnel digger at the time, and it was a man versus machine, and the legend is that John Henry cut through the mountain in the same amount of time that a machine did, but at the end of it he grabbed his heart and fell over dead. We all know that it’s very easy now for a machine to do much more physical labor that a person can do. This trend is not going to change, it’s just going to continue to get larger, and larger.
Again, robotic systems are awesome, they can do a lot of really cool, a lot of really good things, let’s use them for making the world safer.
Questions & answers
Q: Robert, I understand companies like Uber and Airbnb are software companies that don’t really own the cars or apartments they make money from, is there a similar model in the robotic space or for robotic software companies?
A: Yes, somewhat. You’ll see it with a lot of the apps in the App Store for example. There’s somebody that’s writing an app for a phone, but they don’t own the phone, and that’s one of the incredibly beautiful things about software is you write it once, and it can be installed millions of places. It doesn’t cost anymore, it’s bits and bytes, it’s not like manufacturing a chair, if you sell that chair 10 times, you have to physically put together 10 chairs.
This is, you sell 100,000 copies of software, they’re copies, there’s no additional, incremental cost for them. The software field has been using this for a long, long time, and was co-opted by Airbnb and Uber, but it’s similar. You’re utilizing, or piggybacking off of existing hardware by using the value of software. How this relates to robotics is it with robotics there does have to be a physical robot, but the software can do more and become better.
Again, I take it back to the example of the phone, and/or your desktop PC, that you’re continually getting updates on your software to make it better, to add functionality, to add features, while the hardware stays the same. You can still have that one piece of hardware doing one task, but maybe now with software upgrades that one piece of hardware can do two, or three, or four tasks.
Q: Robert, how do you see robotic software changing in the next three to five years?
A: It goes back to the presentation with Moore’s Law of hardware processing speed doubling every 18 months. As the value is unlocked, people understand the huge benefits, especially companies understand the benefits of software, it’s just going to become more and more ubiquitous, and more and more resources are going to be poured into it. As we talk about with industry 4.0, a lot of companies are looking to move from analog to digital, they’re looking to do that with information and data. That’s part of the pull, or the push behind big data, because you can unlock a huge amount of value that you didn’t have before you had that data.
As robotic started entering into tasks within the workforce, and do things, and as we start measuring things with various sensors, all that requires additional software.
Q: Are you concerned at all that these new robotic systems will take jobs from workers?
A: Not really. Actually, people are very concerned about that, and a lot of people have talked to this issue, but looking historically, at one point in time, a large percentage of the population work on farms, and now there are tractors that do a lot of the work, and we’re able to sustain our population, that’s with a much, much, much smaller number of workers. The same thing was said with computers when they first came out, typists, people on typewriters are going to lose their jobs, and they did, certainly, yes, most of them, but look at the productivity that that enabled.
There’s going to be hard times, there’s going to be a lot of transition, but the robotic systems, I believe, are going to greatly enhance the quality of life of people, and turn this from take a lot of the jobs that were menial, back-breaking jobs and turn them into jobs that are more cerebral, or utilize skills or human cognitive processing.
Not to mention the just enormous backlog of things that need to be done. For example, in infrastructure. Here in the United States, there are so many thousands of bridges that are below standard, and infrastructure that has been delayed, just even the power grid, the number of power transmission towers, most of those were built back in the 1950s and 1960s when the power grid was constructed. They need to be maintained and/or replaced. As we create robotic systems that construct things, and move things, and do things, and paint things, or do stuff like that, do things like that, that’s going to be able to take that backlog out of that, into actual work, that’s going to require additional people to do.
I can actually see this being something that would increase the jobs for people, because more work is going to need to be done.
Q: Can you talk a little bit on the security side of robotic software? How are companies ensuring that robots can’t be hacked by bad guys?
A: That’s absolutely a fantastic question. Given that robotic systems now are becoming more and more networked, and more and more interconnected, it’s more and more relevant. While in the past, robotic systems for the assembly line, for example, might have been what’s called offline, meaning they were self-contained and didn’t transmit any data outside of their own functionality, that’s changing rapidly.
Security is becoming even more and more critical. That’s something that companies need to pay close attention to, and we’re reminded with that every day with all the hacks that we see. This comes back to software once again, because how do you prevent the hacks with software? How are the hacks accomplished with software?
You have to make sure that you have well-written software that prevents this from happening in the first place, whatever possible.",https://www.therobotreport.com/robots-software-software-eating-world/,[[0.11376985]]
UMass Dartmouth Ramps Up Research Programs,"University scientists enjoy access to the world’s most advanced computing architectures.
Plymouth, MA – Microway, a leading provider of computational clusters, servers, and workstations for AI and HPC, announces that research activities are accelerating at the University of Massachusetts Dartmouth since the installation of a new supercomputing cluster.
UMass Dartmouth’s powerful new cluster from Microway affords the university five times the compute performance its researchers enjoyed previously, with over 85% more total memory and over four times the aggregate memory bandwidth. It includes a heterogeneous system architecture featuring a wide array of computational engines.
Some of the main high-performance computing research activities on campus include deep learning, astrophysical simulation, computational quantum chemistry, molecular dynamics simulation, solids analysis, computational fluid dynamics, systems security research, and the development and application of novel numerical methods.
This new cluster purchase was funded through an Office of Naval Research (ONR) DURIP grant award.
Serving Users Across a Research Campus
The deployment has helped continue to serve, attract and retain faculty, undergraduate students, and those seeking advance degrees to the UMass Dartmouth campus. The Center for Scientific Computing and Visualization Research administers the new compute resource.
With its new cluster, CSCVR is undertaking cutting edge work. Mathematics researchers are developing new numerical algorithms on the new deployment. A primary focus is in astrophysics: with focus on the study of black holes and stars.
“Our engineering researchers,” says Gaurav Khanna, Co-Director of UMass Dartmouth’s Center for Scientific Computing & Visualization Research, “are very actively focused on computational engineering, and there are people in mechanical engineering who look at fluid and solid object interactions.” This type of research is known as two-phase fluid flow. Practical applications can take the form of modelling windmills and coming up with a better design for the materials on the windmill such as the coatings on the blade, as well as improved designs for the blades themselves.
This team is also looking at wave energy converters in ocean buoys. “As buoys bob up and down,” Khanna explains, “you can use that motion to generate electricity. You can model that into the computation of that environment and then try to optimize the parameters needed to have the most efficient design for that type of buoy.”
A final area of interest to this team is ocean weather systems. Here, UMass Dartmouth researchers are building large models to predict regional currents in the ocean, weather patterns, and weather changes.
A Hybrid Architecture for a Broad Array of Workloads
The UMass Dartmouth cluster reflects a hybrid design to appeal to a wide array of the campus’ workloads.
Over 50 nodes include Intel Xeon Scalable Processors, DDR4 memory, SSDs and Mellanox ConnectX-5 EDR 100Gb InfiniBand. A subset of systems also feature NVIDIA V100 GPU Accelerators for GPU computing applications.
Equally important are a second subset of POWER9 with 2nd Generation NVLink- based- IBM Power Systems AC922 Compute nodes. These systems are similar to those utilized in the world’s #1 and #2 most powerful Summit and Sierra supercomputers at ORNL and LLNL. The advanced NVIDIA NVLink interfaces built into POWER9 CPU and NVIDIA GPU ensure a broad pipeline between CPU:GPU for data intensive workloads.
The deployment of the hybrid architecture system was critical to meeting the users’ needs. It also allowed those on the UMass Dartmouth campus to apply to test workloads onto the larger national laboratory systems at ORNL.
Microway was one of the few vendors able to deliver a unified system with a mix of x86 and POWER9 systems, complete software integration across both kinds of nodes in the cluster, and offer a single point of sale and warranty coverage.
Microway was selected as the vendor for the new cluster through an open bidding process. “They not only competed well on the price,” says Khanna, “but they were also the only company that could deliver the kind of heterogeneous system we wanted with a mixture of architecture.”
For more information about the UMass Dartmouth Center for Scientific Computing and Visualization Research please navigate to: http://cscvr1.umassd.edu/.
About Microway, Inc.
Microway builds solutions for the intersection of AI and HPC. These include clusters, servers, quiet workstations designed for bleeding-edge computational performance—that serve demanding users in the enterprise, government, and academia.
Since 1982, customers have trusted Microway to deliver them unique and superior deployments—enabling them to remain at the forefront of supercomputing and solve the world’s toughest challenges. Microway is an NVIDIA NPN Elite Solution Provider and an IBM Business Partner. Classified as a small business, woman owned and operated, Microway’s GSA Schedule is GS-35F-0431N.",https://industrytoday.com/umass-dartmouth-ramps-up-research-programs/,[[0.11078674]]
Digital transformation: who is your company’s ‘Uber’?,"To survive and thrive through this current wave of disruption, businesses need to successfully bridge from the physical to the digital world. A new IBM whitepaper lays out exactly how to do just that.
Nobody knows disruption in business models better than manufacturers. In the wake of the Fourth Industrial Revolution (4IR), companies must embrace the latest technologies and processes to efficiently serve ever-more demanding customers and stay relevant in fluctuating global markets.
Since 2000, more than 50% of the Fortune 500 have disappeared. For a manufacturer to not only survive, but thrive, they must bridge from the physical to the digital world in the things that they make, how they make them and how they communicate with their products and customers as they operate throughout the lifecycle.
They need to design and build these bridges, and identify key patterns for success. These new patterns provide us smarter ecosystems populated with smarter products, designed and delivered by smarter enterprises.
Bridging the physical & digital worlds
The biggest challenge right now for industry is addressing how to make these ‘bridges’ of frictionless transactions and data fabrics that cross the gap between the digital and the physical world.
Organisations need to develop smarter products, smarter enterprises and smarter ecosystems across these bridges and unlock the new business opportunities that flow both ways over them.
Focusing on this challenge is the imperative for manufacturers in an industry both exacerbated and assisted by advances in technology such as the Internet of Things (IoT), blockchain and cognitive.
In its new whitepaper – Engineering Industrial Ecosystems: Bridging from the Physical to the Digital World, IBM sets out exactly what smarter products, smarter enterprises and smarter ecosystems are, and how to connect them.
Authored by Paul Homan, CTO Industrial, IBM UK & Ireland, it offers easy to follow advice on what to focus on first and what your next steps should be to develop your organisation’s digital strategy.
To download your copy…",https://www.themanufacturer.com/articles/digital-transformation-companys-uber/,[[0.10754731]]
FogHorn App brings IIoT Edge Computing to Android Devices,"Industrial IoT and edge intelligence company Foghorn Systems has recently announced a solution that brings real-time analytics, machine learning and AI capabilities to Android-based mobile devices such as smartphones.
Called Lightning mobile, the technology is intended to bring edge computing information to operational technology and field professionals without having to rely on connectivity to the cloud. With better access to data and insights, these professionals will be able to make better decisions and assess industrial workflows on the go.
Lightning mobile is a software solution, which means that it opens up new opportunities to build and market off-the-shelf solutions based upon it. According to the company, the software also comes with a support system to deal with the high-volume deployment of the devices.
By enabling industrial edge computing on mobile devices, the company aims to open the door to new edge computing applications across industry. Applications include advanced barcode image recognition via the device camera, smart power tools, advanced fleet applications, portable factory environmental monitors, and device health and battery monitoring.
“Over 85% of mobile operating systems worldwide are Android,” said Mike Guilfoyle, Director of Research at ARC Advisory Group. “For users, more of their operations technology staff can leverage edge intelligence for real-time analytics in the field, without the restriction of fixed-position devices. By enabling OT-staff access to edge computing on handheld Android devices, it will expand the pool of thinking about what is possible at the edge. This will inevitably lead to new use cases for industrial and commercial organizations.”
FogHorn’s Android App, in addition to providing the core analytics and ML capability on the live data, supports ingestion of all the Android event data coming from various sources. This provides a view of actionable insights right on the device, and aims to offer an efficient way to process digital, audio, video and image-based content.
Another interesting industrial IoT application that uses smartphones is an AI-based system that delivers work instructions to field personnel using smartphones and wearable devices, from Contextere. Check out that feature story here.",https://www.engineering.com/AdvancedManufacturing/ArticleID/18892/FogHorn-App-brings-IIoT-Edge-Computing-to-Android-Devices.aspx,[[0.10604126]]
Mitsubishi Electric Automation releases MELIPC industrial computers for edge and IoT,"Mitsubishi Electric Automation has released its MELIPC Series of industrial-use computers for data computing, edge computing and remote monitoring.
The MELIPC Series is targeted towards OEMs and end users running general manufacturing applications, and especially those who require a computing and data monitoring solution that takes up a limited amount of space with a small footprint. MELIPC is designed to enable Internet of Things (IoT) on factory floors that have not been introduced to it yet, or improve it where it is already enabled.
MELIPC releases with four initial models: MI1000, MI2000, MI3000 and MI5000. MI5000, the flagship product, combines real-time equipment control and information processing in one solution. MI3000 contains a touchscreen LCD panel and pre-installed software that allows users to run it as if it were an HMI.
The mid-range MI2000 is designed for wide-ranged system expansion, and the compact, low-cost MI1000 enables companies to begin introducing IoT on their factory floors. All four models can be purchased standalone with Windows 10 IoT Enterprise 2016 installed, or can be purchased together with software as a comprehensive MELIPC data solution.
MI5000 includes two operating systems, VxWorks and Windows. It is compatible with the CC-Link IE Field industrial network, enabling high-speed data exchange at speeds of up to 1ms for real-time equipment control. It also uses Edgecross, an open software platform, to process and distribute data. All models in the MELIPC Series are have Windows preinstalled and various software that allows for edge computing and high speed data transmission.",https://www.automationmag.com/mitsubishi-electric-automation-releases-melipc-industrial-computers-for-edge-and-iot/,[[0.1050733]]
"PLM This Week: News from Siemens, Arena, PTC and Aras","Siemens Acquires EDA Developer Mentor Graphics
Siemens is set to acquire the leading Electronic Design Automation (EDA) software developer Mentor Graphics for $ 4.5 billion.
Mentor’s solutions are centered around an area of product development that has experienced an exponential increase in demand in recent years, which includes design and simulation solutions for things like electrical systems, integrated circuits, printed circuit boards, embedded systems and automotive electronics. Siemens will pay $37.25 per share for the company, which is a 21 percent premium over it’s closing price the day before the deal was announced. This price tag says a lot about the attractiveness of Mentor's product portfolio.
The deal, which received the support of Mentor's board of directors, is conditional and will be completed during the second quarter of next year.
With this acquisition, Siemens (and the Siemens PLM division) will acquire one of the main players in the fast-growing EDA software space. Mentor is headquartered in Wilsonville, Oregon, but is represented in 32 countries, and has a total of more than 5,700 employees. The company has sales of roughly $1.2 billion and a profit margin of slightly over 20 percent.
The company has about 14,000 customers worldwide in every industry from communications, computers and consumer electronics, to aerospace and automotive industries. For these reasons, the company is usually regarded as a global leader in strategically important industrial development areas such as integrated circuit (IC) design, testing and manufacturing; electronic system design and analysis; and automotive electronics.
No stranger to the world of simulation
Speaking of acquisitions, it has been barely a year since Siemens bought CD-adapco, strengthening its portfolio of solutions for analysis and simulation of fluid dynamics.
While there are significant differences between the two companies and their solutions, there is a clear kinship when it comes to Siemens’ strategy behind the acquisitions. Mentor is no stranger in the simulation world; in fact, the company has its own flagship platform in this category in the form of the 3D CFD solution FloTHERM.
FloTHERM is a software that utilizes advanced CFD techniques to study and predict airflow, temperature and heat transfer in components and systems, including things such as computer racks and data centers. The program is usually regarded as one of the industry's best solutions for the integration of MCAD and EDA software. Furthermore, it is considered the world leader in electronics thermal analysis.
In addition, Mentor’s portfolio also contains the CFD-in-CAD solution FloEFD and the 1D CFD software Flowmaster.
Facilitating the creation of digital twins
However, it is primarily solutions for designing printed circuit boards (PCB), and simulation, which one associates with Mentor. This includes the Veloce emulation platform, which reduces the risk associated with the verification of today's complex system chips, or systems on circuits (so-called SoCs). Veloce is the core technology in the Mentor Verification Enterprise Platform (VEP). Other solutions in this complex realm are HyperLynx (signal and power integrity analysis) and systems for MEMS (microelectromechanical systems), not to mention the solution for RF design (RF) Tanner EDA.
“The addition of Mentor solutions for electronic design automation (EDA) and the competent team behind the development of these will radically improve our core capabilities in terms of product design. Thus, we can create highly precise digital twins of the smart product or production line anywhere,” said Siemens' member of the board, Klaus Helmrich.
Altium Releases New Version of Flagship EDA Solution
Speaking of leading EDA software developers, one of Mentor Graphics’ biggest competitors, Altium, recently launched the latest version of its PCB design software Altium Designer 17. Specific for this release is a significant focus on new technologies that reduce the time engineers spend on non-design-related tasks.
“It is a continuation of our ongoing pursuit to shift the focus back onto what engineers are passionate about: designing electronics.” said Henry Potts, Chief Operations Officer at Altium. “Altium Designer is all about the engineer, and we want to capture what inspired our customers to start designing electronics in the first place by automating as much of the process as possible, and putting the focus on creative solutions to engineering challenges.”
So, what new technologies has Altium added to make designers’ lives easier? The main selling point of version 17 is a solution called ActiveRoute, which sets out to make the connection routing of printed circuit boards quicker and less tedious, without sacrificing quality. It straddles the line between an automatic and a manual routing system, letting designers interactively guide their routes across the entire circuit board in minutes.
Altium also claims that engineers will be able to save a lot of time, as well as accurately communicate their design intent, with the automated documentation technology in PCB Draftsman. This solution was added in the 16.1 release, but has received some updates in this latest version.
CREO 4.0: Designing For The IoT
Software developer PTC recently announced the release of a new version of its CAD software Creo.
At version 4.0, it has become clear that PTC's strategy surrounding the Internet of Things has become deeply ingrained into its core products. The new version introduces not only a range of new IoT-centric capabilities, but also extended support for additive manufacturing, augmented reality and model based definition (MBD), things that are central to PTC’s vision of “smart, connected products.”
One of the main ideas behind this vision is the ability to take advantage of sensor data from the IoT to better understand how products are used in real life, then feeding this information back into the product development process to improve design decisions. In Creo 4.0, PTC has added support for this way of working, as well as adding processes to make it easier to design proactively by integrating sensors into the design process.
The new version also makes it easier to print production-ready parts with additive manufacturing techniques. It promises ""design for additive manufacturing,"" enabling designers to design, optimize, validate and run a print-check in the Creo environment. With the ability to create parametrically controlled lattice structures, it enables designers to optimize models to meet multiple design objectives or constraints.
Making augmented reality useful
While AR so far has seen the most use in gaming and marketing, there is no doubt that there is much to be gained by using this technology in other areas. With the acquisition of Vuforia, one of the leaders in the field, PTC has gained a leg up on the competition when it comes to the efficient integration of these experiences into its other products.
With Creo 4.0, designers can seamlessly reuse CAD data to easily create engaging and informative visual augmented reality experiences of a design with a realistic sense of size, scale and context.
Model Based Definition
Another important new feature in the version 4.0 is an increased focus on allowing designers to successfully implement Model Based Definition and increased efficiency in product development by reducing dependency on 2D drawings.
Creo 4.0 enables designers to reduce the errors that result from incorrect, incomplete, or misinterpreted information by guiding and educating designers in the proper application of Geometric Dimensioning and Tolerance (GD&T) information. Creo 4.0 also validates that the GD&T is captured in the 3D CAD model in a fully semantic way, that the model is compliant with ASME and ISO standards and that it constrains model geometry to enable efficient and error-free downstream use in manufacturing and inspection.
Will PTC’s Vision Pay Off?
In the last few years, PTC has made an all-in bet on the Internet of Things, acquiring companies for over half a billion dollars while also investing large sums in further development. In certain ways, it has already paid off. For instance, a recent report by the analysis firm Forrester Research (The Forrester Wave: IoT Software Platforms, Q4 2016), placed PTC’s ThingWorx platform at the absolute top of the heap.
But it hasn’t been all roses during this phase. Sales have been mediocre, and the company is also in the middle of the switch from selling licenses to selling cloud subscriptions.
One thing is for sure: the man behind the plan, PTC CEO and president, Jim Heppelmann, is certain that it will work. If you’re interested in learning more about his reasoning, don’t miss Verdi Ogewell’s exclusive interview with Jim Heppelmann, which will be posted on ENGINEERING.com in the coming weeks.
IBM Offers Aras Innovator to Complement IoT Platform
IBM and Aras have entered a partnership agreement that sees IBM offering the Aras Innovator PLM platform as a complement to the IBM Internet of Things Continuous Engineering solution to deliver an end-to-end Internet of Things (IoT) product development environment.
While there is no specific mention of integration, Aras Innovator is known for its flexibility, scalability and upgradability in product data management (PDM) and PLM solutions —even when heavily customized—relative to traditional PDM and PLM systems. Aras Innovator is designed to be used either as a full PLM solution, or to extend an existing PLM/PDM solution.
The IBM IoT continuous engineering solution supports systems engineering and software development activities throughout the product development lifecycle, helping engineering teams to predictably deliver high quality results and to respond with agility to change.
By using these solutions together, IBM claims that companies can manage systems engineering, hardware development and software development activities throughout the product development lifecycle. Companies will also be able to better understand and manage the dependencies between hardware and software configurations to help break down the barriers between engineering disciplines and ensure better outcomes in the ‘new normal’ of constant change.
Arena Adds Requirements and Defect Management to PLM Platform
Arena Solutions has added a new piece of software to its 2016 fall release. The new solution is called Arena Verify, and adds requirement and defect management to Arena’s cloud-based product development platform, which already contains fully fledged, integrated solutions for PLM, ALM, supply chain collaboration and QMS.
According to Arena, Verify will play a key role in bringing the platform together. The reasoning goes like this: when Verify discovers a defect, the entire process is captured within the product record. Instead of trapping the information in a silo the way many stand-alone solutions might, the integrated nature of the solution allows information to flow to the right people, both internally and within the extended supply chain. Requirements management is also integrated within the product record, so that this critical information can be shared with all relevant stakeholders.
“Our goal is to provide OEMs with complex electronics an all-in-one platform for product development, because there’s no reason these systems should live in separate silos,” said Arena CEO, Steve Chalgren. “Engineers, designers, quality managers, operations, manufacturing and stakeholders throughout the extended supply chain all need access to product data so they can work together to produce the highest quality product in the shortest amount of time. The introduction of Arena Verify brings together this unified solution.”",https://www.engineering.com/PLMERP/ArticleID/13766/PLM-This-Week-News-from-Siemens-Arena-PTC-and-Aras.aspx,[[0.10195811]]
VIDEO: Manufacturing in the Cloud: Part Makers and IT Get to Business,"Machine connectivity with platforms like the Cloud allow manufacturers to collect large amounts of data in real time to isolate errors and improve machine performance.
ENGINEERING.com met with Chet Namboodri, global industry director at Cisco Systems at MAZAK Discover 2015 to talk about how Cisco’s collaboration with MAZAK Corporation and Memex Inc. will change the working dynamic between manufacturers and the software industry in automation.
See the video above and the Q&A below for highlights of the interview.
Jim Anderton (JA): Manufacturers have been a little reluctant to relinquish control of manufacturing processes to people from the software industry. I understand that the collaboration between MAZAK and Cisco changes that dynamic a little bit.
Chet Namboodri (CN): We’ve had a history of trying to enter into this space from the IT perspective. The differences in viewpoint between what we refer to as OT (Operations Technology) and IT has been a barricade to overcome for us.
Partnerships with companies like MAZAK enable that dialogue to occur because we have a common language that we are able to adopt together, based around a common problem we’re both trying to solve.
This is an opportunity to really level up all that control optimization that is taking place in the machines here at the MAZAK Discover 2015 event and level that into the system perspective.
So, by connecting a machine into a larger system, suddenly you’re able to optimize a much broader set of variables that are required for producing any type of parts within any type of environment.
Collaborations like what we’re having with MAZAK include a company called Memex Inc. We’re leveraging their software platform in order to provide for OEE (Overall Equipment Effectiveness) level dashboards and information that we’re able to use for predictive analytics by focusing in on that problem.
With companies such as MAZAK, we’ve been able to drive that integration to not only technologies between the original OT and IP based technologies, but also organizationally and culturally – really coming together in terms of that language and the problems that we’re looking to solve.
We’ve really appreciated the opportunity that has arisen here with MAZAK and Memex and we’re happy to be part of the show.
JA: Closed loop controllers take the thinking out of the process as they’ve made it possible for less experienced operators to still get great results.
In terms of the information sharing of multiple machines and the flow of information in the central system, can a machine shop with 30 to 40 machines dedicate one human being just to analyze this data, or is that something the software can handle?
CN: Yes, more and more software can handle data analyses. The advantage that we have with the architecture with Cisco combined with the IT perspective is that we’re taking computing power all along that stream.
We’re able to take the computing power that’s local and do some analytics in conjunction with the information that we have from other machines, from the ERP, the suppliers and the ecosystem and then use that with local analytics that’s then done in conjunction with Cloud-based analytics.
We refer to that as Fog computing, like a lower level Cloud. There’s a lot of software out there that’s able to take advantage of the computing power locally and do it in conjunction with a Cloud-based system.
For more information, visit cisco.com.",https://www.engineering.com/AdvancedManufacturing/ArticleID/10912/VIDEO-Manufacturing-in-the-Cloud-Part-Makers-and-IT-Get-to-Business.aspx,[[0.09995911]]
People: The real enabler of business growth,"Too often, conversations around the fourth industrial revolution focus on ‘systems’, ‘equipment’, and ‘pieces of kit’. Though every digital journey will leverage new technology, the real driver of business growth will come from your people.
Disruption is nothing new to manufacturing, but the current speed of change is like never before. This makes investing in new systems and processes to assist your workforce and propel your businesses forward has quickly become fundamental.
“You must have the right people in an organisation, undertaking the right roles to innovate, and they then need to be organised in the right way. Fundamentally, it is as simple as that,” James Petherbridge, Executive Partner for Aerospace & Defence at IBM, explained to The Manufacturer.
Transforming a business’s HR process may appear to be a momentous task, but it doesn’t have to be. Taking the right, simple steps and leveraging modern systems can create a more engaged, informed, satisfied and, crucially, productive workforce – which has a direct impact on your bottom line.
The need for change
Helena Parry, Global Market Development of Talent Acquisition & Optimization at IBM, says a lot of manufacturing companies she is working with are rapidly having to change everything.
“They are having to revolutionise skills, processes and systems in order to be relevant in the future and to recruit the right people.”
This need for industry to “reinvent itself” is one of the reasons why Andi Britt, Vice President of Talent & Engagement Europe at IBM, believes HR is so essential manufacturing businesses.
How can organisations achieve such a radical transformation? By employing people who can reinvent themselves, and can therefore transform the wider business,” he suggests.
The other reason Britt says HR is so important to manufacturing in particular, is that specific job roles are narrowing.
“Across sectors, we are all competing for the same people; driven, innovative in their ways of thinking and technology literate. HR technology can help assist manufacturing companies to recruit the right individuals who will propel their business forward, before they are snapped up by someone else.”
Transforming the role of HR
Realising your business case for adopting HR technology is one thing, but surely deployment is a laborious, time-consuming task, right? Not necessarily, says Britt.
“Often, we would start with design-thinking, working with manufacturing employees and managers to identify the specific pain points they have in their current HR processes. Using that as the starting point, we essentially redesign the entire employee experience.”
The employee experience – or employee lifecycle – encompasses the whole process, from recruitment and selection, to onboarding, mapping out their individual development plans and managing performance.
Britt says that HR systems – such as the cloud-based SAP SuccessFactors – can transform every aspect of the employee lifecycle, bringing efficiency and a host of other benefits from recruitment through to performance management.
“SAP has designed a solution to enable employees to have a leading user experience,” he explains. “In manufacturing as in any industry employees are now expecting the same intuitive and easy to use consumer-grade IT that they use in their personal lives, at work.
“Why can’t learning be as fun and addictive as binge-watching your favourite programme? Why can’t mapping out your career be like mapping out your run on an app? This is the challenge that manufacturing HR departments have to face if they are to recruit and retain tomorrow’s workforce.”
Another example of reinventing HR to advance an entire business is IBM’s AI virtual assistant, Chatbot.
Britt says: “Most organisations will start by integrating a very simple chatbot or virtual assistant as a way of answering queries a new joiner might have. Over time, however, these chatbots learn and become increasingly sophisticated and take on more complex tasks.”
Technology like IBM’s Chatbot could also help to sustain a safe workforce, by creating a refined dataset of employees’ work history through previous conversations, helping to identify training opportunities and ongoing development requirements.
Human-centric
People remain the backbone of any company. They are essential if businesses are to succeed in these challenging times. Equally important, however, is the need for reinvention and the adoption of new technologies.
Introducing systems to enable your workers to perform their roles more efficiently and productivity and to the best of their abilities, for example, is becoming ever more important in the future success of your businesses.
“It is all about creating great employee experiences,” Petherbridge adds. “When people come to work, they can communicate with the employer simply, they can access the information they need at their fingertips, and they can acquire real-time insights instantly.”
By utilising tools like chatbots or other smart systems, businesses can better identify the likelihood of employees leaving or understand what training individuals have undertaken recently, and have real-time data available instantly.
Britt concludes: “We have good evidence to prove, that if we get the right technology and the best employee experience in place, manufacturers can improve employee engagements, and this then drives up their productivity.”
HR is often overlooked, but it needs to be championed through technology, because what it represents is the real driver of business growth: people.",https://www.themanufacturer.com/articles/people-the-real-enabler-of-business-growth/,[[0.09973259]]
Pepper delayed until summer; top execs leave,"Softbank announced a delay in sales of their Pepper robot from February until sometime during the summer. Aldebaran announced that CEO and Founder Bruno Maisonnier and Jean-Christophe Baillie have left Aldebaran as CEO and CSO respectively.
TOP EXECS LEAVE:
According to an Aldebaran press release today, Bruno Maisonnier has sold his remaining shares of Aldebaran to Softbank (giving Softbank 95% of the shares) and will leave the company effective March 4th. He will then be appointed Special Advisor to Masayoshi Son and SoftBank Robotics. A new Japanese CEO, Fumihide Tomizawa, will be appointed the new CEO of Aldebaran and take Maisonnier’s place.
Jean-Christophe Baillie, Aldebaran’s Chief Science Officer, left the company two weeks ago and started a new AI gaming company NovaQuark.
Neither Baillie nor Maisonnier would comment on anything to do with the change in CEOs nor the departure of the two top execs.
A French blog focused on startups, Rude Baguette, back in December, provided a preview to what was happening at Aldebaran and, if true, is indeed a very sad story entitled: The Sad Story of Softbank’s Aldebaran Robotics and its Emotionally Intelligent Robot.
PEPPER DELAYED:
There appears to have been a lot of spin attempting to explain the delays and executive changes up until today’s official press release about Maisonnier’s departure.
For example, according to Tech-In-Asia, an Indonesian-based tech portal for all of Asia, Softbank received far more pre-orders from developers than expected and consequently wants to focus on meeting those developers needs so that by the summer there will be many more applications for Pepper. Pepper is also scheduled to go on sale at Sprint stores in the US this summer at a price to be announced. In Japan, the selling price is 198,000 yen which converts to $1,670.
Many financial analysts got spun too and took fragments of SoftBank CEO Masayoshi Son’s fiscal year recap to suggest that delays might also involve the recently announced collaboration between Softbank and IBM’s cognitive computer system called Watson. Masayoshi Son said:
“[Regarding the] collaborative project with Watson and Pepper, we have started discussions with IBM, actually we have started testing. Watson and Pepper will make an interesting combination. AI will be enhanced further by combining the advanced technologies of [both].”
The Associated Press reported that SoftBank announced that it will incorporate artificial intelligence technology from IBM into its empathetic robot Pepper.
The AI engine “Watson” is already used in health care, travel and insurance services in English, but an adaptation was needed to make it work and think in Japanese, said Steve Gold, Vice President, IBM Watson Group. Unlike other cognitive technology that responds rather mechanically, Watson can learn over time like a human brain, and understands the concept of probability, which makes it sophisticated and more human-like for applications such as Pepper, according to IBM.
It’s also been reported by SoftBank that some Pepper robots will be sold this month but only to software developers who have reserved a robot. Consumers won’t be able to get a robot until sometime between June and August. Details of the sales plan were still undecided, and an announcement will be made later, Son said.
No mention was made regarding the Romeo project or the continuation of Nao robots and support of the Nao community – a community wrapped around the 7,000+ NAOs currently being used for STEM development, academic research and education around the world. SoftBank has a $100 million investment in Aldebaran and will hopefully find a way to perpetuate the company, the NAO community and Aldebaran’s line of robot products.",https://www.therobotreport.com/pepper-delayed-until-summer-top-execs-leave/,[[0.09501799]]
PLM This Week: PTC Strengthens ThingWorx with Augmented Reality Acquisition,"PTC Strengthens ThingWorx with Augmented Reality Acquisition
PTC continues to build the capabilities of its IoT (Internet of Things) platform. With this week's announcement that the company is set to acquire augmented reality (AR) platform developer Vuforia from Qualcomm for $65 million, PTC makes it clear that it will keep investing into its ThingWorx platform.
The acquired solution, called Vuforia, is a platform for mobile vision that makes it possible for applications to ""see"" and connect digital experiences into the physical world.
Vuforia is is supported by a global ecosystem of developers in 130 countries. As of today, nearly 20,000 apps with an estimated 200 million users are equipped with Vuforia’s AR capabilities. With this information at hand, it’s not hard to see why PTC would want a piece of the pie.
PTC’s CEO, Jim Heppelmann, aims to combine Vuforia and PTC to meet two important technology trends: the Internet of Things (IoT) and augmented reality (AR). By linking the solutions, he believes it will be possible to create a type of product where digital and physical realities merge.
“Because of what IoT is enabling, more and more products are now a mixture of digital and physical content. So naturally the ways in which we interact with these products will evolve toward a mixed-reality model that blends physical and digital interactions,” said Jim Heppelmann.
Since PTC announced the acquisition of ThingWorx almost two years ago, the company has spent close to half a billion dollars on technologies related to the Internet of Things, including ThingWorx ($112 million), Axeda ($170 million) and ColdLight ($105 million). That’s over $450 million, including the $65 million it is now paying for Vuforia.
PTC’s plan is to integrate Vuforia with the company’s IoT platform (ThingWorx) and analytics platform (Coldlight) to both find new ways to create products, and find new innovative solutions in terms of how to monitor, control and create operational information that optimizes functionality.
Exactly what that entails is hard to tell today. But PTC did give a sneak peek of what the technology might be used for as a part of its Digital Twin presentation at the LiveWorx 15 event that was held in Boston in May. Here’s a link to the presentation. ENGINEERING.com’s Kyle Maxey has also written on this topic.
BAE Systems Selects Aras
Earlier this week, PLM developer Aras announced that BAE Systems Sweden, a leading manufacturer of weapons systems and military vehicles, has selected Aras Innovator as its new common PLM platform.
BAE Systems Sweden is perhaps best known for producing the combat vehicle CV 90.
Danish Aras Partner Minerva will conduct the implementation and data migration from the two legacy PDM systems using a multi-phase approach.
Phase one will include Aras solutions for configuration management, Bill of Materials (BOM) and document/CAD management, enterprise reporting and searching, and secure social, as well as integrations to multiple MCAD and ECAD systems, SAP and IFS ERP, and Eurostep’s Share-A-Space data repository.
According to Aras, the decision was made after an extensive evaluation of the five major PLM systems on the market, and based on four criteria: depth and breadth of functionality, flexibility and ease of use, TCO and implementation partner competence.
Is Subscription a Good Deal for Autodesk’s Resellers?
Ever since Autodesk started talking about the cloud, the company’s partners and resellers have had one burning question: How will Autodesk’s transition from the traditional licensing model to a subscription model, mainly based on cloud and rental/subscriptions, affect the bottom line? Quite a bit initially, according to Cad-Q, one of Europe’s largest Autodesk resellers.
According to the company’s latest quarterly report, the underlying volume of business does not change, but the transition will initially provide a negative impact on the reported net sales, earnings and cash flow. The change comes from the fact that licenses are recognized when they are sold as compared to a subscription model that recognizes revenue as the software is used.
To combat this, Cad-Q will increase sales of their own products and services and adapt the organization by implementing cost savings. Cad-Q’s assessment is that earnings in 2016 are negatively affected by approximately SEK 15 million (approx $2 million). The company expects that earnings from Autodesk products will reach previous levels by the 2019 fiscal year.
However, this is not taking into account the dynamic effects the subscription model might have, according to Staffan Hanstorp, president and CEO of Cad-Q’s parent company, Addnode Group.
“The transition to a subscription-based business model for Autodesk Software means that we can reach more customers and build up an even larger share of recurring and predictable revenue streams,” says Hanstorp.
IBM or HCL to Acquire Volvo IT
The fight for the ownership of Volvo IT will be between IBM and Indian HCL. There has been quite a bit of speculation about who would buy the Swedish IT company, which has been for sale for some time.
But, according to Swedish tech publication Computer Sweden, the parties have reached a final position where both IBM and HCL have submitted their respective declarations of intent.
The final decision is expected to be made during October and to be finalized at the end of the year.
The main attraction is Volvo IT's customer base with companies like Volvo Cars, Volvo Group, H&M and Stockholm City.
For IBM the deal would, among other things, secure the company’s mainframe operations in Northern Europe. The fact that IBM traditionally has been strong in IT solutions related to the automotive industry should also be seen as a plus.
For Indian HCL, the acquisition would be important for the company’s Nordic initiative, and provide a much heavier presence in the Nordic market.
The company has some dealings with giants like Ikea and Astrazeneca, but the company’s largest Nordic customer, the oil company Statoil, is currently struggling with major issues in the troubled Norwegian oil economy.
About the Author
Felix Nilsson is PLM editor at VerkstadsForum, who works with both printed and online media. He also works as a reporter for PLM TV News.",https://www.engineering.com/PLMERP/ArticleID/10827/PLM-This-Week-PTC-Strengthens-ThingWorx-with-Augmented-Reality-Acquisition.aspx,[[0.09458494]]
Revolutionising manufacturing with artificial intelligence,"Artificial intelligence is the technology to transcend them all. It is set to transform design, manufacturing and after-market phases through the entire product life-cycle.
The time is right for manufacturing leaders to commit to AI beyond pilots and proof of concepts, and take full advantage of its promise to revolutionise their people, processes and machines.
Eight out of ten (84%) senior manufacturing executives believe that digital technologies like artificial intelligence will drive innovation in design development and manufacturing processes, according to The Manufacturer’s Annual Manufacturing Report 2019.
It is clear that business leaders know the value of artificial intelligence, but are they moving fast enough to introduce it?
This formed the core of the latest in The Manufacturer Director’s Forum series of events. First, a group of manufacturing executives toured Factory 2050 — part of the Advanced Manufacturing Research Centre (AMRC) in Sheffield — before sitting down over dinner, co-hosted with IBM, to discuss the issue in-depth.
The executives, representing a broad cross-section of businesses, spent the evening discussing AI use cases, what they had seen at Factory 2050, and the possible applications of artificial intelligence in their businesses.
Sharpening the manufacturing edge with AI
The evening kicked off with Henry Anson, Managing Director of Hennik Group – publishers of The Manufacturer, discussing the importance of Factory 2050, a centre that produces the answers to many of the manufacturing sector’s problems.
“It is a hub for cutting-edge innovation, and from the tour today it is clear that there are many opportunities artificial intelligence can offer the manufacturing industry.”
From retrofitted legacy equipment with sensors and advanced software to match 21st century manufacturing demands, to precise visual recognition tools that could aid medical professionals, Factory 2050 is a showcase which proves Industry 4.0 (and beyond) can be accessed by businesses of all sizes.
Sam Turner, CTO at the High Value Manufacturing Catapult, of which the AMRC is a part, continued the conversation by adding, “The integration of artificial intelligence into manufacturing will continue to accelerate. I think we will see a bigger role for AI in manufacturing design and in getting greater insights from the products already in operation.
“This is crucial in terms of product quality and in design stages. The first question to ask now is how accessible is AI to businesses like yours, and how accessible are the things you have seen today at Factory 2050?”
One delegate said, “There were many practical examples from today of technology from improving quality inspection to boosting workforce efficiency through AI-powered assistants. But we are running at 100mph to keep ourselves profitable and people are almost nervous to stop at times, I am interested to understand how we can make that AI engagement step change smoothly.”
Proving the value of artificial intelligence
A key issue discussed at the dinner was that making the business case for technology adoption remains a long-standing obstacle. And that even if the business case is accepted, and a pilot validates the value-add, projects regularly stay on the shelf.
“Often pilots are tested and advantages are proved, but concepts still aren’t taken through to scaled deployment,” Andrew Tyler, Industrial Director at IBM, said. “What are the barriers to that? It could be something to do with manufacturing firms’ ability to absorb change.”
A senior executive at a global packaging company commented, “It is not just getting the cash, it is the resources too, to get people to spend the time to experiment and prove these concepts. I think it is my job to fight across the company to say, ‘look we need to do these things and actually implement them.’”
Sam Turner added, “The application of AI has started to progress to a practical level. What has become apparent is that in order to facilitate adoption of AI on the shopfloor, the insights from the data need to be made more accessible to the workers. That’s why the cognitive wrapper which allows conversation with the AI systems through chatbots and digital assistants are so powerful.”
The importance of all that data
The proliferation of data became a topic that resonated with the manufacturers around the table: the increasing volume, variety and aggregation of data and the challenge of knowing exactly how to exploit it.
“We seem to want to do something with the data but aren’t sure what. It is important to understand the objective and where the tangible benefit is. We can get data, but it’s what we want to do with it that counts,” one guest said.
This was confirmed by another delegate who added, “As an industry, I am not sure manufacturers understand the value of data, or the power of it. My concern, when we are talking about AI and data, is what’s practical on the shop floor? You can drown yourself in too much data, so it must deliver a real benefit.”
One use of data and artificial intelligence is in predictive maintenance. If manufacturers can track machine failures, and the conditions that cause them, by looking at the data, then they can become better at predictive maintenance, reduce downtime and increase profits.
On this note, a director at an industrial machinery manufacturer said, “How do we start to track those near misses, how do we start to understand those elements in a meaningful way, and then how do we deploy it to the shop floor so we minimise the friction of its adoption?”
Pilot purgatory to scaled deployment
The crucial question around the table remained: are the rich technologies in use at Factory 2050 and the benefits of adoption highlighted by the evening’s discussion within the grasp of all manufacturers?
“Absolutely, there are applications and ideas that could be used in the firm I work at,” one delegate said. “The biggest barrier seems to be justifying it within our firms, to prove the value of these technologies and then actually implementing them.”
Sam Turner added, “I think there are relevant artificial intelligence applications for every manufacturer around the table; design, maintenance and quality inspection, and for small and large volume production.”
IBM’s Andrew Tyler rounded off the evening by saying, “The discussions today have confirmed that AI offers manufacturing huge opportunities, but we have to focus on a solution to how we move from pilot activity to scaled deployment that delivers the value from these technologies that we know are possible.
“Data is a very important facet for being able to take advantage of AI, especially considering its variety, velocity, volume and veracity coming off shopfloor machines.
“However, it is also about so much more than data. To truly embrace AI, manufacturers need to be prepared for a transformation encompassing their people, processes and machines. And if they’re willing to commit themselves to this journey with the right partners, they have a better chance of realising the huge potential from AI and cognitive technologies.”
Supercharge your AI data pipeline with IBM Spectrum Storage
The success of artificial intelligence depends on the ability to transform data into accurate models and insights with speed and efficiency. Address every stage of the AI data pipeline from ingest to insight with IBM.",https://www.themanufacturer.com/articles/revolutionising-manufacturing-artificial-intelligence/,[[0.09427035]]
What will manufacturers make of tech in 2018?,"technology
UK Manufacturing is enjoying its largest expansion in 10 years. The manufacturers' organisation EEF sees output and export growth continuing through 2018 thanks to a strong global economy and a weak pound following the Brexit referendum. Manufacturing has been a forerunner in the digital revolution and, to ride this wave of opportunity, organisations must continue to innovate. The challenge that many face is applying new technologies to their business and exploiting the rapidly increasing amounts of data. As part of its Industrial Strategy, the government published 4 Grand Challenges in November 2017, focused on the global trends which will transform our future. First on the list is “growing the Artificial Intelligence and data driven economy”. We consider how AI, along with the digital twin model and edge computing will play a more dominant role in manufacturing this year, and expand into the sectors where they are not yet exploited.
Digital twins
The digital twin model will revolutionise how high value assets are designed, developed and maintained. This is the process whereby something that exists within the physical world is mapped out in the virtual world - an exact digital replica, which provides a number of benefits when building high value capital assets. Even at the very start of a project, engineers can use digital twins to run models to map out any potential obstacles before any physical work has begun. The technology also facilitates real-time analytics which can markedly improve operational maintenance and, combined with AI, predictive maintenance.
Take the airline industry; engineers can test virtual models of planes to predict when parts will start to malfunction. Anticipating problems with the planes means airline companies can swap out parts in advance and minimise the ground time of the fleet. This is crucial to airline profits given that every minute a plane is on the ground, it loses money. With the most basic commercial airplanes selling upward of $82m or leasing for around $375,000 a month, they need to be commercially flying to make the investment pay off.
It’s an indication of the potential of the technology that companies such as General Electric (GE) are using digital twins to get a holistic picture of major developments such as wind farms. Its engineers can monitor and control the turbines, predict power output, and adjust settings accordingly. And it isn’t just manufacturing where we’ll see this model making waves in 2018. A recent survey found 75% of executives across a broad range of industries planned to incorporate this technology into their operations within the next few years.
Edge Computing
We’ll also see greater adoption of computing at the edge of a network where data is processed closer to the point where it is produced, typically by internet of things (IoT) devices, avoiding long distance data communications. Computing at the edge lets organisations analyse important data in near real-time and facilitates faster processing for the explosion of data that will define the tech sector in 2018.
There will be a continuation of the move towards the edge of the network for corporate computing with the proliferation of smaller data centres across the world. The move will be prompted by the ever-growing need of businesses to ensure data is processed in line with end-user management and security requirements. Large automotive manufacturers need suppliers across the world to send and receive computer-aided design (CAD) files, which are likely to be sizeable and full of sensitive information. A focus on edge computing will not only reduce the latency when these files are transferred, but also ensure data security is sufficient on the supplier’s side to protect this information.
Artificial intelligence
AI – by no means a new concept, but one whose potential is finally being put into action - is set to shake-up the factory floor by making industrial robots safer and able to perform more tasks.
Specifically, two of the ways AI will make further inroads into manufacturing are:
Adaptive manufacturing
Adaptive manufacturing incorporates AI into the factory line to overcome the inflexible nature of industrial robots. These robots are designed to perform repetitive tasks, and re-programming them to do other tasks is time-consuming. Adaptive manufacturing gives robots the ability to learn routines from human workers and work alongside them, eliminating the downtime required for re-programming.
Automated quality control
The need for speed on a production line comes at the expense of errors and a decline in the quality of output. But, automated quality control removes the need to compromise. Better monitoring can be brought in to spot errors more quickly. For example Instrumental.ai uses cameras powered by computer vision algorithms to spot anomalies on the production line and identify the cause of the failure. This means staff can resolve the issue quickly, rather than spending hours trying to figure out the problem.
What this means for the future
We’ll come to see these technologies incorporated into manufacturing projects right from the beginning. As it stands, technologies such as AI are currently being retrofitted onto planes, power stations and other pre-existing assets. New versions of these assets will be equipped with advanced tech right from the get go helping to improve efficiency right across the manufacturing industry. And it’ll mean more data to store and process: something manufacturers will have to think about before making any changes to their proven IT systems.",https://www.manufacturingglobal.com/technology/what-will-manufacturers-make-tech-2018,[[0.09338969]]
Stanford Medical Innovation Conference Focuses on Robotics,"Changing roles for the surgeon; black boxes, automated scrub nurses – these and other ideas were presented at the Stanford Medical Innovation Conference on Medical Robotics Saturday, at Stanford University.
Presenters from business, research labs and venture capital firms.
Other medical information making the news:
Steadily improving medical software developed by IBM to help Mayo Clinic improve detection of aneurysms, Fortune Magazine.
Cellular carriers are jumping into the remote-healthcare marketplace where body parts make phone calls, BusinessWeek Magazine.",https://www.therobotreport.com/stanford-medical-innovation-conference-focuses-on-robotics/,[[0.09203032]]
A new type of hybrid colloidal quantum dot/organic solar cells,"Solution-processed semiconductors, including materials such as perovskites and quantum dots (i.e., small particles of matter in the quantum size regime), are substances with a conductivity ranging between that of insulators and that of most metal. This type of semiconductors has been found to be particularly promising for the development of new optoelectronic devices that perform well and have low manufacturing costs.
Recently, some studies have highlighted the advantages of fabricating semiconductors by combining colloidal quantum dots (CQDs), nanoparticles that can harvest infrared photons, and organic chromophores, parts of a molecule that absorb visible light photons and give color to the molecule. Nonetheless, so far, hybrid photovoltaic based on CQDs and chromophores have only achieved power conversion efficiencies (PCEs) below 10 percent due to a chemical mismatch between different components and challenges in enabling charge collection.
Researchers at the University of Toronto and KAIST in South Korea have recently developed a hybrid architecture that overcomes these limitations by introducing small molecules into a CQD/organic stacked structure. The hybrid solar cells they created, presented in a paper published in Nature Energy, achieved remarkable PCEs that are retained even after long periods of continuous operation.
""The first challenge of this study was to combine the advantages of the broad photo-absorbing band of CQDs and the strong (but narrower) absorption coefficient of organic molecules to create a higher performance photovoltaic platform,"" Se-Woong Baek, one of the researchers who carried out the study, told TechXplore.
The researchers drew inspiration from a study carried out by a research team at Berkeley National Laboratory almost two decades ago, which demonstrated the potential of using semiconductor nanorods and polymers to fabricate hybrid solar cells. While the team at Berkeley Lab and several others tried to combine organic molecules with CQDs, Baek and his colleagues felt that this was difficult to achieve, as device performances achieved by their hybrid architectures were lower than typical organic or CQD-only semiconductors. Thus, they set out to investigate the potential of CQD/organic semiconductors further, trying to overcome the limitations of previously developed architectures.
For solar cells to perform well, they should be able to maximize light absorption and efficiently convert it into electrical current. The hybrid solar cells developed by Baek and his colleagues have a small molecule bridge that complements CQD absorption, which in turn creates an excitor cascade with the host polymer. This results in a more efficient energy transfer than that observed in other hybrid architectures.
""The structure we developed can achieve high light harvesting efficiency via an additional organic layer, which has a strong absorption coefficient at its backside and a primary broadband absorption by CQD near its front side,"" Baek explained. ""The strongest advantage of the resulting solar cells is that they allow us to program the photo-response of CQD by resizing and combining it with suitable organic molecules.""
The unique structure of the solar cells developed by Baek and his colleagues allows for greater degrees of freedom in programming their functions compared to other types of hybrid solar cells. In addition, it allows the solar cells to maintain good efficiency over longer periods of continuous operation.
""Many previous studies have reported broad and high absorbance through a combination of CQD and polymers, but their performance was less efficient due to the low charge extraction efficiency,"" Baek said. ""By introducing the third component, a small molecule bridge, into CQD/polymer hybrid heterostructure, we revealed an underlying mechanism that facilitates charge extraction as well as absorption, thereby improving PCEs.""
In the future, these solar cells could be used to fabricate photovoltaic panels that use both quantum dots and chromophores, but that achieve higher efficiencies than those observed in previously developed hybrid architectures. So far, the CQD-organic structure they proposed has an absorption band up to 1100 nanometers. In their next studies, they would thus like to adapt the structure or develop alternative hybrid architectures to achieve broader absorption bands.
""Eventually, this structure could be combined with actually high band-gap perovskite solar cells, for example, by designing a rear-cell platform as a tandem structure that can reinforce the absorption of the near-infrared band, where perovskite does not absorb,"" Baek said. ""Theoretically, an efficiency of 15 percent can be added to the perovskite solar cell when we combine our hybrid structure as a rear-cell of tandem structure.""
More information: Se-Woong Baek et al. Efficient hybrid colloidal quantum dot/organic solar cells mediated by near-infrared sensitizing small molecules, Nature Energy (2019). DOI: 10.1038/s41560-019-0492-1
W. U. Huynh. Hybrid Nanorod-Polymer Solar Cells, Science (2002). DOI: 10.1126/science.1069156
© 2019 Science X Network",https://techxplore.com/news/2019-11-hybrid-colloidal-quantum-dotorganic-solar.html,[[0.09197915]]
Industrial Internet Consortium and OpenFog Consortium Join Forces,"The hype surrounding the Industrial Internet of Things (IIoT) continues to grow and shows no signs of slowing, and rightfully so. With the promise of reduced operating and maintenance costs, improved quality control and customer service, more efficient manufacturing work flows, and not to mention the potential for brand new data-based revenue streams, it’s easy to see why. All of this is possible due to the network of physical objects and devices around the world that are connected to the internet and specifically meant to collect and share data.
While the Internet of Things (IoT) and the Industrial Internet of Things (IIoT) have been buzzwords for a while now, fog and edge computing are two newer terms on the scene. While they may be newer, they are equally important in terms of how IIoT promises to shape how data is collected, shared and analyzed moving forward. In fact, fog and edge computing are so integral to the development of IIoT that consortiums have been formed to aid in that development process.
The Industrial Internet Consortium and OpenFog are two of those consortiums. Both were founded with the goal of accelerating the growth and adoption of IIoT. The Industrial Internet Consortium was founded to bring together the organizations and technologies necessary to accelerate the growth of the Industrial Internet by identifying, assembling and promoting best practices. OpenFog was founded to accelerate the adoption of fog computing and address bandwidth, latency and communications challenges associated with IoT, 5G and AI applications.
Now IIoT can fully enjoy the best of both worlds. In December 2018, the Industrial Internet Consortium and OpenFog announced that they have agreed in principle to combine the two largest and most influential international consortia in Industrial IoT, fog and edge computing. This partnership promises to aid the growth of IIoT by helping to develop and promote industry guidance and best practices for fog and edge computing.
“This is great news for the industry. Both organizations have been advancing the IIoT, fog and edge computing, and their members represent the best and the brightest in their fields. It makes sense to merge their expertise and work streams to continue providing the IIoT, fog and edge guidance that the industry needs,” said Christian Renaud, Research Vice President, Internet of Things, 451 Research.
“We’re excited by the growth and advancement of fog technologies—from a technology, standards and general awareness standpoint—since our launch nearly three years ago,” said Matt Vasey, OpenFog chairman and president, and director, AI and IoT business development, Microsoft. “During that time, it has increasingly become apparent that we share so much synergy with the efforts of the IIC that it just made sense to bring the two consortia together. The resulting combination of memberships, resources and shared knowledge will only further the growth of the technologies, including fog, that will support IIoT ecosystems.”
This new partnership will bring wide-reaching benefits to those that are currently utilizing or hope to utilize IIoT. Their promotion and industry guidance for fog and edge computing, as well as the IIoT overall, means that the companies that utilize this partnership will learn how to harness the collection, sharing and analyzing of data, and also that IIoT is not just hype—it’s smart business.",https://www.engineering.com/AdvancedManufacturing/ArticleID/18431/Industrial-Internet-Consortium-and-OpenFog-Consortium-Join-Forces.aspx,[[0.09024978]]
"Microsoft to Build Artificial Intelligence into Every Product, Service it Offers","Devices like smart surveillance cameras, smartphones, or factory floor machines were referred to as ""edge computing,"" with the coordination of cloud power and intelligent edge devices improving productivity and safety on the ground.
Microsoft on May 10 unveiled new tools intended to democratize artificial intelligence by enabling machine smarts to be built into software from smartphone games to factory floors.
The technology titan opened its annual Build Conference by highlighting programs with artificial intelligence that could tap into services in the internet ""cloud"" and even take advantage of computing power in nearby machines.
""We are infusing AI into every product and service we offer,"" said Microsoft executive vice president of artificial intelligence and research Harry Shum.
""We've been creating the building blocks for the current wave of AI breakthroughs for more than two decades.""
Microsoft research has gone deep into areas such as machine learning, speech recognition, and enabling machines to recognize what they ""see.""
""Now, we're in the unique position of being able to use those decades of research breakthroughs,"" Shum said.
Microsoft rivals including Amazon, Apple, Google and IBM have all been aggressively pursuing the promise and potential of artificial intelligence.
Artificial intelligence is getting a foothold in people's homes, with personal assistants answering questions and controlling connected devices such as appliances or light bulbs.
Digital assistants already boast features such as reminding people of appointments entered into calendars and chiming in with advice to set out early if traffic is challenging.
Steering away from '1984'
Microsoft chief executive Satya Nadella, who opened the Seattle conference, also highlighted the need to build trust in technology, saying new applications must avoid the dystopian futures feared by some.
Nadella's presentation included images from George Orwell’s ""1984"" and Aldous Huxley's ""Brave New World"" to underscore the issue of responsibility of those creating new technologies.
""What Orwell prophesied in '1984,' where technology was being used to monitor, control, dictate, or what Huxley imagined we may do just by distracting ourselves without any meaning or purpose,"" Nadella said.
""Neither of these futures is something that we want... The future of computing is going to be defined by the choices that you as developers make and the impact of those choices on the world.""
Microsoft's aim on May 10 was on businesses and software developers, whether they be students building a fun app or professional technology teams.
""Microsoft is trying to use AI for businesses to solve business problems and app developers to make applications better,"" said Moor Insights and Strategy principal analyst Patrick Moorhead.
""Which is different from Amazon, Facebook, and Google whose primary business model is to mine personal information using AI to sell you things or put ads in front of you.""
Microsoft is taking a unique approach by letting developers customize gesture commands, voice recognition and more instead of making them conform to settings in ""off-the-shelf"" AI, according to the analyst.
Microsoft executives used demonstrations to provide a glimpse into a near future in which artificial intelligence hosted online works with internet linked devices such as construction site cameras to alert workers of dangers, available tools, or unauthorized activities.
Devices like smart surveillance cameras, smartphones, or factory floor machines were referred to as ""edge computing,"" with the coordination of cloud power and intelligent edge devices improving productivity and safety on the ground.
Windows Numbers Rise
Nadella also told developers that some 500 million devices now run on Microsoft's latest Windows 10 operating system, creating a huge audience for their software creations.
Microsoft's online Office 365 service has some 100 million commercial users monthly, while Cortana digital assistant is used by 140 million people monthly, according to the Redmond, Washington-based technology firm.
""The future is a smart cloud,"" Nadella said, forecasting a future in which mobile devices take back seats to digital assistants hosted in the cloud that follow people from device to device.
""It is a pretty amazing world you can create using intelligent cloud and intelligent edge.""
By Glenn Chapman
Copyright Agence France-Presse, 2017",https://www.industryweek.com/technology-and-iiot/article/22016113/microsoft-to-build-artificial-intelligence-into-every-product-service-it-offers,[[0.08963533]]
Why It's Not Too Late to Build Your Own Industrial Internet Platform,"Over the past three years, the emergence of the Industrial Internet of Things (IIoT) has led to an outpouring of technological cooperation, as more than 350 firms have joined various consortia to hammer out standards around open digital platforms. Yet this leaves industrial companies in an uncertain competitive position in terms of creating and capturing value for themselves. With the industrial internet accounting for nearly $800 billion in commerce last year and growing to a multi-trillion dollar opportunity over the next decade, companies don’t just need to cooperate: they need to focus on forging a digital platform strategy that generates growth.
Indeed, while these digital networks are meant to be “open,” there is also great advantage in being the provider of the platform. The Industrial Internet Consortium, for instance, counts Bosch, GE, Intel, IBM, SAP, and Schneider Electric among founding members working to assure that different equipment can share data for energy, health care, manufacturing, transportation, and smart cities applications. While the rise of Industrial Internet platforms does not mean every company must build one, every company must have a strategy for how to remain relevant to their customers.
For a prime example of a company doing both, we need to look no further than General Electric, whose turbines generate 300 data points per second (see image). If GE increases fuel efficiency 1% in its jet engines by analyzing data from embedded sensors, airline industry profits could increase by $3 billion.
At the same time it is providing those kinds of benefits for those who plug into its Predix operating system, GE’s digital industrial business generated about $7 billion in revenue last year and is on track to reach $15 billion by 2020. That is good for GE, but the question for other firms is clear: is there still an opportunity to build your own digital platform, even on a smaller scale, or is the best strategy to simply plug your equipment in and cooperate?
What is your digital platform strategy?
The challenge for companies that want to capture new value is that industrial applications often exist in a ‘systems of systems.’ That is, there are many systems and subsystems from different manufacturers that need to work together. This requires coordination. ‘Platforms’ are a type of solution that enables different systems and stakeholders to coordinate all the various inputs and outputs—and to provide developers the ability to build vertical software applications that are used by end users (see figure 1).
As the central clearinghouse, the company that owns and manages the platform is well positioned to capture a significant portion of the value. Dozens of companies have launched IoT platforms targeting industrial applications, with analysts expecting this new capability to add $14.2 trillion to cumulative global GDP by 2030. According to Forrester Research, 60% of decision-makers at global enterprises are using or planning to use IoT-enabled applications over the next two years.” Gartner has suggested that two thirds of industrial enterprises will be doing so with an IIoT Platform by 2020.
We suggest that there are two types of Industrial Internet systems: broad platforms like GE’s and niche platforms that serve specific industries or applications. To determine where you are best able to play, it helps to begin with a common understanding: First, building an IIoT platform is not cheap. It requires a significant and sustained investment to build infrastructure to develop capabilities required to sustain the platform, and to fund customer acquisition activities. Second, building an IIoT platform is very different from making, say, a jet engine. Industrials considering playing in these new areas will need new strategies, business models, and organizational structures to succeed. IIoT platforms have the potential to widen a company’s competitive landscape while also provide a source of future growth.
To achieve the optimal IIoT platform strategy we believe it is fruitful to study the recent history of platforms, which yield these five lessons:
Lesson #1: Outside hires and agile development cycles are required to deliver constant iteration.
Most industrial businesses have long development cycles that require focused development activities with incremental changes spanning years and sometimes decades. Like most digital opportunities, IIoT platforms entail dramatically shorter, faster development cycles. Whether you’re considering a broad or a niche platform, many industrial companies will need to fundamentally revisit their internal development process and talent base.
Here we can learn from the cloud computing space, where competitors seek differentiation by constantly adding new features. Recently, Google Cloud has added artificial intelligence and data analysis. The IBM Cloud has focused on tailoring vertical solutions for different markets. Amazon Web Services added 1,000 distinct features in 2016. In all these cases, agile development is core to those cultures.
Constant iteration is necessary for several reasons including staying competitive, increasing revenue from existing customers, and creating features targeted at niches. For example, AWS targeted government customers by adding Criminal Justice Information Services compliance and by launching a “GovCloud” with security for government use.
Most industrials presently lack the ability to ship hundreds of features per year, so this means a new agile software capability must be built. Agile development is an iterative approach to building software that accelerates the delivery of finished projects. Many industrial companies, including John Deere, have moved their existing software groups to an agile workflow and seen delivery timelines drop by 92%. In addition to agile many industrial companies are pursuing what is known as bimodal IT. According to Gartner, bimodal refers to the practice of managing two separate IT work styles. One group is focused on predictable, well understood legacy products. While a second group explores new problems in a fast-moving, assumption driven manner.
Strategic acquisitions are one way to rapidly build an agile software capability. Bosch used a technology acquisition to form its Intelligent Solutions Group which has since developed an IIoT platform.
But for most industrials, achieving agile development or bimodal IT to build a viable IIoT platform requires consistent hiring of outside talent. GE CEO Jeffrey Immelt has said that GE never made progress in digital “until we brought people in from outside.” Despite employing over 10,000 software developers, GE still chose to initially staff its software center of excellence with 98% outside hires. To attract talent, GE has located offices near software hubs, which included moving its headquarters from Connecticut to Boston. In doing so, GE also changed compensation packages and launched advertising campaigns focused on the potential impact GE’s work can have.
Lesson #2: Leveraging B2B relationships are essential for incumbents to gain a fast foothold.
When discussing market entry strategies, many players focus on technology development strategies and ignore the human side of IoT. Incumbents with customer relationships have multiple advantages that new entrants will lack in this regard. First, existing relationships provide a source of first mover advantage and serve as potential platform validators. GE has relied on existing customers to serve as validation stories for its Predix platform. Second, customer trust built over time will help incumbents address customer’s top concerns around security and compliance.
The same lesson is reinforced in the cloud computing environment. More than a decade into the cloud revolution, many large enterprises are still in the early stages of adopting a cloud computing platform. But the transition is quickening; a 2015 study found that 77% of companies primarily used traditional on premise data centers for at least one workload, but that by 2018 the percentage will drop to 43%. The shift is being driven by cost savings, decreased time to market, and the quality of cloud systems. This lag has provides incumbents that can leverage a sense of trust to address concerns around security and compliance with an opportunity to catch up to early entrants.
That’s because a minimum viable platform needs a significant customer base to be financially sustainable. For example, Johnson Controls shuttered its Panoptix platform after failing to attract enough interest to justify development costs. Thus, IIoT platform operators should focus on attracting customers, knowing that the lifetime value will be high. Google recently used incentives to help provide capacity to host the Spotify music service and even Apple’s own iCloud platform. Customer acquisition in the early stages of the industry lifecycle is crucial for the platform to gain critical mass in the long term.
Lesson #3: Niche platforms can differentiate by focusing on critical customer-job-circumstance combinations
Even if your organization can’t sustain the investment and operational speed that is required to grow a broad-based IIoT platform, smaller companies can win by focusing on narrower customer jobs, or problems that crop up in specific circumstances. This requires a more targeted feature set, which are not sufficiently addressed by the broad IIoT platforms.
A good way to start is with a simple mapping of jobs, or needs, addressable by IIoT versus the circumstances that specific customers may encounter. This map can allow you to understand where general platforms compete and highlight opportunities where your unique capabilities and knowledge can provide an advantage.
SKF Group, the Sweden-based leader in the ball bearing systems industry, has developed IIoT solutions designed to increase the performance of its products. SKF Insight provides real time updates to customers alerting them to when conditions such as temperature or lubrication levels may cause a system to fail. SKF Insight is able to provide this service by collecting data generated by tiny sensors embedded in bearings that are powered by kinetic energy generated by the motion of the bearings. Preventing bearing failures is an important job many SKF customers have. Replacing the main bearing on a wind turbine is so costly that doing so can undermine the business case for building the turbine.
Companies have also found success partnering with established IIoT platforms. Pitney Bowes, a leader in the mailing equipment industry, has been forced by a long-term decline in mail volume to transform itself. To fortify its legacy mailing equipment business the company has partnered with GE’s IIoT platform, Predix, to develop a suite of software tools for its equipment. These tools are available to customers as a paid subscription. Seeking new growth, the company has leveraged its experience in the mailing industry to simplify the international shipping process for retailers. Pitney Bowes has pursued a conservative IIoT strategy for its legacy business while pursuing new growth opportunities enabled by digital.
In creating nice platforms and partnering, SKF and Pitney have both been successful decreasing downtime—a priority job for many industrial customers.
Lesson #4: Platform operators should build core features and when possible allow partners to provide supporting features.
Regardless of the scope of an industrial IIoT platform, industrial companies should look to partners to provide basic IIoT platform functionality. For example, Apple famously built Apple Maps because of the increasing importance of mapping to mobile platforms. Mapping was becoming a differentiating feature that Apple risked losing control of unless an internal capability was developed. Yet Apple still partners with third parties to provide weather and stock data for their mobile platform. Weather and stock data are basic features that customers expect but not features upon which they base their purchasing decisions.
Another example can again be seen in the cloud computing industry where basic computing and storage has become a basic feature expected by customers. Prices for these features have fallen over time, partly driven by Moore’s law and partly by the willingness of competitors to sell basic computing at prices that allow little margin.
This trend suggests to industrial IIoT platform managers that these features may be best provided through a partner. Digital leaders have already recognized this insight and begun partnering with Microsoft’s Azure, AWS, and others to host their IIoT platforms on established cloud computing platforms. Similarly, General Electric recently paired with Microsoft to host Predix on Microsoft’s Azure platform. This partnership allows GE to focus resources on building core IIoT features rather than dedicating resources to supporting features.
Lesson #5: Not every company is positioned to build an IIoT platform but every company must develop a strategy to remain relevant.
Few companies are positioned to become broad IIoT platform operators, like GE, IBM or Google. Even smaller, more niche solutions like SKF Insight are not an option for every company.
However, companies that do not pursue IIoT platform strategies must still find ways to remain relevant to customers and to protect against disruption caused by digital.
For instance, Yard Club is a startup seeking to de-link the value construction equipment creates from actually ownership of that equipment. The company allows equipment owners to rent their machines to operators during periods of downtime. Yard Club thus has the potential to significantly reduce the demand for new equipment by increasing the utilization of existing equipment. Rather than ignore this potentially disruptive business model, Caterpillar has invested in the company and has instructed its dealer network to list their rental inventories on the platform. This enables it to add the benefits enabled by another IIoT platform while remaining relevant to its customers.
Second to Caterpillar, in construction equipment sales, Komatsu faces a similar threat. Rather than wait to be disrupted, Komatsu has pursued efforts to create disruptive concepts internally. Komatsu’s Smart Construction unit provides a service that semi-autonomously excavates sites. The service combines drones, remote operators, and Komatsu equipment to accomplish a job that previously required ownership of expensive equipment and significant labor. Selling excavation as a service is a significant departure from selling equipment and could eventually reduce Komatsu’s traditional equipment sales.
Moving forward with your digital strategy
Leaders must identify where their company is positioned in the industry ecosystem to determine the optimal strategic action. Incumbents do not have to be the first mover but waiting too long will make it difficult for a platform to reach viability. This is seen in the cloud space the top five or six platforms, from Google, IBM, Amazon, and Microsoft together control about 60% of a giant market.
A successful IIoT platform will begin by targeting existing customers with differentiated features created through constant iteration funded with sustained investments. Not every company should build a general-purpose IIoT platform; opportunities exist for niche platforms as well as in adjacent areas. To determine an optimal IIoT platform strategy, leaders should assess their existing data portfolio as well as the priority jobs of their target customers. But it’s now becoming vital to settle on your strategy soon, as the cloud platform business shows just how momentum can entrench the strongest digital marketplaces.
Michael Brady is an analyst with growth strategy consulting firm Innosight, where Ned Calder is a partner and Joe Sinfield a senior partner.",https://www.industryweek.com/technology-and-iiot/information-technology/article/22006121/why-its-not-too-late-to-build-your-own-industrial-internet-platform,[[0.08812864]]
5 Technologies Transforming the Defense and Aerospace Industries,"The aerospace and defense industries are at the forefront of innovation, driven by technological advancements just as much as they drive them. A recent report by Frost & Sullivan examines the technologies that are transforming defense and aerospace.
1. Wearables
Getting reliable and up-to-date information on the battlefield is crucial, and being able to monitor a soldier’s condition can prevent avoidable injuries. Both needs can be satisfied via wearables, such as heads-up-displays (HUDs) and smart tattoos that monitor vital signs. Wearables are also useful in the factory, where head-mounted displays and smart glasses can be used in maintenance and assembly applications.
2. Additive Manufacturing
3D printing is becoming ever more ubiquitous in the aerospace industry, where new designs enables lighter and stronger aircraft. Airbus has already begun printing parts using recently approved materials, and the industry will likely see more significant changes as new materials and more efficient methods become available.
3. Specialized Imaging
From autonomous aircraft to Terahertz (THz) imaging, many industries can benefit from advanced visual imaging technology. Whether it’s military or security personnel identifying concealed weapons, or advanced flight systems to assist human or autonomous pilots, the technology is finding its way into a range of applications.
THz imaging also has additional applications in manufacturing, such as non-destructive testing.
4. Better Batteries
Battery technology is always improving, with lithium-ion batteries now a mainstay in electronics after their commercial release in 1991. In addition to powering electric vehicles, these high capacity, mostly reliable batteries are being utilized in defense and aerospace applications as systems backups for a variety of aircraft, including the F-35 fighter and both Boeing and Airbus jets.
5. Cloud Computing
While potential applications in the defense industry range from integrating logistics into wearable tech to analyzing big data from Army installations around the world, it's in aerospace that cloud computing is making the biggest waves.
Aside from the ability to connect every aircraft currently flying, expanding existing satellite systems and GPS or having up to date and relevant flight information, cloud computing can also benefit the intensive simulation work necessary for aerospace design and testing.
The rise of cloud computing and connected technology is also driving developments in cybersecurity, which cuts across both aerospace and defense.
For information on engineering opportunities in cybersecurity, aerospace, defense and other industries, check out our Jobs Page.",https://www.engineering.com/AdvancedManufacturing/ArticleID/13712/5-Technologies-Transforming-the-Defense-and-Aerospace-Industries.aspx,[[0.08520218]]
"LEA walks tall with machine learning, predictive maintenance, and NLP","How Robot Care System uses cloud computing to enhance its LEA smart walker
A walker is a simple tool, designed to provide support and balance for people with ambulatory and balance difficulties. But what if a walker could talk to you, detect falls, and intelligently avoid hazardous obstacles — all while powered by cloud computing? That’s the idea behind Robot Care System’s Lean Empowering Assistant, or LEA.
LEA is a smart walker designed to improve mobility and independence for individuals with diseases like Parkinson’s or who are at risk of falling. Robot Care Systems is now making the second generation of LEA more efficient, smarter, and more powerful, thanks to the tools provided by Amazon Web Services (AWS).
The first generation of LEA featured over 70 sensors and could do things like automatically adjust for balance, call family and friends, encourage exercise, and set medication reminders. As advanced as this device was, it was limited in its computing power. As a result, utilizing machine learning models, predicting maintenance needs, and processing voice commands were far beyond LEA’s onboard computing system’s capacity.
However, these capabilities were high on customers’ wish lists of features. By adopting AWS cloud services and building robotics applications with AWS RoboMaker, Robot Care Systems can now deliver these and other advanced features to customers.
LEA gets smarter with ROS, RoboMaker, and the cloud
AWS RoboMaker works by providing cloud extensions for Robot Operating System (ROS) and allows users to develop, test, simulate, and deploy advanced robotics applications. With RoboMaker, the second-generation LEA will be more intuitive, safer, and more efficient for customers to use.
Adopting cloud computing will allow developers to manage data from all LEA robots for machine-learning model training. This information processing will help increase the scale and speed at which their robots can learn from each other and function better for customers.
In addition, RoboMaker allows Robot Care Systems to create managed robotics simulations, in which developers can test and evaluate how their robots will behave in certain situations. These simulations are conducted virtually via the Web console, thus saving the time, cost, and operational burden of having to physically deploy, test, and capture data from additional robots.
Migrating to cloud computing will help Robot Care Systems grow its current fleet from 100 domestic robots to more than 10,000 across the globe. Also, maintaining robots becomes easier in the cloud. The current state of maintenance operations requires on-site visits by human technicians, but with updated cloud-supported fleet management, the group can receive diagnostic alerts and push out bug fixes and software updates remotely.
Behind the scenes, RoboMaker alone is not powering LEA’s increased computing power. Switching to the AWS cloud opens up the possibilities to incorporate hundreds of other features and services into a robotics application. The next generation of LEA uses other AWS services such as SageMaker, Lex, Polly, and Rekognition to add and test even more features.
Amazon Lex and Polly will be used to test and deploy a natural language processing (NLP) voice interface for LEA, giving the device a new way to interact with users. Meanwhile, SageMaker, a machine learning program, will help Lea better identify risk factors for users by improving movement and behavior detection. AWS RoboMaker opens the door for innovation, with access and compatibility to a variety of innovative AWS services.
Robot Care System is one example of how a company has been able to evolve and enhance its product via cloud computing and AWS RoboMaker, with other companies following suit. Companies are deploying robotic arms, drones, and ground robots in innovative ways every day. As the diversity and sophistication of robot applications expand, these breakthroughs demand a high level of intelligence and autonomy. AWS provides the infrastructure and tools to support such innovation.
Sponsored content by AWS.",https://www.therobotreport.com/how-robot-care-system-uses-cloud-computing-enhance-lea-smart-walker/,[[0.08331855]]
IBM Watson AI XPRIZE announces 10 semifinalist teams,"The XPRIZE Foundation, which designs and runs competitions to “solve humanity’s grand challenges,” has announced the 10 semifinalist teams advancing in the IBM Watson AI XPRIZE. The four-competition is intended to demonstrate how people can collaborate with artificial intelligence to tackle pressing global problems.
Sponsored by IBM Watson, the AI XPRIZE also aims to encourage “better human collaboration with AI to develop creative, innovative, altruistic, and audacious applications that are truly scalable,” stated the foundation.
“AI is key to a prosperous future. AI completely changes how we work, how we communicate, how we conduct research, how we communicate and will eventually integrate itself into every aspect of our lives,” said Amir Banifatemi, general manager for innovation and growth at XPRIZE. “These 10 teams are developing technologies that will completely change the game in their respective fields, and we’re looking forward to seeing these solutions in the field with the hope they will change humanity for the better.”
An independent judging panel evaluated 34 teams across a set of performance categories, including technical performance, real-world impact, future impact, and ethics. These comparison scores were combined by a specially designed AI algorithm to propose a ranking of all teams.
The ranking was presented within an interactive visualization to judges, who then decided on the final list of top 10 teams for the semifinals. The panel included academics and professionals with deep expertise in AI and a variety of application backgrounds, from healthcare and ethics to education.
IBM AI XPRIZE semifinalists
The 10 teams advancing in the competition include the following:
aifred health (Montreal): Developing a system that uses high-quality data about mental health to help physicians work with their patients to choose personalized treatments for depression.
Clean Robotics (Pittsburgh): Developing robotic trash cans that automatically sort waste into the correct waste stream using artificial intelligence, computer vision, and a proprietary sensor system.
Deep Drug (Baton Rouge): Developing computer aided drug design software utilizing AI-based techniques to rapidly identify new drug compounds to address the issues of multi drug-resistance and newly emerging pathogens.
Element Inc. (NYC): Developing a biometric recognition-solution for children under the age of five.
emPrize (Atlanta): Developing virtual tutors for online education that will offer learning assistance through personalized tutoring, answering questions, and providing feedback to students.
Iris.ai (Germany/Norway/Netherlands): Developing technology to improve access to scientific knowledge.
MachineGenes (Queensland, Australia): Focusing on helping people with Type 1 diabetes, including those with “brittle” diabetes, through the use of evolutionary machine learning and advanced AI to recommend the best insulin dosage and keep each individual patient’s blood glucose levels under control.
Marinus Analytics (San Francisco and Pittsburgh): Developing AI solutions that help law enforcement, government, and the private sector identify and combat sex trafficking.
Orbem (Munich, Germany): Developing MRI + AI image classification technology aimed at preventing the unnecessary killing of billions of 1-day-old male chicks, reducing food waste and energy consumption along the way.
Zzapp Malaria (Tel Aviv, Israel): Applying AI in the fight against malaria, by analyzing online databases and satellite data to create intervention strategies for individual communities based on environmental and other conditions.
The three finalists are slated to be announced next month. The IBM Watson AI XPRIZE competition will conclude in April 2020, with three finalists participating in the Grand Prize competition on the TED2020 stage in front of a live in-person and online audience.
A $3 million Grand Prize, $1 million Second Place Prize, and $500,000 Third Place Prize will be awarded to the teams that receive the top scores. Audience voting during TED2020 will determine the final winner.
Other recent XPRIZE challenges involving AI and robotics include the Shell Ocean Discovery XPRIZE and the Rainforest XPRIZE.",https://www.therobotreport.com/ibm-watson-ai-xprize-announces-10-semifinalist-teams/,[[0.08277126]]
10 Tech-Savvy CompaniesHunting for AI/robotics Talent and IP,"Tencent, Alibaba, Baidu and JD.com from China are in a global competition with Google/Alphabet, Apple, Facebook, Walmart and Amazon from the USA and SoftBank from Japan. All are agressively searching for talent, intellectual property, market share, logistics and supply chain technology, and presence all around the world.
These leading tech-savvy companies have many things in common. Foremost, they are all in pursuit of global growth and the funding, technology and talent to propel that growth. And they all are investing in voice assistance and other forms of AI and robotics.
Although Amazon is leading the way with its ecosystem surrounding its AI assistant Alexa, each of the others either has or are developing competing systems of equal or greater capability… think OK Google, Siri and Apple’s new Homepod and Cortana or, in China, Alibaba’s Tmall Genie, Baidu’s Little Fish and JD’s DingDong.
Also, they are all moving toward providing AI as a service.
Baidu (NASDAQ:BIDU) is China’s primary search source and also provides Internet-related services and products as well as targeted advertising, transaction services and a video platform. Baidu is heavily investing in researching deep learning, computer vision, speech recognition and synthesis, natural language understanding, data mining and knowledge discovery, business intelligence, artificial general intelligence, high performance computing, robotics and autonomous driving (at their new self-driving lab in Silicon Valley).
Alibaba (NYSE:BABA) is a multi-national China-based e-commerce retailer, payment and technology conglomerate, cloud provider, whose two shopping malls (Tmall and Taobao) have over 1 billion combined active users and are supported by a budding logistics network. Alibaba’s AI-powered platform (which it uses internally for its shopping malls and logistics processing) was recently rolled out in Kuala Lumpur to support smart cities in their digital transformation. It analyzes large data volumes extracted from various sources in an urban environment, through video, image, and speech recognition. The system then uses machine learning to provide insights for city administrators to improve operational efficiencies and monitor security risks.
Tencent (HKG:0700) is a Chinese provider of Internet and cloud-related services and products, entertainment, music services, AI, real estate and social media including WeChat (which recently hit 1 billion users). More than 35% of WeChat users spend over four hours a day on the service compared to the little more than an hour a day spent on Facebook, Instagram, Snapchat and Twitter combined. Tencent has set up AI labs in Shenzhen and Seattle and is researching voice and image recognition systems and transforming what they’ve learned into apps and algorithms to keep their users informed and attentive.
NOTE: Baidu, Alibaba and Tencent make up B A T, the acronym given to the trio of main competitors in China’s quantum computer and machine learning research. In addition to labs in China, each has a Silicon Valley research center. Funding and incentives are provided by the Chinese government. The three BAT companies already collect and analyze huge amounts of data from their e-commerce transactions, mobile gaming, online search and payments to social media, video streaming and on-demand services such as ride-sharing and food deliveries. With quantum computing, they will be able to sift through massive data streams faster and better than with existing supercomputers.
JD.Com (NASDAQ:JD) is a Chinese e-commerce competitor with about half the user base of Alibaba yet with very progressive logistics and infrastructure programs. JD (Jingdong) is testing robotic delivery services, operating driverless delivery trucks and building drone delivery ports. JD operates 7 fulfillment centers and 405 warehouses in China. Last month it raised $2.5 billion for its JD Logistics subsidiary to build out and expand their logistics network.
SoftBank (TYO:9984) is a Japanese telecom conglomerate. Softbank is also the instigator of the SoftBank Vision Fund which is investing massive amounts ($98 bn) in technologies and entrepreneurs pioneering the future through a wide range of sectors: IoT, AI, robotics, mobile applications and computing, and infrastructure, cloud technologies and software. SoftBank, with it’s funding partners Apple, Qualcomm and various sovereign wealth funds, wants to invest another $900 billion in 1,000 AI and robotics companies in the next decade. SoftBank is also a partner with Alibaba and Foxconn to produce and market Pepper and Nao robots.
Google/Alphabet (NASDAQ:GOOG) is a Silicon Valley search engine and Internet products company with a stable of forthcoming AI ventures such as Waymo, Verb Surgical and Nest along with consumer products like Google Home, Android phones and Chromebook computers. Google is leveraging their data, processing power, and talent into an array of AI-based apps, processes and products. Their foray into robotics hardware has resulted in much valuable research but all of the units have either been sold off or closed (except for Boston Dynamics and Shaft which are held up from sale by government regulators). Although still a leader in machine learning, Google is finding much competition from their Chinese competitors.
Apple (NASDAQ:AAPL) is Apple, a Silicon Valley designer, manufacturer and marketer of phones, media and hardware devices and provider of software, services and digital content. Apple is the world’s largest information technology company by revenue and the world’s second-largest mobile phone manufacturer after Samsung with annual revenue of $229 billion. Building out Siri from the virtual world into the consumer product world with their new Homepod is off to a late start.
Facebook (NASDAQ:FB) is also a Silicon Valley-based Internet phenomena with products that include Facebook, Instagram, Messenger, WhatsApp and Oculus. Facebook has over 2.2 billion active users. Their investments in AI appear to be focused on developing a virtual (or physical) assistant. Their acquisition of Ozlo to help Messenger build out a more elaborate virtual assistant for users is an example.
Walmart (NYSE:WMT) is a global retailer with wholesale facilities, logistics and distribution centers all around the world. Walmart operates over 11,000 stores under 59 names in 28 countries and e-commerce sites in 11 countries. It grosses over $480 billion annually and employs over 2.3 million workers. As Walmart increases its online e-commerce market share while simultaneously changing practices to provide better product transparency (particularly in and faster material handling at its stores and distribution centers, it too is on a talent hunt for roboticists and AI/machine learning people and providers.
Amazon (NASDAQ:AMZN) Amazon is the leading e-commerce seller of products, supply chain services, AI, and cloud services that is copied and competed with around the world. Amazon accounts for ~4% of all retail and ~44% of all e-commerce spending in the US. Amazon’s supply chain and logistics facilities use more than 60,000 robots in its various warehouses and distribution centers, and its cloud services, which not only services Amazon, provides on-demand cloud computing platforms to companies and governments on a subscription basis. Amazon’s Echo/Alexa home assistant has started to include capabilities like a display, camera and alarm clock, security cameras, and even a fashion advisor. It is combining all these different incremental parts to build a smart home robot as they become viable and front-ended by the Alexa voice assistant.
Amazon is the company to watch in terms of early innovation. Others follow and emulate; Amazon quietly goes forward and China is on its horizon. CBInsights had two interesting comments on the subject as can be seen in these two charts:
CBInsights looked at which peers companies were talked about in financial reports and calls and found that Amazon doesn’t mention competitors. But Amazon mentions of China are up 57% over 2016.
NOTE: There are no Europeans in this list nor in the Top 15 Alexa Sites. Large robotics firms in Germany and Italy have been sold to China. ARM, the British chip-maker, was sold to SoftBank and DeepMind, the UK AI wonder, was picked up by Google. Many fear that Europe may excel at manufacturing but don’t have protectionist impulses to fend off (and keep up with) America or China and to know that smart manufacturing and smart cars – in fact smart everything – is the new game. Recently European leadership has shown fear in the use of and connection to cloud and analytics platforms in the age of IoT – even though Europeans pioneered the term Industry 4.0.
A major talent-hunting event is the big NVIDIA GPU tech conference being held in San Jose March 26-29. Over 8,000 industry professionals of all types are planning to attend this job fair and place to learn about AI, machine learning and deep learning.
Infrastructure
Common to all is e-commerce and the systems that pick, pack, ship and deliver all the goods. Thus, in addition to investments and interest in cloud platforms, super computing and AI, there is a global explosion in warehouse construction and reconfiguration for automation. According to Cushman & Wakefield, U.S. developers added almost 1 billion square feet of warehouse space from 2013 to 2017, a 2X increase over the previous 5 years. It’s harder to get information for China but news stories indicate similar if not greater growth, new forms of automation and labor shortages.
The constant lament heard in the U.S. is captured (and presumed to be relevant worldwide) is this quote from a fulfillment executive:
“A big part of our strategy is how do we make the current employees we have more productive and to reduce the requirement for more labor at peak times.”
Providing warehouse labor is a big business because workers are hard to find and turnover is more than 10% per month. Hence the simultaneous investment in robotics and smart warehousing systems to maximize human effort and reduce costly errors and turnover.
Warehousing has always been as automated as possible, particularly in pallet and box handling, but as labor has become more scarce and costly, as robotic systems have improved and costs been reduced, and as the number of shipments has increased exponentially due to e-commerce, the nature of material handling and fulfillment has radically changed. Hence the need for mechanical assistance.
But this is fodder for another article to follow shortly on the global inroads being made in fulfillment and material handling. Stay tuned.",https://www.therobotreport.com/10-tech-savvy-companies-on-the-hunt-for-ai-robotics-talent-and-ip/,[[0.08214787]]
SMAC in the DARQ: five trends shaping tech in 2020,"In 2020, will the wow factor return to consumer hardware? Will blockchain and 5G punch into the mainstream? Or will the world unify against Big Tech's tax-avoiding practices?
AFP looks at five themes shaping the world of technology, after a year in which debate intensified over the industry's exploitation of its customers' privacy.
5G's unfulfilled promise
Super-fast fifth-generation network speeds are meant to revolutionise communications along with areas like urban transport.
But so far, 5G has failed to meet expectations due to the lagging build of infrastructure in many places. Apple has yet to launch a compatible phone, unlike rivals including Samsung.
The rollout should quicken next year as more countries install base stations and networking equipment—although US President Donald Trump's war on Chinese sector leader Huawei remains a wild card.
As smartphone sales plateau around the world, manufacturers have been focussing more on ancillary services.
""You have to sell the entire experience, the entire ecosystem,"" Dominique Bindels, senior analyst for home and tech with London-based research firm Euromonitor International, told AFP.
Highlighting Apple's success in payments and peripheral devices such as AirPods, Bindels predicted that smart earphones, along with speakers and at-home devices connected on the ""internet of things"", would be among the more dynamic sectors in 2020.
Digital assistants such as Alexa and Siri may start talking to each other, after Amazon, Apple and Google this month formed an alliance with other industry players to develop a common standard for smart home devices.
Another trend could be consolidation in TV streaming, after Apple and Disney joined Netflix, Amazon Video and some national broadcasters in a crowded subscription market.
Leap into the quantum dark
For the industry at large, business consultancy Accenture this year coined the acronym DARQ to denote four major trends: distributed ledger technology (such as blockchain), artificial intelligence (AI), extended reality and quantum computing.
Unbreakable blockchain networks of computers have already been generating virtual currencies in the form of bitcoin and its ilk, bypassing the need for a regulator like a government or central bank.
Facebook wants to make the tech respectable through its ""Libra"" project, but has hit political opposition around the world, and several financial partners have pulled out.
Unwilling to let private enterprise dictate terms, China and other nations are building their own digital payments systems, which could see fruition next year.
However, blockchain networks devour huge amounts of energy, and concerns will mount about their environmental impact as debate intensifies more broadly about tech's contribution to climate change.
The price of privacy
Most companies are now actively engaged across the spectrum of another tech acronym, SMAC: social, mobile, analytics and cloud. For consumers, SMAC is felt in how we communicate with friends and how we search and shop.
That is accentuating fears about privacy, after a series of data leaks at Facebook first laid bare how much of our online lives are exploited by companies and political parties.
""People are becoming more conscious of sharing data but also in the same moment, the Nest cameras and smart speakers are flying off the shelves,"" said Bindels.
""There's a huge divide. People have been learning to trade privacy for convenience. It's just another currency.""
Amnesty International, in a hard-hitting study last month into Facebook and Google, said that tradeoff amounts to a ""Faustian bargain"" which imperils our human rights.
Tech wars
To Beijing's anger, Washington alleges that Huawei and another telecoms group, ZTE, are little more than shell fronts for Chinese spy chiefs.
Ni Lexiong, professor at the Shanghai National Defense Strategy Institute, said US sanctions depriving those firms of access to US components would only encourage China to stand on its own feet.
""In the end, once China has formed its own industrial chain in the field of artificial intelligence, the United States will also lose a large market,"" he said.
Samm Sacks, an expert on China's digital economy at the Washington think tank New America, said the tech standoff could harm progress in areas such as precision medicine and AI-based diagnoses.
The two countries have cooperated in research, ""and severing that could have global consequences"", she warned.
Taxing times
The US presidential election next November will likely prove another flashpoint over disinformation peddled on social media.
Democratic hopeful Elizabeth Warren wants Amazon, Facebook and Google to be broken up on anti-trust grounds.
The Organisation for Economic Co-operation and Development is meanwhile due by June 2020 to present a ""unified approach"" for richer countries to levy a digital tax on internet giants.
Some like France have gone ahead with their own tax, igniting another front in Trump's multifaceted trade wars as the US threatens tariffs on a range of French goods.
© 2019 AFP",https://techxplore.com/news/2019-12-smac-darq-trends-tech.html,[[0.08076937]]
Autonomous Vehicles & The Automotive Supply Chain,"IBM has revealed results of its new Automotive 2025 Global Study, outlining an industry ripe for disruptive changes to the automotive ecosystem. The move towards a more personalized driving experience with smarter cars will lead to new entrants emerging to challenge established players.
The study forecasts that the automotive industry will offer a greater personalized driving experience by 2025. It also suggests that big changes are coming in the automotive supply chain.
""While the automotive industry has seen a resurgence in recent years, a new industry identity is emerging—one that is more open, inclusive, and without borders. Welcoming this transformation can result in benefits the likes of which haven't been seen since the automated assembly line,"" said Alexander Scheidt, Global Automotive Industry Leader, IBM Global Business Services. ""By 2025, the industry will not only recreate our highly personalized and digitized lives inside our cars, but also give consumers a bigger role in defining that experience, whether as a driver or passenger.""
This is a significant shift in the product development landscape. With electric vehicles and hybrids forming only a minority of vehicle sales, and the prospect for stable, lower oil pricing for the foreseeable future, there is no significant technical innovation on the horizon that will drive a sea change in consumer auto buying preferences.
What’s left is connectivity. With automakers now driving sales with a pitch that revolves around a car’s ability to connect to the Web or a driver’s smart phone, volume growth in non-telematics mechanical and electrical systems may be limited. And with notable exceptions such as Delphi Automotive, the supply chain for high level telematics will come increasingly from the IT industry rather than traditional Tier Ones.
The IBM Automotive 2025 Global Study is based on interviews with 175 executives from automotive OEMs, suppliers, and other thought leaders in 21 countries, detailing customer expectations, growth strategies, mobility requirements, ecosystem disruption and other topics shaping the direction of the industry. Entitled ""Automotive 2025: Industry without borders,"" the study was developed by the IBM Institute for Business Value (IBV) as a follow up to ""Automotive 2020: Clarity beyond the chaos.""
Consumers and automakers will co-creating autonomous vehicles
Today's consumers are more engaged than ever. They desire both digital engagement and an improved driving experience. The report indicates that consumers not only want to drive cars; they want the opportunity to innovate and co-create them so that they include related services, such as infotainment.
According to the study, changes in consumer expectations were the most dramatic shift between the Auto 2020 and Auto 2025 studies. Addressing consumer expectations now ranks behind only technology in order of importance to the automotive industry.
The report also indicates that nearly two out of every three (63%) executives surveyed saw mobility services or car/ride sharing as an area for greater collaboration with consumers. In addition, more than half (59%) felt product design, marketing campaigns (54%) and service/after-sales (52%) were areas in which the industry would benefit from working directly with consumers.
Cognitive vehicles will offer a personalized driving experience
By 2025, vehicles will be sophisticated enough to configure themselves to a driver and other occupants. Also, they will be able to learn, heal, drive and socialize with other vehicles and their surrounding environment. Nearly 80% of the executives felt that in-vehicle cognitive technologies will be a key component of how vehicles learn to provide a better experience for the occupants and optimize itheir own performance.
Fifty-seven percent of the respondents believe that vehicle ""social networks"" will be in place whereby vehicles will communicate with each other, allowing vehicles to share not only traffic or weather conditions, but information specific to a given automaker. For instance, if a vehicle was experiencing some type of problem not recognized before, it could communicate with other vehicles of the same brand to seek help on that issue.
In contrast to common beliefs, the report also underscores considerable skepticism about fully autonomous vehicles—where no driver is required and the vehicle is integrated into normal driving conditions. A mere 8% of executives see it becoming commonplace by 2025. Moreover, only 19% believe that a fully automated environment—meaning the driving system handles all situations without monitoring, and the driver is allowed to perform non-driving tasks—will be routine by 2025.
Eighty-seven percent of the participants felt that partially automated driving, such as an expansion of today's self-parking or lane change assist technologies would be commonplace. Moreover, 55% said highly automated driving, where the system recognizes its limitations and calls on the driver to take control, if needed, allowing the driver to perform some non-driving tasks in the meantime, would also be adapted by 2025.
The skepticism about fully automated driving is especially noteworthy given Google’s advanced technology and several predictions that automated systems would in fact be commonplace by 2025.
While most predictions are based on the rapidly advancing state-of-the-art in sensor actuator technology, there are still multiple unresolved legal and political issues around fully autonomous driving. Not least of these is product liability. If automakers become automatic co-defendants in traffic accident cases, the pressure will be on to either implement serious tort reform, or delay implementation of autonomous systems until they can be so demonstrably foolproof that automakers’ insurers will underwrite the risk.
In the US at least, juries generally find it easy to award massive damages against OEMs, regardless of the facts. Expect any fully autonomous systems to still require a licensed driver with some nominal control to avoid these issues, much like the upcoming Mercedes-Benz highway autopilot system, which will require a hand on the steering wheel.
The borders of the automotive supply chain will come down
Overall, the IBM Automotive 2025 study paints a very clear picture: Industry growth will come from delivering additional value rather than just selling more vehicles. And even though one third of those surveyed feel they will be able to adapt to the challenges this presents, only one in five feel that they are prepared now.
The future requirements from the study emphasizes that the rigid, self-contained industry of the past century must quickly transform into an ecosystem that is open, collaborative and filled with new innovators:
73% of OEM executives rated mobility services and cost-effective alternatives to vehicle ownership like car/ride-sharing as a significant area for co-creation with consumers
73% of all executives rated collaboration with other industries as the best opportunity for industry growth as it progresses toward 2025
75% of all executives expect non-traditional industry partnerships to have a key role in the automotive ecosystem by 2025
An element of increasing importance in those non-traditional partnerships may be the emergence of Uber-like ridesharing systems. In urban environments, the possibility that vehicle ownership may be replaced by either subscription-based or pay-as-you-go automated taxi services is very real. If this evolves, technology changes may become evolutionary, without the new model change cycles that have defined the industry since World War II.
""Looking toward 2025, as the borders continue to come down, the new ecosystem will create challenges and opportunities the industry has never had to face before; the enterprises that welcome openness will set the stage for long term success and industry leadership,"" said Scheidt.
For more information about autonomous vehicles, check out Driverless Cars - The Race to Level 5 Autonomous Vehicles.",https://www.engineering.com/AdvancedManufacturing/ArticleID/9388/Autonomous-Vehicles-The-Automotive-Supply-Chain.aspx,[[0.08008861]]
New security system to revolutionize communications privacy,"A new, uncrackable security system created by researchers at King Abdullah University of Science and Technology (KAUST), the University of St Andrews and the Center for Unconventional Processes of Sciences (CUP Sciences) is set to revolutionize communications privacy.
The international team of scientists have created optical chips that enable information to be sent from user to user using a one-time un-hackable communication that achieves ""perfect secrecy"" allowing confidential data to be protected more securely than ever before on public classical communication channels.
Their proposed system uses silicon chips that contain complex structures that are irreversibly changed, to send information in a one-time key that can never be recreated nor intercepted by an attacker.
The results published in the scientific journal Nature Communications open a new pathway towards implementing perfect secrecy cryptography at the global scale with contained costs.
""This new technique is absolutely unbreakable, as we rigorously demonstrated in our article. It can be used to protect the confidentiality of communications exchanged by users separated by any distance, at an ultrafast speed close to the light limit and in inexpensive and electronic compatible optical chips,"" says Professor Andrea di Falco of the School of Physics and Astronomy at the University of St. Andrews and first author of the study.
Current standard cryptographic techniques allow information to be sent quickly but can be broken by future computers and quantum algorithms. The research team say their new method for encrypting data, is unbreakable, and uses the existing communication networks, taking up less space on the networks than traditional encrypted communications.
""With the advent of more powerful and quantum computers, all current encryptions will be broken in very short time, exposing the privacy of our present and, more importantly, past communications. For instance, an attacker can store an encrypted message that is sent today and wait for the right technology to become available to decipher the communication,"" says Dr. Andrea Fratalocchi, Associate Professor of Electrical Engineering at KAUST and co-author of the study.
""Implementing massive and affordable resources of global security is a worldwide problem that this research has the potential to solve for everyone, and everywhere. If this scheme could be implemented globally, crypto-hackers will have to look for another job,"" Dr. Fratalocchi continues.
The new method uses the classical law of physics to protect the messages and in particular the second law of thermodynamics. The technique achieves perfect secrecy, meaning a hacker will never be able to access the information contained in the communication.
Keys generated by the chip, which unlock each message, are never stored and are not communicated with the message, nor can they ever be recreated, even by the users themselves, adding extra security.
""This system is the practical solution the cybersecurity sector has been waiting for since the perfect secrecy theoretical proof in 1917 by Gilbert Vernam. It'll be a key candidate to solving global cybersecurity threats, from private to national security, all the way to smart energy grids."" says Dr. Aluizio M Cruz, co-founder and CEO of the Center for Unconventional Processes of Sciences (CUP Sciences) in California, and co-author of the study.
The team is currently working on developing commercial applications of this patented technology, have a fully functional demo and are building user-friendly software for this system.
Provided by King Abdullah University of Science and Technology",https://techxplore.com/news/2019-12-revolutionize-privacy.html,[[0.07839595]]
Hollow bore incremental encoder,"With bores sizes up to 0.625 inches, Quantum Devices’ QPhaseT QD200 has been designed to eliminate the assembly hassle and hidden cost of installing modular or kit encoders onto OEM products. Available through Electromate Industrial Sales, the QD200 is a complete operational unit with an integral dual ABEC 5, ball bearing, insert molded hollow shaft support that provides the mechanical stability for this low profile, high resolution encoder package. Using proprietary sensing technology, the encoder is able to obtain an incremental, 5000 PPR, plus Index pulse, without the use of interpolation schemes. The stainless steel flexible spring mount provides for 30 degree rotational adjustment to permit precise commutation alignment and has been designed to allow for more motor tail shaft run out than typical modular or kit type units can tolerate.
Electromate Industrial Sales
www.electromate.com",https://www.automationmag.com/357-hollow-bore-incremental-encoder/,[[0.07563538]]
Having your head in the cloud prepares you for Industry 4.0,"How is machine learning, big data and cloud technologies changing the manufacturing industry and how to take the first steps in order to embrace it?
Over the past 350 years, the manufacturing industry has been marked by huge leaps in technology that have given us better control over automated production. First steam took over from water power, and later electricity ushered in the era of mass production.
In the ’60s, computers empowered us to repurpose machines’ and automate processes without rewiring them, and now the next manufacturing revolution is in full swing.
Industry 4.0 is bringing a new level of automation to manufacturing by allowing machines’ processes to be reprogrammed with minimal input from humans. This is thanks to the parallel emergence of nine key technologies, as identified by the Boston Consulting Group, including machine learning, big data and cloud.
The building blocks of industry 4.0
Cloud technology has probably received the most widespread coverage in the mainstream, but its use goes well beyond Netflix or Spotify. In fact, cloud-computing is one of the most important building blocks of Industry 4.0.
Manufacturing machines have always produced vast amounts of data, but previously there was no way of sending, receiving, storing or analysing it. Thanks to improving cloud technologies, every single operation performed by a piece of equipment connected to the internet, no matter where it’s located, can be sent directly to a virtual-server.
Once the data is in the cloud, it can be analysed by business intelligence software and shared using a cloud-enabled device and authorised access. If the adage is true and knowledge is power, cloud-computing could transform factories into an almost endless source of power.
Where this all leads to is Smart Factories.
From the shop floor to the consumer
Smart factories, where every single operation performed, from customer orders to deliveries, becomes a part of this 360-degree knowledge of your operation.
In more concrete terms, consider an experienced shop-floor machinist, he can probably look at a drawing and tell you approximately how long it will take to fabricate.
Now think of the shop-manager, he can tell you if you have the available stock and space in the schedule. Finally think about the factory owner, he’ll know how to price the job and order new stock to replace what’s used.
In a smart factory, all this information already exists in the cloud and can be processed in an instant. Customers could simply submit a drawing and your system would order the stock, schedule the work, calculate a price, arrange a delivery and send a quote to the customer – all based on real-world data from your factory.
While you might not be ready for that kind of automation, embracing cloud-computing could help prepare your manufacturing business for Industry 4.0",https://www.themanufacturer.com/articles/having-your-head-in-the-cloud-prepares-you-for-industry-4-0/,[[0.07520855]]
"Latest Production Tech: Bodine Planetary Gearmotor, Yxlon Line Detector & More","Bodine Planetary Gearmotor
Bodine has introduced its type 22B4-60P planetary gearmotor, an integral gearmotor that combines the company’s type 22B brushless DC motor with the 60P (60mm) planetary gearhead. It is suited for applications that require higher torque than conventional helical/spur gearheads of a similar size can provide, and where a low backlash gearhead is not needed.
The 60P gearhead has a rated torque of up to 26Nm and mounts in any orientation. It is also permanently lubricated with high-performance grease and features needles bearing supported, hardened steel gears for increased longevity. The standard backlash of this gearhead is less than one degree.
For more information, visit Bodine’s website.
FARO Manufacturing Arm
FARO has unveiled its 8-Axis FaroArm system, which combines either the portable Quantum FaroArm, Quantum ScanArm or Design ScanArm systems with a functionally integrated, yet physically separate eighth axis. Unlike a turntable, the eighth axis is completely transparent to the measurement software, so no software updates or upgrades are needed.
The 8-Axis system is ideal for addressing a range of noncontact measurement and design challenges, including point cloud comparison with CAD, rapid prototyping, reverse engineering and 3D modeling of free-form surfaces.
For more information, visit FARO’s website.
OMRON Vision System
OMRON has announced its FH Series Vision System, which allows for the automation of external inspections. Used in combination with the Multi-Direction Multi-Color (MDMC) Light,the FH Series can detect defects with low color differences or defects with different characteristics simultaneously, which was previously difficult to achieve without human input and supervision.
The FH Series Controllers and Cameras have also been upgraded to detect and determine minute differences that the human eye cannot identify and quantitatively manage inspection results. Due to its processing speed and synchronization with automation devices via a communication network, the FH Series can store all inspection results that are required to comply with industry laws and regulations, without compromising productivity.
For more information, visit OMRON’s website.
Pepperl+FuchsAbsolute Positioning System
Pepperl+Fuchs has launched the PXV 2-D absolute positioning system, which combines a 2D reader with a three-colored Data Matrix code tape. The code tape contains two overlapping Data Matrix codes in red and blue. The 2D reader is equipped with two different colored LED rings—also in red and blue. These rings are activated separately and then read just one Data Matrix code each. An SIL 3/PL e absolute position is always provided as the result.
The PXV requires a 2D camera, helping to ensure that irritation related to track switches is excluded. To prevent this from occurring, the cameras in the two-camera setup can receive the relevant differing position signals in these areas.
For more information, visit Pepperl+Fuchs’ website.
Yxlon Line Detector
Yxlon has released the CTScan 3 line detector. Going forward, the CT Compact computer tomography system will be equipped with the line detector as a standard component.The CT Compact system is a fan-beam CT device for medium to large castings designed for the automotive and aerospace industries, but it is also suited for the non destructive analysis of dense historical art and archaeological objects, as well as large-scale geological samples.
Production is now machine-supported with the CTScan 3, resulting in crystal uniformity. Due to the range and signal stability, material thicknesses can be tested with the same X-ray energy. The solid housing is resistant to temperature fluctuations, which prevents the electronics from overheating.
For more information, visit Yxlon’s website.
Missed last week’s Latest Production Tech? Click here.",https://www.engineering.com/AdvancedManufacturing/ArticleID/17419/Latest-Production-Tech-Bodine-Planetary-Gearmotor-Yxlon-Line-Detector-More.aspx,[[0.07174574]]
Scaling High-Performance Computing to Manufacturers’ Needs,"Every business is shaped by “economies of scale,” the principle that there are operating cost advantages related to its size or (in manufacturing, particularly) production volume. Manufacturers more typically express this concept as “productivity”: how can revenue be improved without an adverse affect on capital and operating costs?
But, “productivity” focuses on an enterprise’s specific costs and tends to deemphasize a salient point about “economies of scale,” that is, the factors shaping an enterprise’s competitive position are always changing. For that reason, larger businesses have advantages over small and mid-sized businesses, particularly in manufacturing — and particularly now that acquiring and processing data has emerged as a factor determining competitive standing. From sourcing energy and materials, to evaluating product or process design, to exploring new product and market opportunities, managing Big Data is a big challenge to small and midsized manufacturing businesses.
Now a startup business is commercializing technology developed at Argonne National Laboratory and the University of Chicago to provide “supercomputing-as-a-service” to SMBs, helping them to achieve economies of scale in managing the expanding volume of information that is constantly redefining businesses and industries.
“High Performance Computing, or HPC, refers to the use of many computers working concurrently (‘in parallel’) to solve large-scale computing problems, such as simulating the operations of a manufacturing plant,” explained Michael Wilde, CEO of Parallel Works Inc. “If, for example, you have 10,000 computers available, and can thus evaluate 10,000 designs at a time, then a computation that would have taken 1 million minutes (almost two years) can now be done in under two hours. That's high performance computing.”
Parallel Works is offering that capability to SMBs in a Cloud-based HPC platform via a ""software as a service"" model, typically to be accessed from a Web browser. “Users select from a set of pre-written ‘workflow apps’ developed by third-party vendors, or even by the customer's own IT staff, to solve specific problems product design, manufacturing process improvement, assembly or end-customer application simulation,” Wilde detailed.
Democratizing HPC
Making such functionality available to SMBs is partly an effort to “democratize high-performance computing,” according to Parallel Works’ statement. Similar publicly available capabilities are offered by Amazon, Google, and other vendors, “but there’s still a gap in terms of the expertise that an SMB needs to actually use the Cloud,” Wilde noted. The task for Parallel Works is “to connect the cloud to (an SMB’s) critical business and engineering processes.”
What the manufacturer will find, he said, is an ability “to effectively harness the power of parallel HPC … with a minimum of IT expertise needed, with minimal time delay, and on a pay-as-you-go basis with little or no up-front investment.”
The need for supercomputing capability is real, and expanding, according to Parallel Works. Current manufacturing supply chains are realigning not only according to the variable production costs of individual competitors but also according to the needs of customers, regulatory changes, and in particular design changes. HPC allows the manufacturer to evaluate vast numbers of design variations in advance of prototyping. Following that, there are comparable advantages to evaluating differing production set-up possibilities.
Consider HPC in a machining operation, where it will mean that a product design can be evaluated versus any number of tool-path options, to identify the optimal production set-up.
Wilde also identified advantages of HPC in a business’s marketing efforts: “Many products need to be simulated in the sales process,” he noted. “For example, the performance yields expected from advanced building products, better industrial chemicals and other advanced materials, vehicles and vehicle parts, all may need to be simulated to predict their performance and ROI to the customer in specific application contexts.”
An important advantage to Parallel Works’ HPC offering would be the ready availability of the technology update: “Our vision is that HPC systems would run software tools called ‘optimizers’,” according to Wilde, “which quickly and intelligently explore and analyze a vast number of possible process improvements for a product design or a factory or manufacturing system or subsystem.”
What Wilde is describing is typically called a “design exploration service,” which applies to the design of and manufacturing processes for a product, and to its end-customer application. Such optimization processes would run periodically in parallel to existing process control and MES functions, but periodically, “as new lines are created, new products are introduced, or as model mixes change over time.” The optimization process would interact with PLM, ERP, and related systems in the enterprise, to set new MES parameters or execution plans that increase process performance.
There is no hardware to be installed by the manufacturer: all the parallel computing hardware typically lives in and/or is accessed via, the cloud. “You only pay for the computing you need, and you get as much of it as you need, when you need it,” Wilde noted. “That’s a great reduction in capital expense and in the specialized and costly IT expertise you need to select, purchase and operate such parallel equipment.”
The economies of scale may be shifting for manufacturers of all sizes, but the scope and influence of data is not “scalable”: It is only increasing. As a consequence, there is a growing need for business decisions to access the resources of HPC, and so adopting “supercomputing” may be seen as a productivity strategy, rather than just an investment option.",https://www.industryweek.com/small-mid-size-manufacturers/article/21999818/scaling-highperformance-computing-to-manufacturers-needs,[[0.07163751]]
RAPID + TCT 2019: What’s New in 3D Printing Hardware and Software,"This year’s RAPID + TCT show displayed further evidence of additive manufacturing’s (AM) continued maturation into a mass-production technology. While engineering.com will publish numerous videos from on the ground at RAPID, we thought an overview of all of the big announcements from the event would be helpful to our readers.
Without further ado, here is a list of some of the most important bits of hardware and software news from last week’s event. Look out for a second recap covering 3D-printing materials stories, including diamond-based materials and strong moves from BASF.
Deep Learning for Closed-Loop 3D Printing
Markforged unveiled its “artificial intelligence-powered” 3D-printing software, dubbed Blacksmith. The tool uses machine learning and inspection tools to adjust its own programming and parameters to produce parts as designed. Blacksmith will be rolled out for Metal X and X7 customers this fall. If the software delivers as promised, it could be among the first closed-loop metal AM technologies on the market (the only other closed-loop metal 3D printers come from Velo3D and Sciaky).
Carbon Fiber 3D Printing Steps out of Beta with CBAM-2
Impossible Objects showcased the latest version of its composite 3D-printing technology, the CBAM-2. As we’ve covered previously, the company’s proprietary composite-based additive manufacturing (CBAM) technology combines reinforcement materials, like carbon fiber, with engineering-grade polymers, such as polyether ether ketone (PEEK), to create parts with novel materials.
The CBAM-2 is an upgrade to Impossible Objects’ previous beta system, the Model One, released at RAPID + TCT 2017. It can reportedly print objects at a speed 10 times faster than other AM systems and has a print volume of 12 x 12 inches. Other new features include three cameras for better quality control, automatic powder filling and bulk ink cartridges. The new model is expected to be available in Q3.
Additionally, Impossible Objects raised $4.1 million in a recent funding round led by OCA Ventures, raising the firm’s total funding to $13 million.
GE Reinvents the 3D-Printed Wheel
At formnext 2018, HRE Wheels and GE Additive unveiled a unique 3D-printed wheel, which the partners have now reinvented their design to create a second generation HRE3D+ wheel, 3D printed using direct metal laser melting and electron beam melting.
By consolidating the assembly, the HRE3D+ design reduced the part count from six to five parts, reducing the weight of the initial 20- and 21-inch designs from 20 and 23 pounds to 16 and 19 pounds. This also led to material waste of just 5 percent, compared to 80 percent seen in traditional wheel production.
Origin Reveals the Origin One 3D Printer
After a tease last December, Origin unveiled its flagship 3D printer, the Origin One, which uses novel photopolymers that don’t require the presence of oxygen, like other vat polymerization technologies. The system, with a build volume of 192 x 108 x 350mm,is described as providing real-time process monitoring to adjust printing to ensure parts are made to specification.
Danish footwear company ECCO Group has partnered with Origin and BASF to use the Origin One and BASF’s Ultracur3D at its research and development facilities.
Quantum Laser Sintering from NXT Factory
NXT Factory, founded by former 3D Systems CEO Avi Reichental, revealed the QLS 350, which uses the company’s “quantum laser sintering” to reportedly 3D print plastics as quickly as HP’s multi jet fusion (MJF) and four times faster than selective laser sintering technologies. Quantum laser sintering relies on a proprietary laser beam delivery system, as well as autonomous powder management, thermal management and docking. A robotically guided print chamber makes it possible to achieve production rates similar to injection molding, according to NXT Factory.
Beam delivery is aided by deep-learning that are meant to provide “real-time predictive and prescriptive choices” and real-time quality monitoring. The company claims that the system offers cost efficiency for production runs of 8,000 to 12,000 parts. The system is expected to ship in the second half of 2019.
Tethon 3D’s Ceramics and Metal 3D Printer
Previously known for its ceramic resins, Omaha-based Tethon 3D unveiled its first 3D printer, the Bison 1000. The system, developed with the University of Nebraska, features a build volume of 110 x 60 x 130mm and layer thicknesses as fine as 25 microns. The printer is meant to be used with Tethon 3D materials, which include an iron resin, as well as casting, flexible, alumina, regolith and other ceramic resins.
SmileDirectClub Uses HP for Invisible Aligners
The production of dental aligners was among the first mainstream industrial processes to be disrupted by AM, with brands like Invisalign traditionally using vat photopolymerization technologies to produce the molds for custom aligners.
Now, it seems that even that disruption will be disrupted as HP has entered the market, providing 49 MJF 3D printers to SmileDirectClub to produce 50,000 custom mouth molds daily. The teledentistry business aims to make nearly 20 million aligners using the technology in the next 12 months, making the company the largest producer of MJF parts in the U.S. The partners will also develop a recycling program to convert unused plastic powder and processed molds into pellets for injection molding.
Desktop Metal Delivers Production Systems
Desktop Metal has begun shipping its Production Systems, with its first two customers, Fast Radius and Indo-MIM, receiving machines. Indo-MIM is said to be the largest supplier parts made with metal injection molding (MIM) and will incorporate the technology into its production facilities, which make 100 MIM parts per year. The company will “become a full-service manufacturing partner for Desktop Metal,” meaning that it will act as a service provider for clients looking for consultations, parts printing and finishing processes for AM parts.
The Production System will be installed in Indo-MIM’s San Antonio, Texas, factory this summer, and the firm will begin taking AM customers this fall. For more on Desktop Metal’s technology, read our interview with the CTO.
After bringing the Figure 4 Standalone 3D printer into the marketplace last year, 3D Systems has finally announced a release date for the modular version of its fast-curing (100mm/hr) digital light processing (DLP) machine. The Figure 4 Modular is set to be available for purchase for $49,900, including one printer and one controller unit,this June. Meant to be a scalable solution for up to 24 printers, the printer can be purchased with automated materials handling and centralized post-processing. Each printing unit in the setup can be programmed to use different materials and print different jobs.
Meant to be a scalable solution for up to 24 printers, the printer can be purchased with automated materials handling and centralized post-processing. Each printing unit in the setup can be programmed to use different materials and print different jobs.
While we’ve awaited the official release since 2017, the Figure 4 Modular is already in the wild. French sporting goods maker Decathlon uses the machine for design and development, replacing a desktop stereolithography system and achieving 19 times greater printing speed. Other existing users include Midwest Prototyping and D&K Engineering.
We’re still holding our breath for the Figure 4 Production solution, meant to be an integrated factory system for mass production. In the meantime, stay tuned for our recap of 3D printing materials news from RAPID + TCT 2019.",https://www.engineering.com/AdvancedManufacturing/ArticleID/19200/RAPID-TCT-2019-Whats-New-in-3D-Printing-Hardware-and-Software.aspx,[[0.07052618]]
CGTech Now Shipping New Release of VERICUT CAM Software,"When you consider the times you’ve inhabited so far in your life, how much would you say computers have aided humans in manufacturing goods and services all over the world?
It’s an interesting question and quantifying an answer would take considerable time and research. But going into 2017 with the notion that computers and computing do not augment or change the way we experience the world is bound to have fragility sown into its structure.
Since most of the ways we experience the world is as consumers, focusing on physical goods made with the help of computers aids in making a basic distinction between different software. There is software meant to be experienced digitally, through a computer, phone, tablet, or headset and there is software meant to control external hardware like CNC machines and other robots.
Included in the latter category, software that helps humans manufacture goods, is CAM software, such as the new Version 8.0 of VERICUT Composite Applications software from Irving, Calif.-based CGTech.
Customers who use VERICUT generally rely on software runs well on their machines to help them build parts that meet their required design specifications.
There are three programs in the latest release:
1. VERICUT Composite Paths for Engineering (VCPe)
2. VERICUT Composite Simulation (VCS)
3. VERICUT Composite Programming (VCP)
VCPe gives users better insight into the effects of ATL and AFP path trajectory, material steering, surface curvature and other manufacturing process constraints. The software provides a producibility analysis of a fiber angle depending on the curvature of the part, as well as overlap and gaps for structural analysis. If you want to write tape course geometry to a given CAD format for further evaluation, you can do that too.
VCS reads NC (numeric control) programs as well as CAD models from VCP or another composite layup path-generation and simulates sequences on a virtual machine. Material is applied to the layup form in a CNC simulation environment and can be measured and inspected, which ensures that manufacturing standards and requirements are being followed.
VCP reads surface models like CATIA, STEP, V5 and ACIS. It also reads external PLY geometry and information from such software products as Fiberism and CATIA V5. The software fills the plies to your standards and requirements specs and then layup paths are linked to form specific layup sequence and are output as NC programs for the automated layup machine.
Simulating CNC machining to find errors, potential collisions and other inefficiencies help machinists and engineers design and perform their work better, faster and cheaper.
If you are interested in checking out the release notes, downloading the 8.0 flyer “Cheat sheet” to help navigate the menu changes, or want to request Version 8.0 click here.",https://www.engineering.com/AdvancedManufacturing/ArticleID/13876/CGTech-Now-Shipping-New-Release-of-VERICUT-CAM-Software.aspx,[[0.07044572]]
Siemens Partners with HP to Develop New Additive Manufacturing Software,"Industrial tech giants HP and Siemens have partnered to develop an Additive Manufacturing (AM) software module. The new software module, Siemens NX AM for HP Multi Jet Fusion, is available from Siemens as part of their PLM Software for additive manufacturing. The software will only work with the HP Multi Jet Fusion system.
The NX software module will allow customers to develop and manage parts in a single software environment for their 3D printing projects, avoiding data conversions and third-party tools. The software can be used with a project from design to finished part. Siemens and HP hope the new software will help engineers take better advantage of 3D printing’s capabilities.
Additive techniques have new, different limitations than conventional manufacturing. With today's 3D printers, it may be possible to cost-effectively produce new products at faster speeds than 3D printers of the past, which were mainly useful for prototyping.
Today, engineers and designers are used to following principles of conventional manufacturing processes such as injection molding. With additive, designs should be unconstrained by these principles. For example, a printed part can have internal features that would be impossible to release from a mold. As software and hardware advance with our understanding of the potential of the technology, this in turn will lead to expanded opportunities for the industrial-scale 3D printing of innovative designs.
According to the company, the NX software module will enable users to combine design, optimization, simulation, preparation of print jobs and inspection processes for HP Multi Jet Fusion 3D printed parts in a managed environment. Users can load multiple 3D part models into NX, auto nest the parts and submit them to an HP 3D printer.
In the future, the NX and Multi Jet Fusion integration is intended to allow control over including material characteristics down to the individual voxel-level. This will result in the ability to print parts with variable textures, density, strength and friction, as well as thermal, electrical and conductivity characteristics.
HP’s Multi Jet Fusion 3D is a commercial 3D printing system that uses powder bed fusion, in which an energy source—heat lamps, in this case—fuses particles of metal powder together point by point, layer by layer, until an object is complete. Siemens new software aims to provide product lifecycle management (PLM) and electronic design automation (EDA) software 3D printing solutions. Over time, as the hardware and software get better, manufacturers will establish additive manufacturing as a truly industrial production process.
For more information, visit Siemens and HP. For more on metal additive manufacturing, check out this great ENGINEERING.com whitepaper on the subject.",https://www.engineering.com/AdvancedManufacturing/ArticleID/15605/Siemens-Partners-with-HP-to-Develop-New-Additive-Manufacturing-Software.aspx,[[0.07043007]]
What does the factory of the future look like?,"Manufacturing has been earmarked by the World Economic Forum and the European Union as a major driver of increased employment opportunities, reduced carbon emissions and better educational prospects for young people. This huge ambition largely rests on the advent of the smart factory and the rollout of Industry 4.0, which will make manufacturing more affordable in high-wage countries.
The WEF sets out the scale of change in its paper on the Fourth Industrial Revolution (4IR). “The possibilities of billions of people connected by mobile devices, with unprecedented processing power, storage capacity, and access to knowledge, are unlimited. And these possibilities will be multiplied by emerging technology breakthroughs in fields such as artificial intelligence, robotics, the Internet of Things, autonomous vehicles, 3D printing, nanotechnology, biotechnology, materials science, energy storage, and quantum computing.”
Momentum for and the potential of the smart factory was very much in evidence at Discover London and featured a robot picker, designed by HPE in conjunction with the Frauhofer Institute. The robot, controlled by an algorithm in in the cloud, performed a fairly routine and simple task; but the potential for software-programmed and connected devices is much greater and eminently scalable.
Jacques Spee, HPE Industry Advisor on Manufacturing Industry Solutions at Enterprise Services, talked to me about the incremental revolution that is unfolding on the factory floor. Powered by the cloud, data analytics, the Internet of Things and hyper connectivity, the end result of these forces is the convergence of physical and digital manufacturing. Accompanying this shift is the opportunity to optimize not only a single plant fabric but an entire network of smart factories, he explained.
Enterprise Services has produced a customized slice of digital capabilities for manufacturing customers, called Converged Plant Infrastructure (CPI). “CPI is one essential part to make Industry 4.0 a reality. Manufacturing physical goods alone is not yielding you the utmost value – it needs to be augmented by a digital representation and a digital way of doing things”, said Jacques.
“CPI is the foundation of the smart factory in a Connected Manufacturing ecosystem where the operational machinery world and the information technology world get connected”, he continues. Networking machines, equipment and components on the factory floor enables the capture of more data than ever before. But as Jacques points out, the critical part is what you do with the data. “It lets our customers find patterns in operations; how to improve performance, gain more flexibility, and if it manufactures multiple products across multiple sites how optimise.”
A further aspect of the maturity of the digital offering for manufacturers and part of the CPI package was showcased at Discover by Hewlett Packard Enterprise Services – the Virtual Fort Knox. Analogous to an app store for the smartphone, it offers manufacturers a secure market place for smart digital products such as a dashboard for the factory floor. ‘Cloud-picking’, is another smart app that uses algorithms in the cloud to teach robots how, where and when to select components, while cloud navigation teaches HGVs how to self-drive.
This is a tantalising glimpse of what lies ahead in the factory of the future and to find out more, watch Jacques in conversation.",https://www.themanufacturer.com/articles/what-does-the-factory-of-the-future-look-like-2/,[[0.06829249]]
Oxford Martin School founder and GF2045 keynote speaker James Martin dies,"At Global Future 2045, in NYC, June 15-16, the keynote speaker represented rampant technological change as both a problem and a benefit, and it needed to be addressed as such. He died on June 24.
Martin established the Oxford Martin School in Oxford to focus on future challenges facing mankind and spoke eloquently about how technologists needed to work with all the other players involved with their products.
He worked with IBM and was the principal developer of real-time database systems including the American Airlines and BOAC reservation systems. He also wrote The Meaning of the 21st Century, which was made into a major film, narrated by Michael Douglas. He was a Pulitzer nominee for his book The Wired Society.",https://www.therobotreport.com/oxford-martin-school-founder-and-gf2045-keynote-speaker-james-martin-dies/,[[0.067842]]
Siemens Sees Atlas 3D as Part of Additive Manufacturing Puzzle,"Atlas 3D's Sunata software reduces downstream 3D printing errors caused by thermal distortion.
From day one, 3D printing was supposed to provide an easy avenue for companies to create anything. Unfortunately, potholes in the road have made it difficult from most firms to easily transition designs from small runs to useful production parts.
The high rate of 3D print failures is a key challenge companies face in leveraging additive manufacturing for high-volume production. Parts often need to go through several design and analysis iterations before the optimal build orientation and support structures are determined. Typically, designers don’t have the capabilities to consider such factors as part orientation, distortion, and heat extraction uniformity in their design. This puts the onus on engineering specialists to resolve such issues.
Sunata software, created by Plymouth, IN-based Altas 3D, aims to solve this problem by giving front-end designers a quick, easy and automated way to get much closer to a “right first time” build. Sunata is a GPU-accelerated high-performance computing additive manufacturing software solution that can deliver results up to one hundred times faster than other build simulation solutions on the market. GPU-accelerated computing is the employment of a graphics processing unit (GPU) along with a computer processing unit (CPU) to facilitate processing-intensive operations such as deep learning, analytics and engineering applications.
Joining Siemens
Siemens signed an agreement to acquire Atlas 3D Inc. as part of Siemens Digital Industries Software, where its solutions will expand additive manufacturing capabilities in the Xcelerator portfolio of software. Atlas' Sunata software that works with direct metal laser sintering (DMLS) printers to automatically provide design engineers with the optimal print orientation and requisite support structures for additive parts in near real-time.
Sunata software uses thermal distortion analysis to provide a simple, automated way to optimize part build orientation and generate support structures. This approach allows the designer—rather than the analyst—to perform these simulations, thereby reducing the downstream analysis that needs to be conducted via Simcenter software to achieve a part that meets design requirements.
Siemens plans to make the Atlas 3D solution available through its online Additive Manufacturing Network.
“We welcome Atlas 3D to the Siemens community as the newest member of our additive manufacturing team. Our solutions industrialize additive manufacturing for large enterprises, 3D printing service bureaus, design firms and CAD designers,” said Zvi Feuer, Senior Vice President, Manufacturing Engineering Software of Siemens Digital Industries Software. “The cloud-based Sunata software makes it easy for designers to determine the optimal way to 3D print parts for high quality and repeatability. The combination of Sunata with the robust CAE additive manufacturing tools in Simcenter enables a ‘right first time’ approach for industrial 3D printing.”
“The power of Sunata is that it equips designers to more easily design parts that are printable, which helps companies more quickly realize the benefits of additive manufacturing,” said Chad Barden, Chief Executive Officer of Atlas 3D. “As part of Siemens, we look forward to introducing Sunata to customers who already have Siemens’ AM solutions and can achieve new efficiencies in their front-end design-for-additive process, as well as companies who have yet to start their additive manufacturing journey.”",https://www.industryweek.com/technology-and-iiot/article/22028576/siemens-sees-atlas-3d-as-part-of-additive-manufacturing-puzzle,[[0.06757288]]
The Industrial Internet Consortium Updates Industrial Internet Vocabulary Technical Report,"The Industrial Internet Consortium (IIC), the organization focused on accelerating the adoption of the Industrial Internet of Things (IIoT), recently announced version 2.1 of the Industrial Internet Vocabulary Technical Report. Designed to reduce confusion in the marketplace, the report is a foundational document that provides a common set of definitions for IIoT terms used in all IIC documents. It is also intended as a reference for anyone working in IIoT, including those in IT, OT and vertical industries.
According to the IIC, the new version of the report serves an urgent need in the industry by defining new IIoT vocabulary terms that are widely used across many vertical industries. The report adds definitions for terms used in data management, edge and edge computing, IT/OT convergence, connectivity, interoperability, brownfield and greenfield.
“People from different backgrounds and different vertical industries will often use different terms to mean the same thing. Additionally, the industrial internet has core concepts that mean different things to different people,” said Anish Karmarkar, Co-Chair of the Vocabulary Task Group, and Senior Director, Standards Strategy & Architecture at Oracle. “Without an agreed upon vocabulary, there’s a lot of room for misunderstandings. For example, we’ve defined IT/OT convergence as a process of interweaving IT and OT in order to create IIoT systems. While IT/OT convergence is a hot topic today, not everyone is on the same page as to what it exactly means.”
The report provides definitions for data management, including data, data at rest, data in motion, data in use, data integrity and many others to make communication on this subject easier for IIoT stakeholders. The report also clears up confusion on “connectivity” and “interoperability,” which IIoT stakeholders often mix up. “Connectivity” means the ability of a system or app to communicate with other systems or apps via networks. “Interoperability” means the ability of two or more systems or apps to exchange and use that information.
“Edge and edge computing are hotly debated topics in IIoT this year,” said Marcellus Buchheit, one of the primary authors of the IIC IIoT Vocabulary Technical Report, and President & CEO, Wibu-Systems USA Inc. and Co-Founder, Wibu-Systems AG. “IIoT stakeholders in every industry have been asking ‘where is the edge,’ or ‘what is edge computing.’ The report defines the ‘edge’ as the boundary between pertinent digital and physical entities, delineated by IoT devices, and ‘edge computing’ as distributed computing that is performed near the edge, where the nearness is determined by the system requirements. At the moment, the IIC is the only consortium to provide definitions for ‘edge’ and ‘edge computing.’”
The IIC will continue to revise the IIC IIoT Vocabulary Technical Report with definitions for new IIoT terms. IIC IIoT Vocabulary Technical Report and a list of IIC members who contributed can be found (for free) on the IIC Website at https://www.iiconsortium.org/pdf/IIC_Vocab_Technical_Report_2.1.pdf",https://www.engineering.com/AdvancedManufacturing/ArticleID/17523/The-Industrial-Internet-Consortium-Updates-Industrial-Internet-Vocabulary-Technical-Report.aspx,[[0.06749499]]
Chewing over the Cognitive Factory,"The Manufacturer and IBM recently brought together some of the top minds and leading manufacturers in the country to discuss the state of British manufacturing at an invite-only dinner in Birmingham.
With some of the country’s most cutting-edge manufacturers and fast-moving SMEs, dinner guests chewed over the concept of Industry 4.0 and the cognitive factory.
Industry 4.0: Data lakes or information puddles
One of the biggest discussion points from the evening was, “How do we make Industry 4.0 profitable?” Outlays on automation machinery, connected systems, cloud computing and sensors can all add up extremely quickly to those undergoing a digital transformation and it isn’t always immediately apparent what to do with all of the new capabilities.
Big data is one of the areas that manufacturers have been encouraged to explore, but the plethora of data that can be collected often creates what is known as a ‘data lake’. Data flows in to a growing pool of information without being used.
Guests discussed differing views on data collection, ‘edge’ processing and the validity of data retention. There was agreement that getting some kind of insight (and therefore value) out of data is a key element to evolving manufacturing efficiency. A discussion on whether lakes of unused data were a waste of resource or a future enabler elicited varied views.
The consensus was that data needs to be collected and stored in smaller, more manageable sections so that real value can be pulled from it. A phrase used was ‘information puddles’, demonstrating an acceptance that certain information will likely be siloed in an organisation with limited value in a business case to join all information together. These puddles can then be sifted through to find value and steer businesses towards new business models and service offerings from the insight.
How do you monetise big ideas?
Large companies and organisations such as the Catapults, are constantly pushing the envelope of what is possible in manufacturing, spending millions developing new ways to improve processes and overhaul businesses.
The bleeding-edge technology and ideas behind them are astounding, the issue is successfully commercialising those innovations. Additive manufacturing was cited as being one of the areas of incredible growth that industry hasn’t yet been able to fully exploit.
The next big step for industry is to take the cutting-edge technologies and give them a viable use in the modern manufacturing setting, considering adoption challenges outside of the pure technology including business operating models, change management and commercial implications.
Give them the dumb jobs
One of the major talking points of the evening was around automation and the effect it is having on manufacturing. A wide range of companies attended the dinner from a variety of sectors that gave a broad reaching insight in to the industry and some pertinent comments regarding automation.
Many revolved around augmenting human effort in order to free up engineers to do the “important, higher value” jobs. If it is a boring job, a low value job or a job that makes life difficult for operators, then it should be automated was the consensus. This goes to prove the point made in The Manufacturer’s Annual Manufacturing Report 2017, that less than a third of recent automation projects were aimed at reducing staff costs.
Freeing up the workforce to do jobs that further the business was a key theme to come from discussions about automation. If employing a robot alleviates the pressures placed on engineers and free them up to address real business concerns this is more likely to help UK improve overall productivity.
Industrial Evolution or Revolution?
Despite many firms adopting strategies around Industry 4.0, many organisations and individuals are sceptical about the language surrounding the term. The Fourth Industrial Revolution is set as the backdrop to the recent innovation, but there was a split in those attending whether or not that was the case.
There seems to be two very distinct pools of thought emerging when it comes to Industry 4.0; one school believes that the technology and increased capabilities are truly revolutionary and that we have never seen anything like this before. The other is that Industry 4.0 is simply a continuation of the innovation that has become synonymous with the manufacturing sector over the past 150 years.
It was a discussion point that proved very divisive, with some diners pointing to how the adoption of computers in manufacturing was seamless and wasn’t hailed with the same sort of fanfare as Industry 4.0. Others argued that much like steam, electrification and the internet, manufacturing is undergoing a seismic shift that marks a new era of productivity. The idea that a banner such as “I4.0” creates a useful flag for manufacturing companies to address innovation was thought to help and create general awareness across the wider industrial community.
If you’re interested in the themes raised in this dinner then please also watch the accompanying webinar hosted by IBM and The Manufacturer, click here.",https://www.themanufacturer.com/articles/chewing-over-the-cognitive-factory/,[[0.06676802]]
Mazak Certifies CNC Software Inc. as Newest VIP Partner,"Mazak has certified CNC Software Inc., a developer and supplier of computer-aided manufacturing (CAM) software, as the newest member of its Value Inspired Partners (VIP) technology program.
CNC Software established its reputation with the development of Mastercam CAD/CAM software.
The VIP program is intended to bring together producers of complementary technologies to create more innovative products and turnkey processes. Collaborating on R&D and integration efforts, the VIP program was designed to foster cooperation and technological integration.
The program also fuels the development of training solutions and seminars for manufacturers.
As a VIP, CNC Software brings programming solutions for milling, turning, wire EDM, router programming, plasma cutting and lasers, along with 3D design and drafting to Mazak customers.
Founded in 1983, CNC Software is one of the oldest companies in the PC-based CAD/CAM industry. It was one of the first to introduce CAD/CAM software designed for both machinists and engineers. While the original version of Mastercam focused on two-dimensional (2D) CAM, it was also one of the first micro-based CAM packages to include CAD capabilities.
For more information, visit the websites for Mazak and CNC Software Inc.",https://www.engineering.com/AdvancedManufacturing/ArticleID/12088/Mazak-Certifies-CNC-Software-Inc-as-Newest-VIP-Partner.aspx,[[0.06652919]]
Daimler and Bosch self-driving pilot will be held in California,"technologyDaimlerUS
The Germany-based automotive companies, Daimler and Bosch, are set to test self-driving vehicles in central California, New Atlas reports.
The firms will receive computing power from Silicon Valley’s technology company, Nvidia, and are using the unnamed California city as a trial for the SAE level 4/5 autonomous vehicles.
The project will commence towards the end of 2019 when Nvidia will use its expertise to develop the computing platform that is used on autonomous cars, despite being owned by Bosch and Daimler.
It is anticipated that the platform will process trillions of operations per second through the use of artificially intelligent processing for real-time responses.
See more:
Dr. Stephan Honle, Senior VP of Business Unit Automated Driving at Robert Bosch GmbH, said: “Developing automated driving to a level ready for series production is like a decathlon.”
“It's not enough to be good in one or two areas,” he continued.
Through the partnership, the companies aim to successfully operate a self-driving vehicle safely in urban and city environments.
Bosch and Daimler’s work will primarily take place in Silicon Valley, in addition to using its home base in Germany.",https://www.manufacturingglobal.com/technology/daimler-and-bosch-self-driving-pilot-will-be-held-california,[[0.06575786]]
New technology could help solve AI's 'memory bottleneck',"Memory-hungry, power-sapping big data might finally have met its match.
Electrical engineers at Northwestern University and the University of Messina in Italy have developed a new magnetic memory device that could potentially support the surge of data-centric computing, which requires ever-increasing power, storage and speed.
Based on antiferromagnetic (AFM) materials, the device is the smallest of its kind ever demonstrated and operates with record-low electrical current to write data.
""The rise of big data has enabled the emergence of artificial intelligence (AI) in the cloud and on edge devices and is fundamentally transforming the computing, networking and data storage industries,"" said Northwestern's Pedram Khalili, who led the research. ""However, existing hardware cannot sustain the rapid growth of data-centric computing. Our technology potentially could solve this challenge.""
The research will be published on Feb. 10 in the journal Nature Electronics.
Khalili is an associate professor of electrical and computer engineering in Northwestern's McCormick School of Engineering. He co-led the study with Giovanni Finocchio, an associate professor of electrical engineering at the University of Messina. The team also included Matthew Grayson, a professor of electrical and computer engineering at McCormick. Jiacheng Shi and Victor Lopez-Dominguez, who are both members of Khalili's laboratory, served as co-first authors of the paper.
From promise to probable
Although AI offers promise to improve many areas of society, including health care systems, transportation and security, it can only meet its potential if computing can support it.
Ideally, AI needs all the best parts of today's memory technologies: Something as fast as static random access memory (SRAM) and with a storage capacity similar to dynamic random access memory (DRAM) or Flash. On top of that, it also needs low power dissipation.
""There is no existing memory technology that meets all of these demands,"" Khalili said. ""This has resulted in a so-called 'memory bottleneck' that severely limits the performance and energy consumption of AI applications today.""
To meet this challenge, Khalili and his collaborators looked to AFM materials. In AFM materials, electrons behave like tiny magnets due to a quantum mechanical property called ""spin,"" but the material itself does not demonstrate a macroscopic magnetization because the spins are aligned in antiparallel fashion.
Typically, memory devices require an electric current to retain stored data. But in AFM materials, it is the magnetically ordered spins that perform this task, so a continuously applied electric current is not needed. As an added bonus, the data cannot be erased by external magnetic fields. Because densely packed devices will not interact with magnetic fields, AFM-based devices are very secure and easy to scale down to small dimensions.
Easily adoptable technology
Because they are inherently fast and secure and use lower power, AFM materials have been explored in past studies. But previous researchers experienced difficulties controlling the magnetic order within the materials.
Khalili and his team used pillars of antiferromagnetic platinum manganese—a geometry not previously explored. With a diameter of just 800 nanometers, these pillars are 10 times smaller than earlier AFM-based memory devices.
Importantly, the resulting device is compatible with existing semiconductor manufacturing practices, which means that current manufacturing companies could easily adopt the new technology without having to invest in new equipment.
""This brings AFM memory—and thus highly scaled and high-performance magnetic random-access memory (MRAM)—much closer to practical applications,"" Khalili said. ""This is a big deal for industry as there is a strong demand today for technologies and materials to extend the scaling and performance of MRAM and increase the return on the huge investment that industry has already made in this technology to bring it to manufacturing.""
Khalili's team is already working on the next steps toward this translation to applications.
""We are working now to further downscale these devices and to improve methods to read out their magnetic state,"" Khalili said. ""We also are looking at even more energy-efficient ways to write data into AFM materials, such as replacing the electric current with an electric voltage, a challenging task that could further increase the energy efficiency by another order of magnitude or more.""
Provided by Northwestern University",https://techxplore.com/news/2020-02-technology-ai-memory-bottleneck.html,[[0.06575107]]
“AI is on the verge of changing everything” said Charlie Rose on CBS 60 Minutes,"In a quest to understand why and where all the billions of dollars are being spent on Artificial Intelligence (AI), Charlie Rose and the CBS 60 Minutes team took us on a journey to a cancer hospital in North Carolina, Austin, Texas, and the Carnegie Mellon University robotics lab in Pittsburgh.
Governments, companies and universities are investing billions and their best minds into AI-related sciences and their efforts are beginning to pay off.
“A very comprehensive tool”
IBM is staking its future on Watson and its learning ability, particularly their deep learning which Rose characterized as “machines learning through experience, much like how humans do.” Thus far IBM has invested $15 billion in this effort.
In a 1,000 person study of cancer cases done by Chappel Hill, NC cancer doctors, IBM's Watson concurred 99% of the time with the conclusions reached by the oncologist teams, however, in 30% of the cases Watson found a new treatment or trial that was more up-to-date and with a higher chance of successful outcome than the human teams had found.
More recently Watson has been trained to see and review scans and highlight what is normal and what isn't.
Asked to sum up what Watson is doing for his hospital and oncology department, Dr. Ned Sharpless, of the UNC Lineberger Cancer Center said, “Watson is a very comprehensive tool.”
Baidu and Andrew Ng
Not to be outdone, Baidu, China's biggest search engine, launched an AI-powered chatbot to connect with patients and doctors. The new bot is called Melody, the medical assistant.
Baidu is making this effort because they fear a global shortfall of almost 13 million health-care professionals within two decades, according to the World Health Organization.
“I don't know how else to solve this problem other than to use AI,” said Andrew Ng, chief scientist at Baidu Research; Co-Chairman and Co-Founder of Coursera; and an Adjunct Professor at Stanford University. “I'm seeing just the beginnings of what will be a major trend of AI systems in health care.”
Baidu has built a 1,000-person team to work on AI, which Ng said is one of the company's top priorities. The app launched in China — the world's biggest smartphone market — along with doctor and health-care organization partners. The company is in talks with health-care organizations in the U.S. and Europe, said Ng.
Carnegie Mellon (CMU)
The 60 Minutes team explored the campus’ robotics and artificial intelligence labs with former Google VP Andrew Moore, who now runs the Carnegie Mellon’s School of Computer Science. Moore says his goal is to nurture the next generation of computer scientists who could change the world through innovation.
“When you’re programming a robot, it’s like magic, and so the thing I tell middle schoolers is the closest thing to getting to go to Hogwarts is being able to do robotics and A.I.”
“The biggest problems of the world — terrorism, mass migration, climate change — when I look at these problems, I don’t feel helpless. I feel that this generation of young computer scientists is actually building technology to put the world right.”
Artificial General Intelligence (AGI)
Artificial general intelligence (AGI) is the intelligence of a machine that could successfully perform any intellectual task that a human being can. It is a primary goal of artificial intelligence research and an important topic for science fiction writers and futurists. Charlie Rose interviewed David Hansen and his new Sophia robot during a South by Southwest event in Austin, TX during which one can see the present state of the art in artificial general intelligence. Sophia misses cues, makes inappropriate responses and can't really carry on a conversation – but that's not to say that researchers like Hansen aren't well on their way to writing code that can learn and write its own code predicated on what it learned (and never forgets).
Compare this video to a more descriptive Hanson video interview on CNBC:
Most mainstream AI researchers doubt that progress will be as rapid as the timeline suggested by Ray Kurzweil in his book “The Singularity is Near.” He predicts AGI will become available sometime between 2025 and 2045. But the race is on and fueled by the billions of dollars of investment being spent worldwide and the talent grab for the smartest teams of scientiests and their companies to make real AGI happen.",https://www.therobotreport.com/ai-is-on-the-verge-of-changing-everything-said-charlie-rose-on-cbs-60-minutes/,[[0.06559768]]
How technology is shaping a new era for the manufacturing workforce,"By Nick Offin, Head of Sales, Marketing and Operations, Toshiba Northern Europe . Dec 22, 2018, 9:00AM
The manufacturing industry is poised to transform the way its employees work in the coming years, beneftting from technological advances taking place at an unprecedented rate. In recent times, device advancements and the arrival of 4G and cloud have enabled organisations to transition to new levels of efficiency, but a new wave of technological innovations are set to drive this further. The manufacturing industry – with a significant proportion of field-based and frontline workers – is well-placed to be at the forefront of this trend. But what are the catalysts behind this new era of mobility, and where will it take the manufacturing sector?
5G creating a new era of mobility
The mainstream arrival of 5G will not only provide enhanced network speeds, but also greater capacity, both which should enable manufacturers to deliver new capabilities to their workforces. Through 5G, they will benefit from faster download and upload speeds, lower latency, and the ability to run greater capacity applications simultaneously – something particularly useful within a sector where heavy-duty machinery and complex software solutions are integral to product development and innovation.
But a subsequent impact of 5G – and where many organisations expect to see its true value – will be in its ability to serve as the foundations for greater IoT adoption in the enterprise. According to Ericsson’s recent mobility report, the number of cellular IoT connections is expected to reach 4.1 billion by 2024, with the company highlighting how such connections will help companies “to address the diverse and evolving requirements across a wide range of use cases,” one of which being manufacturing.
Through the looking glass of IoT
A recent Zebra survey found that 86% of organisations expect to increase their spending on IoT over the next couple of years. 5G, when combined with the arrival of mobile edge computing solutions, is creating an environment with the capacity, speed and data efficiency needed for widespread IoT adoption and innovation. As a result, we’re already seeing wearable solutions – most notably smart glasses – begin to permeate the workplace. By tethering to a mobile edge computing solution which, through processing data at the edge reduces latency and operational strain on the network core, this new wave of IoT-based solutions can have a considerable impact on digitally transforming the manufacturing sector.
See also
Take, for example, workers on the manufacturing line in an assembly plant. Assisted Reality smart glasses can be used by employees to access and overlay highly-detailed specifications or instructions in real-time, ensuring greater manufacturing precision, reduced errors, and a more efficient overall process. Remote expertise can also be sought through collaboration tools, all while providing a hands-free experience so actions can be undertaken in real-time.
Securing the future
Of course, the rise of IoT brings with it data proliferation at an unprecedented scale, meaning the workforce of the future must be both educated about and protected against an increasingly diverse array of cyber-threats. SonicWall research, for example, revealed a 275% annual increase in the number of encrypted threats, as well as a 101.2% rise in the number of ransomware variants in 2017. And manufacturers are finding themselves in the firing line. An EEF report found 48% to have at some point been affected by a cyber-attack – half of which suffered financial loss or business disruption as a result. Again, mobile edge computing solutions can play an important role here – especially as IT leaders try to ensure security across an ever-extending network perimeter – by enabling data communication to be locally encrypted and translated to a communication protocol before being sent to the company’s network core via the cloud.
Given the nature of the threat faced by the industry, it’s no real surprise to see that 72% of IT decision makers within manufacturing regard data security as a key IT investment, according to Toshiba. Of course, field-based and frontline workers offer concerns in this respect, but equally the traditional office-based workers – whether in finance, sales or HR – are also potential weak links, especially as mobile and remote working continue to grow in popularity. To ensure the workforce remains protected, manufacturers need to educate their employees about implementing an authentication strategy as part of the businesses’ IT infrastructure – including laptops which boast biometric features such as fingerprint sensors, and other deeper security solutions like mobile edge computing that can recognise cyber threats before they reach the network.
Manufacturers are now entering an environment in which they are able to accumulate, analyse and act on data – itself collected in more diverse and convenient locations – and use that to create further competitive advantages and revenue streams. Within such an environment, the future workforce must strive to learn and embrace new skills and capabilities delivered by IoT solutions which can drive new levels of digital transformation across the sector.",https://www.manufacturingglobal.com/technology/how-technology-shaping-new-era-manufacturing-workforce,[[0.06549543]]
Capgemini: Smart factories could add $1.5trn to global economy,"technologySmart Manufacturing
In its latest report, multinational consultancy firm Capgemini predicts that smart factories are set to become revolutionary within the manufacturing industry.
The report found that smart factories could add anywhere between $500bn to $1.5trn in value to the global economy over the next five years, as firms increasingly look to digitise their operations in order to stay ahead of the game.
See also:
“Manufacturing under Industry 4.0 has access to digital technologies such as the Internet-of-Things, Big Data Analytics, Artificial Intelligence, Advanced Robotics, 3D printing, and Cloud Computing that have opened the door to incredible gains for early adopters,” Capgemini stated.
Currently, only 6% of manufacturers can be classified as ‘digital masters’. This, combined with the fact that as many as 76% of manufacturers currently have a smart factory initiative whilst only 14% of these are satisfied, suggests that the market for smart factories is set to explode within the next decade.
Business expectations are also likely to act as a driving factor, with manufacturers expecting on-time-delivery to accelerate by 13 times compared to 1990.
The potential benefits that would be available to businesses are countless, with the likes of IoT, big data analytics, AI, robotics, 3D printing and cloud-based computing services all paving the way for success.
Key sectors where manufacturers are already harnessing the potential of smart factories include industrial manufacturing, automotive, consumer goods, energy & utilities, aerospace & defence and the pharma, biotech and life science industries.",https://www.manufacturingglobal.com/technology/capgemini-smart-factories-could-add-15trn-global-economy,[[0.06457754]]
"What’s all the fuss about AI, robotics and China?","In the constantly changing landscape of today’s global digital workspace, AI’s presence grows in almost every industry. Retail giants like Amazon and Alibaba are using algorithms written by machine learning software to add value to the customer experience. Machine learning is also prevalent in the new Service Robotics world as robots transition from blind, dumb and caged to mobile and perceptive.
Competition is particularly focused between the US and China even though other countries and global corporations have large AI programs as well. The competition is real, fierce and dramatic. Talent is hard to find and costly. It’s a complex field that few fully understand, consequently the talent pool is limited. Grabs of key players and companies headline the news every few days. “Apple hires away Google’s chief of search and AI.” “Amazon acquires AI cybersecurity startup.” “IBM invests millions into MIT AI research lab.” “Oracle acquires Zenedge.” “Ford acquires auto tech startup Argo AI.” “Baidu hires three world-renowned artificial intelligence scientists.”
Media, partly from the complexity of the subject, and partly from lack of knowledge, frighten people with scare headlines about misuse and autonomous weaponry. They exaggerate the competition into a hotly contested war for mastery of the field. It’s not really a “war” but it is dramatic and it’s playing out right now on many levels: immigration law, intellectual property transgressions, trade war fears, labor cost and availability challenges, and unfair competitive practices as well as technological breakthroughs and lower costs enabling experimentation and testing.
Two recent trends have sparked widespread use of machine learning: the availability of massive amounts of training data, and powerful and efficient parallel computing. GPUs are parallel processors and are used to train these deep neural networks. GPUs do so in less time, using far less datacenter infrastructure than non-parallel-processing super-computers.
Service and mobile robots often need to have all their computing power onboard as compared to stationary robots with control systems in separate nearby boxes. Sometimes onboard computing involves multiple processors; other times it necessitates super-computing power such as offered by chip makers that offer parallel processing and super-computer speeds. Nvidia’s Jetson chip, Isaac lab, and toolset are an example.
Nvidia
The recent Nvidia GPU Developers Conference held in San Jose last month highlighted Nvidia’s goal to capture the robotics AI market. They’ve set up an SDK and lab to help robotics companies capture and learn from the amount of data they are processing as they go about their tasks in mobility and vision processing.
Nvidia’s Jetson GPU, SDK, toolset and simulation platform are designed to help roboticists build and test robotics applications and simultaneously manage all the various onboard processes such as perception, navigation and manipulation. As a demonstration of the breath of capabilities in their toolset, Nvidia had a delivery robot to cart around objects at the show.
Nvidia is offering libraries, SDK, APIs, an open source deep learning accelerator, and other tools to encourage the use by robot makers for them to incorporate Nvidia chips into their products. Nvidia sees this as a future source of revenue. Right now it is mostly all research and experimentation.
Examples of deep learning in robotics
In a recent CBInsights graphic categorizing the 2018 AI 100, 12 companies were highlighted in the robotics and auto technology sectors. Note from the Venn Diagram that not all AI companies are involved with robotics (in fact, most aren’t – there were 2,000+ startups in the pool of companies from which the 100 were chosen). The same is true for robotics.
Here are four use cases of robot companies using AI chips in their products:
Cobalt Robotics – Says CEO and Co-founder Travis Deyle, “Cobalt uses a high-end NVidia GPU (a 1080 variant) directly on the robot. We do a lot of processing locally (e.g. anomaly detection, person detection, etc) using a host of libraries: CUDA, TensorFlow, and various computer vision libraries. The algorithms running on the robot are just the tip of the iceberg. The on-robot detectors and classifiers are tuned to be very sensitive; upon detection, data is transmitted to the internet and runs through an extensive cloud-based machine learning pipeline and ultimately flags a remote human specialist for additional input and high-level decision making. The cloud-based pipeline also makes use of deep-learning processing power, which is likely powered by NVidia as well.”
Bossa Nova Robotics – Walmart is partnering with San Francisco-based robotics Bossa Nova on robots that roam the grocery and health products aisles of Walmart stores, auditing shelves and then sending data back to employees to ensure that missing items are restocked, as well as locating incorrect prices and wrong or missing labels. Bossa Nova’s Walmart robots house three Nvidia GPUs: one for navigation and mapping; another for perception and image stitching (it’s viewing 6′ of shelving at 2 mph); and for computing and analyzing what it’s seeing and turning that info into actionable restocking reports.
Fetch Robotics – Fetch Robotics’ automated material transports and Fetch’s new data survey line of AMRs, all, in addition to navigation, collision avoidance and mapping, collect data continuously and consistently. When the robots recharge themselves, all the stored collected data is uploaded to the cloud for post-processing and analytics.
TUSimple (CN) – Beijing-based TuSimple’s truck driving technology is focused on the middle mile, ie, the need for transporting container boxes from one hub to another. Along the way TUSimple trucks are able to detect and track objects at distances of greater than 300 meters through advanced sensor fusion that combines data from multiple cameras using decimeter-level localization technology. Simultaneously, the truck’s decision-making system dynamically adapts to road conditions including changing lanes and adjusting driving speeds. TuSimple uses NVIDIA GPUs, NVIDIA DRIVE PX 2, Jetson TX2, CUDA, TensorRT and cuDNN in its autonomous driving solution.
The China factor
Twelve years ago, as a national long-term strategic goal, China crafted 5-year plans with specific goals to encourage the use of robots in manufacturing to enhance quality and reduce the need for unskilled labor, and to establish the manufacture of robots in-country to reduce the reliance on foreign suppliers. After three successive well funded and fully incentivized 5-year robotics plans, one can easily see the transformation: robot and component manufacturers have grown from fewer than 10 to more than 700 while companies using robots in their manufacturing and material handling process have grown similarly.
[NOTE: During the same period, America implemented various manufacturing initiatives involving robotics, however none were comparably funded or, more importantly, continuously funded over time.]
Recently China turned its focus to artificial intelligence. Specifically, they’ve set out a three-pronged plan to catch up by 2020, achieve mid-term parity in autonomous vehicles, image recognition and, perhaps, simultaneous translation by 2025, and lead the world in AI and machine learning by 2030.
Western companies doing business in China have been plagued by intellectual property thievery, copying and reverse engineering, and heavy-handed partnerships and joint ventures where IP must be given to the Chinese venture. Steve Dickinson, a lawyer with Harris | Bricken, a Seattle law firm whose slogan is “Tough Markets; Bold Lawyers,” wrote:
“With respect to appropriating the technology and then selling it back into the developed market from which it came: that is of course the Chinese strategy. It is the strategy of businesses in every developing country. The U.S. followed this approach during the entire 19th and early 20th centuries. Japan and Korea and Taiwan did it with great success in the post WWII era. That is how technical progress is made.”
“It is clear that appropriating foreign AI technology is the goal of every Chinese company operating in this sector [robotics, e-commerce, logistics and manufacturing]. For that reason, all foreign entities that work with Chinese companies in any way must be aware of the significant risk and must take the steps required to protect themselves.”
What is really clear is that where data in large quantity is available, as in China, and where speed is normal and privacy is nil, as in China, AI techniques such as machine and deep learning can thrive and achieve remarkable results at breakneck speed. That’s what is happening right now in China.
Bottom line:
Growth in the service robotics sector is still a promise more than a reality and there is a pressing need to deliver on those promises. We have seen tremendous progress on processors, sensors, cameras and communications but so far the integration is lacking. One roboticist characterized the integration of all that data as a need for a “reality sensor”, i.e., a higher-level indicator of what is being seen or processed. If the sensors pick up a series of pixels that are interpreted to be a person, and the processing determines its motion to be intersecting with your robot, it would be helpful to know whether it’s a pedestrian, a policeman, a fireman, a sanitation worker, a construction worker, a surveyor, etc. That information would help refine the prediction and your actions. It would add reality to image processing and visual perception.
Even as the ratio of development in hardware to software shifts more toward software, there are still many challenges to overcome. Henrik Christensen, the director of the Institute for Contextual Robotics at the University of California San Diego, cited a few of those challenges:
Better end-effectors / hands. We still only have very limited capability hands and they are WAY too expensive
The user interfaces for most robots are still very limited, eg, different robots have different chargers
The cost of integrating systems is very high. We need much better plug-n-play systems
We see lots of use of AI / deep learning but in most cases without performance guarantees; not a viable long-term solution until things improve
One often forgets the science involved in robotics, embedded AI, and the many challenges remaining until we have a functional fully-capable, fully-interactive service robot.",https://www.therobotreport.com/whats-all-the-fuss-about-ai-robotics-and-china/,[[0.06381154]]
Averna releases solution for software management,"Averna has developed a new test package manager software solution with the release of Averna Deploy, the latest in the company’s smart data management suite.
The program ensures all manufacturing activities remain accurate and reliable with the most up-to-date software versions installed on systems throughout smart facilities.
All updated software revisions are automatically deployed to every test station and asset throughout production plants. In addition, users have the ability to select the code they need on the test station they want.
The intelligent software comes with a mechanism to prevent tests from running should a machine be outdated, guaranteeing accurate and consistent data.",https://www.automationmag.com/averna-releases-solution-for-software-management/,[[0.06277288]]
Brain-like computer chips could address privacy concerns and greenhouse emissions,"A team lead by Professor Simon Brown at the University of Canterbury (UC) has developed computer chips with brain-like functionality, that could significantly reduce global carbon emissions from computing.
Published this week in prestigious peer-reviewed journal Science Advances, the paper proves signals on the chips are remarkably like those that pass through the network of neurons in the brain. This is important for building new kinds of computers because the brain is incredibly good at processing information using very small amounts of energy. Brain-like computing could enable ""edge computing"" and address the ever increasing energy consumption of computers. It would also significantly reduce the amount of data shared with companies like Google and Facebook, and reduce global carbon emissions from computing.
The chips are based on self-organisation of nanoparticles – taking advantage of physical principles at unimaginably small scales, a hundred thousand times smaller than the thickness of a human hair, to make brain-like networks.
The components of this new chip are at the atomic level and are so small they cannot be seen with the naked eye or conventional microscopes, and can only be seen in electron microscopes.
""The research shows that this type of chip really does mimic the signalling behaviour of the brain. We were surprised at the extent to which the avalanches or cascades of voltage pulses on our chips replicate the avalanches of 'action potentials' that are observed in the brain. These are the signals that pass instructions from one 'neuron' to another, and so replicating them is an important step towards being able to make computer chips with brain-like functionality,"" Professor Brown says.
""These chips might provide a different kind of artificial intelligence. By understanding the underlying fundamental physical processes, we believe we can design these chips and control their behaviour to do things like pattern or image recognition,"" he says. ""The key is that processing on-chip and with low power consumption opens up new applications that are not currently possible.""
Potential applications of on-chip pattern recognition technology can be found in retinal scans on cell phones, robotics, autonomous vehicles and biomedical devices. The team is conscious of concerns about AI and works with social scientists to understand ethical considerations in tandem with the research. It is possible that by allowing more data processing to take place on cell phones, the technology might by-pass concerns about sharing data with big companies like Facebook and Google.
Avalanches and criticality in self-organised nanoscale networks is co-authored by doctoral students Josh Mallinson, Shota Shirai and Edoardo Galli, and postdoctoral fellows Susant Acharya and Saurabh Bose. The research shows the chips are based on self-organisation of nanoparticles – taking advantage of physical principles at unimaginably small scales, a hundred thousand times smaller than the thickness of a human hair, to make brain-like networks.
Provided by University of Canterbury",https://techxplore.com/news/2019-11-brain-like-chips-privacy-greenhouse-emissions.html,[[0.0621018]]
Time to Update Engineering Colleges,"It’s time engineering colleges took a look at their curriculums and majors and made some changes. There’s already almost too much “essential” engineering knowledge these days to expect graduates coming out of traditional discipline tracks (EE, Mech E, Materials, even Civil E) to be productive in their first year or more in real engineering jobs. More co-ops couldn’t hurt, especially if they emphasized hands-on time with modern manufacturing tools (CNC, metalworking, injection modeling, IC design and construction).
The concept of a core of engineering courses seems like a good one. It provides a common base of need-to-know information and gives all the engineering students something in common. But that core should be updated to weed out courses that are a waste of time and money. For example, one course that apparently could be tossed is Differential Equations. It was voted the most useless course in a landslide in an informal poll of our audience a few years ago. One retired electrical engineer explained that the course was taught mostly to keep math professors busy and employed. Required physics courses on quantum mechanics and special relativity also failed to prove useful in most engineering careers.
There also some engineering schools that require Phys Ed. Now while the gyms, swimming pools, playing fields, and courts are nice to have, they don’t contribute much to an engineering education. If I were cynical, I’d say Phys Ed requirements are a roundabout way to keep coaches employed.
The core courses should also be expanded to include topics every good engineer should be familiar with, such as intellectual property law, the economics of manufacturing, engineering ethics, and written and oral communications. Then you can get rid of any requirements in humanities and social studies. The library has everything students will ever need to know in those subjects.",https://www.industryweek.com/talent/education-training/article/22005835/time-to-update-engineering-colleges,[[0.06110714]]
Helping computers perceive human emotions,"Personalized machine-learning models capture subtle variations in facial expressions to better gauge how we feel.
MIT Media Lab researchers have developed a machine-learning model that takes computers a step closer to interpreting our emotions as naturally as humans do.
In the growing field of “affective computing,” robots and computers are being developed to analyze facial expressions, interpret our emotions, and respond accordingly. Applications include, for instance, monitoring an individual’s health and well-being, gauging student interest in classrooms, helping diagnose signs of certain diseases, and developing helpful robot companions.
A challenge, however, is people express emotions quite differently, depending on many factors. General differences can be seen among cultures, genders, and age groups. But other differences are even more fine-grained: The time of day, how much you slept, or even your level of familiarity with a conversation partner leads to subtle variations in the way you express, say, happiness or sadness in a given moment.
Human brains instinctively catch these deviations, but machines struggle. Deep-learning techniques were developed in recent years to help catch the subtleties, but they’re still not as accurate or as adaptable across different populations as they could be.
The Media Lab researchers have developed a machine-learning model that outperforms traditional systems in capturing these small facial expression variations, to better gauge mood while training on thousands of images of faces. Moreover, by using a little extra training data, the model can be adapted to an entirely new group of people, with the same efficacy. The aim is to improve existing affective-computing technologies.
“This is an unobtrusive way to monitor our moods,” says Oggi Rudovic, a Media Lab researcher and co-author on a paper describing the model, which was presented last week at the Conference on Machine Learning and Data Mining. “If you want robots with social intelligence, you have to make them intelligently and naturally respond to our moods and emotions, more like humans.” Co-authors on the paper are: first author Michael Feffer, an undergraduate student in electrical engineering and computer science; and Rosalind Picard, a professor of media arts and sciences and founding director of the Affective Computing research group.
Personalized experts
Traditional affective-computing models use a “one-size-fits-all” concept. They train on one set of images depicting various facial expressions, optimizing features — such as how a lip curls when smiling — and mapping those general feature optimizations across an entire set of new images.
The researchers, instead, combined a technique, called “mixture of experts” (MoE), with model personalization techniques, which helped mine more fine-grained facial-expression data from individuals. This is the first time these two techniques have been combined for affective computing, Rudovic says.
In MoEs, a number of neural network models, called “experts,” are each trained to specialize in a separate processing task and produce one output. The researchers also incorporated a “gating network,” which calculates probabilities of which expert will best detect moods of unseen subjects. “Basically the network can discern between individuals and say, ‘This is the right expert for the given image,’” Feffer says.
For their model, the researchers personalized the MoEs by matching each expert to one of 18 individual video recordings in the RECOLA database, a public database of people conversing on a video-chat platform designed for affective-computing applications. They trained the model using nine subjects and evaluated them on the other nine, with all videos broken down into individual frames.
Each expert, and the gating network, tracked facial expressions of each individual, with the help of a residual network (“ResNet”), a neural network used for object classification. In doing so, the model scored each frame based on level of valence (pleasant or unpleasant) and arousal (excitement) — commonly used metrics to encode different emotional states. Separately, six human experts labeled each frame for valence and arousal, based on a scale of -1 (low levels) to 1 (high levels), which the model also used to train.
The researchers then performed further model personalization, where they fed the trained model data from some frames of the remaining videos of subjects, and then tested the model on all unseen frames from those videos. Results showed that, with just 5 to 10 percent of data from the new population, the model outperformed traditional models by a large margin — meaning it scored valence and arousal on unseen images much closer to the interpretations of human experts.
This shows the potential of the models to adapt from population to population, or individual to individual, with very few data, Rudovic says. “That’s key,” he says. “When you have a new population, you have to have a way to account for shifting of data distribution [subtle facial variations]. Imagine a model set to analyze facial expressions in one culture that needs to be adapted for a different culture. Without accounting for this data shift, those models will underperform. But if you just sample a bit from a new culture to adapt our model, these models can do much better, especially on the individual level. This is where the importance of the model personalization can best be seen.”
Currently available data for such affective-computing research isn’t very diverse in skin colors, so the researchers’ training data were limited. But when such data become available, the model can be trained for use on more diverse populations. The next step, Feffer says, is to train the model on “a much bigger dataset with more diverse cultures.”
Better machine-human interactions
Another goal is to train the model to help computers and robots automatically learn from small amounts of changing data to more naturally detect how we feel and better serve human needs, the researchers say.
It could, for example, run in the background of a computer or mobile device to track a user’s video-based conversations and learn subtle facial expression changes under different contexts. “You can have things like smartphone apps or websites be able to tell how people are feeling and recommend ways to cope with stress or pain, and other things that are impacting their lives negatively,” Feffer says.
This could also be helpful in monitoring, say, depression or dementia, as people’s facial expressions tend to subtly change due to those conditions. “Being able to passively monitor our facial expressions,” Rudovic says, “we could over time be able to personalize these models to users and monitor how much deviations they have on daily basis – deviating from the average level of facial expressiveness – and use it for indicators of well-being and health.”
A promising application, Rudovic says, is human-robotic interactions, such as for personal robotics or robots used for educational purposes, where the robots need to adapt to assess the emotional states of many different people. One version, for instance, has been used in helping robots better interpret the moods of children with autism.
Roddy Cowie, professor emeritus of psychology at the Queen’s University Belfast and an affective computing scholar, says the MIT work “illustrates where we really are” in the field. “We are edging toward systems that can roughly place, from pictures of people’s faces, where they lie on scales from very positive to very negative, and very active to very passive,” he says. “It seems intuitive that the emotional signs one person gives are not the same as the signs another gives, and so it makes a lot of sense that emotion recognition works better when it is personalized. The method of personalizing reflects another intriguing point, that it is more effective to train multiple ‘experts,’ and aggregate their judgments than to train a single super-expert. The two together make a satisfying package.”
This article was reprinted with permission of MIT News.",https://www.therobotreport.com/helping-computers-perceive-human-emotions/,[[0.0609215]]
"The What, Why and How of Industrial Robot Simulation Software for Offline Programming (OLP)","When it’s time to program an industrial robot on the production line, the line has to stop. Because this downtime can cost upwards of thousands of dollars, offline programming (OLP) is an attractive option for many manufacturers. Using simulation software, it’s possible to digitally recreate robots, tools, fixtures, and the entire cell, then define a program complete with motions, tool commands, and logic. That program can be processed and downloaded to the robot, similar to the process of programming any CNC machine with CAM software.
Even if line stoppage isn’t a problem, however, there are still cases where designing a robot program in simulation is preferable to manual programming. For example, in a palletizing application involving dozens or even hundreds of boxes, a typical program could include hundreds of points. Teaching all these points manually would be tedious and time consuming. In these cases, OLP comes into play.
According to Heikki Aalto, founder and executive vice president of Delfoi, the ubiquity of CAD models in today’s manufacturing world means that programming in simulation can begin even before the first product rolls off the line. “When you are designing something, you have the design available for programming at a very early stage. You don’t have the car, the airplane, the product ready yet, but you can do everything based on CAD model beforehand,” he said. “Once you have your components on the shop floor, you have done your program already.”
Choosing the right robotic simulation software involves several important considerations.
Will the software be compatible with the robots and tools in use?
Is the software best suited to the process, such as arc welding or painting?
How much robot programming or CAD experience is required to use the software?
And how much will it cost?
In this article, we’ll take a look at several options in the OLP market and some of the critical factors. In the end, you should have a better idea of how to find an OLP solution that will be best for your application.
Cost
For the purposes of this article, we’ve divided cost of one seat of the product into three tiers: 0-$10,000; $10,000 - $40,000; and $40,000 and beyond.
Because this software is highly customizable, price is variable, and it's important to contact your vendor for an accurate quote. For example, a user planning to simulate one robot performing one process will need a package costing less than a package that can simulate multiple robots of different brands, with extra features like calibration or analysis.
Compatibility
Robots
Robot controllers from each vendor perform motion planning differently, so there’s no guarantee that a simulated robot will move the way a real one does. However, even if the motion of individual axes differs from the simulation, the defined motion of the TCP in cartesian space will be the same.
In general, However, whatever OLP solution you choose, it’s safe to say the robot you need to simulate will be supported. In most cases, the specific robot model you need can be added to the simulation from a library. These models are typically provided by the robot manufacturer (eg. KUKA, FANUC, etc.) If you are working with a smaller or lesser-known robot vendor, it may be more challenging.
In OLP software, programs created in simulation can be generated in the proprietary languages for the specific desired robot brand. “When you are happy with the program, you select the specific translator,” said Aalto, “For example, when it comes to KUKA or FANUC there is a pull-down menu, you just select KUKA and then it asks downloading or uploading. It’s possible to upload a program from a robot on the shop floor as well as to generate native KUKA code to download to the robot.”
Tooling
Tools and end effectors, such as welding guns, grippers or dispensers can be more challenging to simulate accurately. The tool’s parameters are required, as well as the offset of the TCP from the robot flange. A CAD Model of the tool can be used in many cases, but it’s not strictly required. “I could put a balloon on the end of the robot in my model but if I had the ability to control the pattern, the spray pattern and parameters that are driving the calculation of the spray application I would get the same results,” explained Mike Rouman, Senior Marketing Manager in Manufacturing Engineering Software at Siemens PLM.
As long as the tool is integrated properly into the robotic cell, I/O calls in the simulation can be done according to the I/O required by the tool manufacturer. In the simulation, an on and off command with a specific I/O can be executed, which will correlate to an arc on/arc off in welding, or plasma on/off for a plasma process, or spray on/off.
Existing Software Environments
It’s not uncommon for users of professional software in all industries to want to stick with one vendor in order to keep things simple and ensure compatibility. For example, if your company uses SolidWorks for CAD from Dassault Systemes, you may be inclined to choose Delmia, Dassault’s robot simulation software. However, several experts we interviewed for this article did not agree with this approach.
Garen Cakmak, Senior Director at Robotmaster, explained: “What does the programmer really need? If that product does not cater to exactly what the customer needs, I would caution this approach. For instance, Robotmaster is not the best product for every single robotic application and the same is true for all software solutions. When we ask the customer about their application, we sometimes actually make other recommendations because Robotmaster is very powerful for path planning and programming, but we don't cater to the markets of pick and place or palletization, For those types of applications we will make other recommendations better suited for those customers.”
Justin Glover, software accounts manager at OCTOPUZ, Inc. agreed. “There's a long list of different CAD file formats or file extensions that we can import to OCTOPUZ. Very seldom are there limitations to the models that we can bring into the environment and play around with.”
If your robot runs on the open-source Robot Operating System (ROS), you can use Gazebo, an open-source simulation tool, to develop code for it.
Calibration
When you program a robot manually, the robot is typically calibrated to a specific frame of reference, as well as being calibrated to the precise position of its joints. When teaching points, the programmer jogs the robot to a precise location in order to teach a point. The programmer can visually confirm that the programmed point is calibrated to the desired physical location. Some points can also be programmed by inputting coordinates directly. In a program designed to dispense glue along a 10mm joint, the programmer may teach the first point, then create the next point by offsetting the x coordinate position by 10mm, for example.
In simulation, the components of the work cell, such as fixtures, welding positioners or parts must be accurately located relative to each other to create a digital twin of the cell. When the program is downloaded, the robot’s frame of reference can be calibrated to align the programmed points with the corresponding real locations.
Simulation does not Translate Perfectly to Reality
When using simulation software to program a robot, it’s important to remember that no simulation will accurately represent what will really happen when you run the program with the real robot. The movement of cables and hoses is not simulated by most software environments, so it’s possible that the programmed motion may snag or stretch cables, causing failure.
“I think that dynamics and physics modeling will also help make simulations more accurate,” said Rouman. “We have started to do some of that in the design of machines in our software, but in terms of simulation, I still think there's some ground to cover. If you think about when a robot moves at high speed with a high payload, when it stops, it's not going to just stop. It's going to settle and there'll be some movement and so on. With those kinds of fine adjustments and things, we have to make some assumptions. I think that in the future we won't have to make so many assumptions. We'll be able to more closely match what the real robot will do.”
One factor that contributes to better simulation is a shift from time-based simulation to event-based simulation. “In the past, simulation developers would have to sort of guess the amount of time a given event would take,” explained Rouman. “But that's not really how these robotics systems work. They work in an event-based mode, and if we can simulate the system the way it's actually operating on the floor by having these events starting and stopping and coordinating with one another, we'll also achieve a higher level of accuracy between the simulation and the real world execution of that program model on the shop floor.”
Using sensors, some robots can make up this calibration difference. For example, a robot performing an insertion task may use a touch probe to perform a search routine to find a hole, rather than relying on a highly precise point. “The process will dictate how sensors are used,” said Cakmak. “For example, in arc welding, the robot may use touch sensing or laser seam tracking to accurately position the tool with the part. Depending on the customer’s process, these or other types of sensors can help to match the real world part to the theoretical CAD model in addition to compensating for the lack of accuracy of the robot.”
According to RoboDK CEO Albert Nubiola, it’s important to understand that a robot is not a CNC. With the right software you can make a robot behave like a 5-axis milling machine, however, robots are not as stiff or accurate as a CNC. For this reason, the real robot path may deviate more from the programmed path compared to a CNC. Keeping this in mind, there are still many applications, typically done by a CNC, that could be handled by a robot arms. Furthermore, robot calibration is another tool that can remarkably improve robot accuracy.
Brand-Specific Simulation Tools
While this article focuses on third-party simulation software, nearly every robot manufacturer offers a simulation tool as well. Why not stick with these options, such as ABB RobotStudio or FANUC Roboguide?
First, if your shop floor includes robots from more than one brand, you may not have the option to use a vendor-specific tool. Most brand-specific offerings do not support robots of other makes and models, so ensuring compatibility may be a hassle or even impossible. In addition, users of used robots may find difficulty in finding support for old controller versions within new brand-specific software.
In addition, Glover noted that OCTOPUZ aims to provide a simpler user experience within the software than what’s available from the major robot brands. “I'd say the biggest difference is that our software is built around the user and the user experience, rather than around the robot and the machine,” he explained. “That being said, we value our partnerships with each of the OEMs. Without them, we wouldn't have a product that was very useful to our customers. That close relationship allows us to build each of our robots to spec based on data we get directly from them. I like to think that we take it a step beyond and we try to make things simple as possible. Our entire line is complex made simple. That is the business that we are in.”
Siemens Process Simulate
If you’re familiar with robotic simulation software from Siemens, you may already be familiar with Robcad, the company’s legacy OLP tool. According to Rouman, Robcad is still supported and in use today. Process Simulate, however, is the newer product. In addition, Siemens NX has capability for robotic machining.
One of the features of Process Simulate is that it can connect to Siemens Teamcenter, a PLM data repository. This allows users to tie their robot simulation into the entire product lifecycle management system, along with other types of manufacturing data, including designs and processes. However, this connection is not required to run Process Simulate for robot simulation and programming.
According to Rouman, when choosing a simulation solution that includes OLP, it’s important to look for dedicated process tools. “For example, if someone is looking to do spraying or painting with a robot and they want to use a general-purpose tool, they may struggle,” said Rouman. “If they find a solution that has dedicated tools for that particular process, they're likely to have a much higher rate of success.” Process Simulate, for example, enables users to set parameters of a spray tool within the software, and deposition of the spray is shown graphically in the simulation.
Cost
Process Simulate is currently available as a perpetual license, with options for single seats, seats shared across a network, or other deployments. According to Rouman, some customers prefer subscription-based software-as-a-service (SaaS) access, which is available in some cases.
“As far as price range goes, we're on the low end of the middle range,” said Rouman. “We are providing some additional configurations of the software for lower cost to entry. For instance, a solution that wouldn't include all of these additional process-specific tools, but is ideally suited to a more basic application such as general handling and pick and place type operations, has a much lower entry point, and then the customer can add on additional modules over time if they want to expand into different processes. Or for instance, if I want to program robots from different vendors, I have a base software price and the ability to add different interfaces for different robot vendor robot models. That would be at an additional cost. That's what gets you into that mid-range pricing with a basic seat of software, a process application and a database for one or two or more robots.”
Robotmaster
Robotmaster features a click-and-drag interface for creating and modifying robot positions and trajectories. Like most other universal solutions, Robotmaster is robot agnostic, working with all brands and models of robots and end effectors. According to the company, Robotmaster V7, a task-based robot programming platform was built from scratch on a completely new architecture.
“Using offline programming, you can take problems that can become quite complex, whether the application is welding, cutting, milling, thermal spray painting or other processes, it creates trajectories with the proper parameters and very quickly solves for all robotic errors during the process,” said Cakmak. ""Our claim to fame is our proprietary optimization feature that allows end users to create error-free robot programs with fewer mouse clicks, even for customers that have no previous robotic experience.""
Cost
Robotmaster is currently available on a perpetual license, with the option for either local or network access. According to the company, the software falls into our middle tier (between $10,000 to $40,000 USD).
“Depending on the application, we consider ourselves to be in the midrange from a price standpoint, but from a functionality standpoint, we offer high-end functionality for a midrange price,” said Cakmak.
Delfoi
Delfoi runs on the Visual Components simulation platform, which includes a robot library of over 1,300 models. Delfoi provides the post-processing for each robot brand. Visual Components was acquired by KUKA in 2017. After the acquisition, KUKA made a statement affirming that Visual Components would remain a hardware neutral simulation platform, hosting models from more than 30 robot brands.
Delfoi offers three main products: Arc, Cut and Paint. Each is specifically targeted to a specific process. According to Aalto, the company aims to provide value to customers by enhancing their programming speed. “In our software, we have several automated algorithms. So, when you are defining a path to weld along a curved surface, the software will automatically detect the curve and create the complete welding arc and then you just click one button to start. We call it automated programming. This reduces the number of clicks required to create a program.”
One thing to note about Delfoi is that it cannot currently generate code for Universal Robots, though it can simulate them. According to the company, this is because UR robots are not commonly used for their main process focus areas; arc welding, metal cutting or painting.
Aalto noted that Delfoi is currently a small, growing company. While there are no Delfoi partners currently located in North America, the software is available in these regions, delivered from Europe.
Cost
According to Aalto, Delfoi Robotics tools are available on a perpetual license, with an additional fee for support and updates. The cost for one seat falls within fall within the middle tier, at €16,800 (About $20,000 USD) for the tool with a translator for one robot brand and updates. There are also more advanced versions with additional features costing up to €48,000 (about $54,000 USD).
OCTOPUZ
Like Delfoi, OCTOPUZ also runs on the Visual Components simulation platform. On top of that platform, OCTOPUZ provides process-specific add-ons to teach process-specific paths and programs, such as for welding. “Once those paths are generated, we have several tools inside of our platform to allow you to analyze, and subsequently solve or manually find solutions to potential errors in your tool path. Those errors can include but are not limited to, singularity, joint limits, reach limits or acceleration limits,” said Glover.
Currently, OCTOPUZ supports 15 brands of robots. In the cases of brands that utilize two programming languages, such as KUKA (which uses KRL for its main product lines, and java for its collaborative robots) OCTOPUZ supports both. Generated code is exported to a USB stick, which is then used to upload the program to the robot controller. OCTOPUZ is UR+ certified by Universal Robots.
According to Glover, many OCTOPUZ customers use it for welding applications. “As a result of this interest in welding, we've had the opportunity to invest quite a bit of time and money into the welding-specific features inside the software because they have been driven by our customers and their experience,” he explained. “Most of the feature enhancements that occur inside the software are customer-driven. The applications that are most popular are the ones that are going to impact the most significant growth development. I think that from a product perspective, welding is probably the process OCTOPUZ is best suited to.” However, he stressed that OCTOPUZ has customers in a wide array of processes and industries, with more projects added in 2018 than ever before.
Cost
According to Glover, OCTOPUZ falls into the middle tier, with a wide range of available features and implementations. “The average investment, for our software as well as some of our competitors' software as well, ranges somewhere from $25,000 to 40,000 CAD (about $18,800 to $30,000 USD). That really depends on several options. It's going to depend on whether you want a local seat or a floating seat. It's going to depend on training and implementation. It's going to depend on the number of cells, the complexity of the parts, training and the application.”
RoboDK
RoboDK is a unique option in the market because of the 30-day free trial offered. Users can continue to experiment with the software after the trial has expired, but saving projects is disabled. According to Nubiola, while a free trial like this is unique among industrial software vendors, RoboDK believes that it gives users a better chance to try the software before making a decision. RoboDK is also UR+ certified by Universal Robots.
One interesting feature of RoboDK is the ability to import a CAM toolpath and convert it into a robot program for applications such as robot machining.
Nubiola cautioned users to carefully consider the number of software licenses they will need for robotic simulation and OLP. “Sometimes, companies buy one license and they have access to the software on one workstation, dedicated to that software, and everybody who needs to use a robot goes through that computer. So, even if the company wants to do a million things, they buy one license, and there may be 10 users using it within a week,” he explained. Consider opting for network licenses to allow users to access the software from more than one local workstation, and buy enough licenses to support capacity.
Cost
Currently, there is a trial version of RoboDK available for free, which you can download and try any time you want. According to the RoboDK website, the full version is available as a perpetual license for just under $3000 USD. This option includes 1 year of support and updates. (termed ‘maintenance’ on the website.) In addition, the Calibration and Performance Testing package includes robot calibration tools, which according to the company can increase the accuracy of a robot by a factor of ten. According to Nubiola, this calibration is especially important for robot machining operations. Because CNC milling machines have massive iron castings, the accuracy is typically much higher than an industrial robot. The package also includes dedicated support. This option costs approximately $15,000 CAD or about $12,000 USD.
Other Major Robot Simulation Options
There are dozens of robot simulation solutions available in the market, but we weren’t able to cover them all in this article. Here are some other vendors to take a look at:
· Delmia
· Artiminds
· Kuka.SIM
Choosing a Robot Simulation Software: Questions to Ask Vendors
When shopping for robot simulation and OLP solutions, here are some good questions to ask yourself and the vendor:
What robot brands and models does the software support?
What are the options for training and support?
Is this the best software solution for my process application?
How long does it take to create a typical program?
How long does it take to solve robotic errors and collisions?
How challenging will it be to translate my knowledge of a given CAD or simulation software to this new software?
Will it be possible or convenient to expand from my current process, such as welding, to another process such as palletizing or painting?
How is data handled and shared?
Will the robot show all the process details I need, not just the robot? (spray deposition, part positions, etc.)
How accurate is the software? Is an external measuring device required or is just a robot used for measuring?
For more information on all of the solutions mentioned in this article, click the links throughout to visit the product websites.
Special thanks to David McMillan for his input on this article.",https://www.engineering.com/AdvancedManufacturing/ArticleID/18288/The-What-Why-and-How-of-Industrial-Robot-Simulation-Software-for-Offline-Programming-OLP.aspx,[[0.06055325]]
Singular Impressions from IROS 2013 in Tokyo,"Two images remain in my mind from IROS 2013 last week in Tokyo. The respect for Professor Emeritus Mori and his charting of the uncanny valley in relation to robotics, and the need for a Watson-type synthesis of all the robotics-related scientific papers produced every year.
Let me explain.
Uncanny Valley:
Almost all of the presentations at IROS were abstract and technical except for the discussion about Prof. Mori’s Uncanny Valley theory. First of all, he was there and described how he came to observe the uncanny valley under different situations and circumstances. Secondly, all of the presenters and audience were respectful of Prof. Mori’s work, his theory, and him as a person. Third, and most interesting to me, each of the other speakers in this special lecture session described how the uncanny valley theory was relevant in different settings and disciplines. In art, philosophy, psychology — in the works of David Hanson and Hiroshi Ishiguro (both of whom were there) — as well as in medicine, prosthetics and in robotics in general. To me it was a reminder that robotics crosses sciences and connects with humans in many different forms, and this tribute presentation at IROS brought the personal relationships and the breadth of their reach to the forefront, and away from the abstract, theoretical and mechanical side of IROS.
In this video by IEEE/Spectrum, filmed outside the door of the room where the session was held, one can clearly see the multi-science and psychological/philosophical aspects of the theory:
Papers, Posters, Presentations and the Real World:
Ever since I learned of the IBM Watson Jeopardy project my mind has been fascinated with possibilities for practical applications. IBM is on that trail as well and is using Watson to help with medical diagnoses and legal research and briefing. My idea is to get the NSF and IEEE (and other organizations) to commission a Watson project to synthesize robotics and AI-related science papers into a meaningful resource for all to use. At present, there are so many papers published that a researcher cannot possibly read them all. Consequently we don’t even know what we already know. But with Watson, we could know — and we could redirect research activities truly into the unknown without reinventing things over and over.",https://www.therobotreport.com/singular-impressions-from-iros-2013-in-tokyo/,[[0.06054942]]
"Webinar: Robotics Solutions for Metal Fabrication – Adept, Collaborative, Cognitive and More","This webinar was presented live on Tuesday, March 19, 2019. Click below to watch it on demand.
The definition of the term “robotic” has evolved over time to reflect the change from fixed, robotics arms, to also include many other types of mechanical systems that sense, think and act in the physical world, now often autonomously. These same autonomous systems have also benefited from advances in hardware and software, as well as access to cloud based, distributed computing resources, becoming much more intelligent and capable with each passing day. Like the articulated arms that preceded them, these new classes of advanced robotics solutions and supporting technologies will have a great impact on the metal fabrication sector, and that impact is occurring now.
Topics covered in this session include:
Collaborative Robots
Motion Control Products and Technologies
Mobile Systems
Commercial Exoskeletons
Cognitive Robotics (Applied AI & Machine Learning)
Featured Speakers:
Dan Kara
Vice President, Robotics
WTWH Media",https://www.therobotreport.com/solutions-metal-fabrication-adept-collaborative-cognitive-more/,[[0.05917324]]
"Why are JIBO, Pepper, Siri, Google Now and Cortana so important?","Imagine an assistant that knows your schedule, contacts, interests and location and can communicate with you to help you stay informed, connected and on top of your game. This is more personalized than your PC, tablet and smartphone and, depending on whether physical or virtual, is in a pleasing, personal and compatible form. If these assistants catch on, they will begin anticipating and handling many of the little decisions that fill our days. The potential for this form of artificial intelligence has tech companies vying to lead the pack.
Apple’s Siri, Google’s Google Now, Microsoft’s Cortana, Facebook, Amazon and Baidu are all in various states of pursuing virtual assistants. But JIBO, Pepper, Cubic, EmoSpark and others are just now coming to market and are offering a physical component — a robotic presence — which they hope will enhance the experience.
2015 is the year physical products are coming to market and available for experimentation and testing. Pepper ships in the summer in Japan, JIBO ships preorders in Q3 as does Cubic in the fall and EmoSpark in the summer.
These types of personal assistants rely on multiple activities including: speech recognition to determine and parse through spoken commands; predictive technology to anticipate what a user will likely do next; and determining and using contextual data (biographic data and situational information, e.g.: location, time and date). Apple, Google and Baidu — all of which attempt to provide this service — want their intelligent interface to fit all front ends, to be the universal contact point. They see a plentiful revenue stream if they are successful. Others want Apple and Google to redirect users to company sites with apps that understand their own content better, e.g.: directing requests for pizza to Dom, the digital front-end for taking Dominos Pizza orders.
Many are waiting to see how the competition plays out. Car companies and other smart product providers, fearing a variety of consequences outside of their control, aren’t enamored of letting Apple or Google (or any of the others) run their voice-powered front-end systems, thus their current intense race for inhouse and startup development. But if Google or Apple or ??? gets to market first with a true digital assistant that people embrace and buy — one that can be virtual or physical — car companies may need to make their systems adapt to that system because it’s what everyone wants to use.
The key to the outcome of this race is whether a general purpose AI will be able to steer people through their digital world or whether users would rather navigate to applications that are specialists (such as American Airlines or Dominos Pizza).
Natural language recognition – and the ability to analyze user desires from that language – is a very competitive science these days. Nuance, the biggest provider of voice and language solutions to the auto industry and a collaborator with IBM up until recently, is now competing with IBM’s Watson team and also Apple which is rumored to be working on their own language processing system instead of using Nuance. A look at the What’s Next section of Nuance’s website is, to quote them, “The intersection of Science Fiction, super-pi, and technology innovation.” But a more descriptive quote from that page seems more appropriate: “Intelligent self-service delivers a better customer experience.” That’s what this race is all about.",https://www.therobotreport.com/why-are-jibo-pepper-siri-google-now-and-cortana-so-important/,[[0.05913359]]
The secret to winning is having an Edge,"Modern manufacturers (and Formula 1 race teams) need real-time insights right where the action is. But how do you gain data-centre level compute power without the time involved with sending information to be analysed and the results returned?
Much has been written about cloud computing and the ever-growing list of opportunities and advantages it brings to an organisation.
But if time is of the essence, then the round-trip path involved with transmitting information to the cloud may be too much. That’s where ‘edge computing’ comes in.
Until now, data had to be transferred to the cloud or data centre – a process which can be slow, costly and bandwidth is finite.
The edge, however, is everywhere that isn’t the data centre or cloud, and there is a growing proliferation of devices residing here – machines, cars, personal devices, drones, cameras, the list goes on.
There are three primary reasons why the edge can offer greater operational efficiency than the cloud or data centre:
Capacity – By 2020, it’s estimated that there will be somewhere between 30 – 50 billion smart devices operating in the world, generating 11 billion terabytes of data every year. There’s simply not enough bandwidth available to bring all that information to the cloud.
Cost – It can be expensive to compute in the cloud, especially if you’re business is being charged per transaction. Some studies have shown computing at the edge to be 30% less expensive.
Celerity – In a world where seconds count, having high-powered computing on or near to your production equipment creates efficient data loops for immediate action.
Edge in the real-world
If your manufacturing plant uses images or video for quality assurance, you need to know whether each item has passed or failed quickly; you can’t afford to wait or stop the production line while the data is transmitted and analysed offsite and the results returned.
This is just one example where the capacity, cost and celerity benefits of edge computing are clear to see.
Other benefits include: optimised operations, redefined employee experiences, improved customer satisfaction, greater data security, and differentiated (service-led) business models.
VIDEO – What can businesses learn from the way Mercedes-AMG Petronas Motorsport approaches technology?
Thanks to its digital twin, every single time the Mercedes-AMG Petronas Motorsport race car goes out the team learns more about the simulation versus the physical and improves overall performance.
Matt Harris, the race team’s Head of IT, Matt, explains how the team benefits from having software tools that are revised and reiterated on a daily basis.
“Consider a factory floor, an oil rig or wind farm,” says Ian Henderson, chief technologist for manufacturing at Hewlett Packard Enterprise (HPE).
“Operational technologies such as control and data acquisition systems, industrial networks and sensors can be now converged and integrated into a single box and combined with enterprise-class IT for cloud-level computing right at the edge.
“This means businesses can compute and analyse edge data from enterprise software and business applications, and take immediate action to control their remote operational assets and bring additional agility, flexibility and value to their business.”
More productivity, better innovation
One industry where time absolutely is of the essence is Formula 1:
“We’re chasing the clock, that’s what we do,”
Lewis Hamilton, driver for Mercedes-AMG Petronas Motorsport
“The role of technology has grown to become crucially important; today, everything is supported by data. Ninety-five per cent of Formula 1 on the performance side is data-driven,”
Toto Wolff, Team Principal & CEO of Mercedes-AMG Petronas Motorsport
Everything Mercedes-AMG Petronas Motorsport does is data-driven. In a sport where split seconds make the difference, those that can turn data into knowledge, knowledge into insights and insights into outcomes will be the winners.
“Everything we do, every decision we make, is based around data – particularly when it comes to the car,” explains Matt Harris, Head of IT at Mercedes-AMG Petronas Motorsport.
The challenge for the team is that one race weekend this year will create more data than the whole of one race season 10 years ago.
The faster the computers are able to turn that data extracted from the car, the faster their two drivers – Lewis Hamilton and Valtteri Bottas – or engineers can make the necessary performance improvements to become more competitive.
Nowhere is this more critical than during qualifying.
Trackside analysis
All drivers must participate in at least one of the three practice seasons to qualify for the race. There are two 90-minutes practice sessions on the Friday and a 60-minute session on the Saturday morning.
“The time pressure involved means we have to ensure that when Lewis or Valtteri comes into the pit garage for a change during qualifying or a practise session, they aren’t kept waiting,” explains Harris.
“The drivers need the information as quickly as possible to overlay his lines with the other car to see where he can improve and have a discussion with his data engineer. They need the data, analysis and insights to hopefully make the car run better and attain or retain poll position.”
During a typical race weekend, 300 sensors on the two cars generate about half a terabyte of data – all of which is being analysed by Mercedes-AMG Petronas Motorsport’s engineers at the edge, the race track.
“We’re using that data in real-time as well as historically to ensure that we’re always improving,” says Harris.
“Real-time at the edge enables us to make more informed, strategic decisions regarding improvements to the car. We have to make decisions in seconds; if we don’t then then that might be difference between first and second.”
The engine behind the engine
One of the ways Mercedes-AMG Petronas Motorsport is better harnessing data – and has the speed and agility to learn from and quickly act on it – is through its technology and advisory partnership with Hewlett Packard Enterprise (HPE).
The partnership is focused on operational efficiency, car performance and overall technology capability both at the factory and trackside, and is enabling HPE to develop intelligent solutions that allow businesses to capture, analyse and act upon data insights seamlessly from edge to cloud.
In a sport where split seconds make the difference, HPE technologies and HPE Pointnext are helping the race team gain new technology advances to power its driver around the track.",https://www.themanufacturer.com/articles/the-secret-to-winning-is-having-an-edge/,[[0.05900207]]
A reservoir computing system for temporal data classification and forecasting,"Over the past decade or so, deep-learning approaches have become increasingly efficient in processing static data such as images. However, these techniques have been found to be somewhat less effective in analyzing temporal data, such as videos, human speech and other streaming inputs. This is mainly because processing temporal data requires bigger artificial neural networks, which are more expensive to train and implement.
With this in mind, a team of researchers at the University of Michigan has recently developed a reservoir computing hardware system to process temporal data more effectively. Reservoir computing systems essentially consist of a reservoir that maps inputs into a high-dimensional space and a readout for pattern analysis based on the reservoir's high-dimensional states.
These systems have been found to be particularly effective for temporal or sequential data processing. The system developed by the researchers, which was presented in a paper published in Nature Electronics, is based on dynamic tungsten oxide (WOx) memristors with internal short-term memory capabilities.
""A main reason for the large network size needed for processing temporal data is the large number of possible temporal features that need to be learned and stored by the network,"" Wei Lu, the senior author who led the study, told TechXplore. ""To solve this problem, we employed a 'reservoir computing' concept, where the 'reservoir' in the system can process inputs without having to learn the features. This is enabled by the 'short-term memory' property of the reservoir, so that it can respond (be excited) accordingly to different inputs without having to explicitly store anything.""
Most previously developed reservoirs were built using digital circuits that emulate short-term memory effects. This ultimately makes them difficult to implement physically, and thus highly impractical.
Lu and his colleagues, on the other hand, fabricated their reservoir computing system using WOx memristor devices with intrinsic short-term memory properties. In other words, each individual memristor device is a dynamic system in itself and can process a broad range of temporal inputs.
Through these memristors, the reservoir system can nonlinearly map temporal inputs into reservoir states. Projected features can then be easily processed by a linear readout function.
""By taking advantage of the internal dynamics of the devices to naturally perform computing, we could build the reservoir network with only a small number of memristor devices leading to much smaller footprint, cost, and power consumption,"" Lu explained.
Lu and his colleagues demonstrated and evaluated their system on a standard speech recognition task that involves recognizing spoken digits. Their system was able to recognize digits spoken by humans with a remarkable accuracy of 99.2 percent.
""More interestingly, since the network can capture the temporal features of the input, we showed that we can also use the network to perform prediction/forecasting functions,"" Lu said. ""For example, in speech recognition, we can predict the speaker's intended word before the speaker finishes it. In another example, we showed the ability of the network to capture the complex features of a chaotic system and reliably predict the evolution of the chaotic system over long term, which is a very challenging task.""
In the future, the reservoir computing system for analyzing and forecasting temporal inputs devised by this team of researchers could have numerous interesting applications. For instance, it could help to improve human-machine interfaces, autonomous driving platforms, and other technology that requires the processing or forecasting of streaming inputs.
Moreover, using this new approach, the size and power consumption of artificial neural networks for processing temporal data can be significantly reduced. This could make embedding these networks into existing systems easier and cheaper, ultimately allowing researchers to equip a broader variety of devices with real-time temporal data analysis capabilities.
""We are now working on more complex systems and on further improving the network's performance,"" Lu added.
© 2019 Science X Network",https://techxplore.com/news/2019-10-reservoir-temporal-classification.html,[[0.0588718]]
Brain-like network uses disorder to detect order,"A disordered network that is capable of detecting ordered patterns: This sounds contradictory, but it comes close to describing the way the brain works. Researchers of the University of Twente have developed a such brain-inspired network based on silicon technology that can be operated at room temperature. It makes use of material properties that electronic designers usually like to avoid. Thanks to ""hopping conduction,"" the system evolves to a solution without making use of predesigned elements. The researchers publish their work in Nature on January 15, 2020.
The brain is very good at recognizing patterns. Artificial intelligence can do better in some cases, but this comes with a price: It takes massive computing power, whereas the brain only consumes 20 watts.
The semiconductor industry is now embracing new computer design strategies inspired by the brain function, like Intel's Loihi processor, which has neurons and synapses. Still, mimicking one single neuron takes thousands of transistors—and the brain has tens of billions of neurons. Miniaturization is one approach to this scale, but the technology is reaching physical limits. The new disordered dopant atom network, now presented in Nature is a different approach: It doesn't use predesigned neurons or other circuitry, but makes use of material properties to evolve toward a solution. This highly counterintuitive approach is energy efficient and doesn't occupy much surface space.
Hopping
In electronics, doping is a well-known way of influencing the properties of transistors by deliberately introducing impurities into the silicon crystal in a concentration high enough to achieve the desired effect. In this case, using a much lower concentration of boron results in a regime that circuit designers prefer to avoid.
That's exactly the regime in which the disordered network operates. Conduction now takes place via electrons hopping from one boron atom to another: This 'hopping conduction' is, in a way, comparable to neurons seeking collaboration with other neurons to make a classification. As an example, the network is fed with 16 basic, four-digit patterns. Each pattern results in a different output signal. With these 16 as a basis, it is possible to recognize a database with handwritten letters with high accuracy and speed, for example. The basic component is now 300 nanometers in diameter, has about 100 boron atoms and consumes about 1 microWatt of power.
In future systems that use this type of network, pattern recognition can be done locally, without using distant computing power. In autonomous driving, for example, many decisions have to be made based on recognition. This involves either a powerful onboard computer system or high-bandwith communication with the cloud, probably even both. The new brain-inspired approach would involve less transport of data, so the car manufacturing industry is already interested in the new UT approach. This type of computing, called ""edge computing,"" can also be used for face detection, for example.
The paper, ""Classification with a disordered dopant atom network in silicon,"" is published in Nature. In the same issue, there is a related review titled ""Evolution of circuits for machine learning.""
Provided by University of Twente",https://techxplore.com/news/2020-01-brain-like-network-disorder.html,[[0.0584768]]
3D Robotics gets $50M Series C funding,"The $50 million Series C funding, mainly from Qualcomm, provides the basis for a tacit partnership between Qualcomm and 3D Robotics with a goal of leveraging the pace of innovation in the smartphone industry and extending it to the world of 3DR.
The company plans to use the funding to expand their software and hardware products and intends to work with Qualcomm to further utilize that company’s Snapdragon processors, a platform designed for use with tablets and smartphones.
Qualcomm’s next-generation Snapdragon processors, including sensors, wireless and computer vision, are considered to be ideal for developing advanced applications and driving increased performance for 3DR drones.
“By working with Qualcomm Technologies, Inc., we can bring advanced computing to the skies at an increasing pace,” said Chris Anderson, CEO of 3DR. “Such multi-gigahertz Linux-based onboard computing platforms, combined with state-of-the-art cameras and other sensors and wireless technologies, will allow us to create next-gen drones that are smarter, easier and safer than ever before.”
The recent FAA-suggested regulations of the airspace, and the opening up of that space to commercial ventures, will expand 3DRs role in that emerging set of industries. With Qualcomm as a significant investor, 3DR becomes privy to smartphone technology and sensors that can help 3DR speed up research and development for the drone world.",https://www.therobotreport.com/3d-robotics-gets-50m-series-c-funding/,[[0.05764862]]
Samsung Looks Beyond Smartphones to AI,"Samsung Electronics Co. is “actively looking” to acquire developers of artificial intelligence and other software as the world’s biggest smartphone maker tries to overcome flat-lining sales for its devices.
Samsung, which has $61 billion in cash and equivalents, wants to morph into more of a software-driven company, executive vice president Rhee In Jong said in an interview. The South Korean consumer-electronics giant also is spending more to develop its own services because the global market for gadgets is saturated and can’t be counted on for significant revenue growth, he said.
“We are actively looking for M&A targets of all sorts in the software area,” said Rhee, who runs the mobile division’s software research-and-development business. “We are open to all possibilities, including artificial intelligence. Intelligence is no longer an option – it is a must.”
Shipments of Samsung’s Galaxy smartphones and other models fell for a second straight year in 2015 as new iPhones gained traction in the high-end category and models from Huawei Technologies Co. and Xiaomi Corp. swayed budget buyers. Revenue and net income have fallen two straight years, and shares are down 16% since the end of 2012.
The company faces another difficult year because oversupply is forcing down prices for smartphones, TVs and memory chips, CEO Kwon Oh-Hyun said in a letter to shareholders before the March 11 annual meeting. Samsung is the largest maker of each.
Two new Galaxy S7 models went on sale this month. They look almost identical to the preceding S6 lineup, with the main differences being an added memory-card slot and a longer-lasting battery.
“With all that cash on hand, it’s the right thing for Samsung to spend more on software development that could also drive sales of its hardware products,” said Yoo Eui Hyung, an analyst at Dongbu Securities Co. in Seoul. “Its key hardware, such as chips and phones, can be overtaken by Chinese brands.”
Asia’s biggest technology company completed just eight deals last year, according to data compiled by Bloomberg. They included the purchase of LoopPay Inc., a company that develops technology for mobile payments. Samsung didn’t disclose the terms.
The inclusion of AI on smartphones can help ensure brand loyalty because of the amount of time it takes to “train” the software to understand your preferences, Rhee said. To that end, Asia’s largest technology company made a strategic investment of less than $20 million in the AI startup Vicarious.
Other parts of the Samsung Group conglomerate also targeted AI developers. Samsung Venture Investment Corp., a venture-capital firm partly owned by group affiliates, took part in a $25.3 million funding round for household robotics startup Jibo Inc. last year.
“Artificial intelligence will make things we do on smartphones much more convenient,” Rhee said. “Your well-trained phone will bring about a huge customer loyalty.”
Samsung’s rivals also are speeding up their efforts. AlphaGo, an AI system developed by Google DeepMind, beat a top-ranked South Korean player of the board game Go in a five-match tournament this month. Apple Inc. last year acquired the startup Perceptio, which is developing technology to let companies run advanced AI on smartphones while limiting the amount of user data shared. Baidu Inc., owner of China’s biggest search engine, is exploring deep learning and autonomous driving with scientists in Beijing and Silicon Valley.
Samsung used to consider software secondary to its hardware, but that’s changing now, Rhee said. It wants to reverse that relationship and have new software drive the development of hardware with enough computing power. If Samsung were to conjoin its own software with its own hardware, it could capture more revenue from users, he said.
To exemplify that shift, the new president of the mobile-phone division is Koh Dong Jin, who helped develop Samsung’s mobile-payment and software-security platforms. Vice chairman Lee Jae Yong also approved an in-house incubator for engineers and the spending of billions of dollars on an ecosystem connecting home appliances and cars to the Internet.
The company also pledged Thursday to change its corporate culture by streamlining internal bureaucracy, eliminating inefficient meetings and reducing excessive working hours. Samsung’s ambitions to promote its own operating system, named Tizen, and reduce dependence on Google Inc.’s Android software haven’t taken off. Yet Rhee said the mobile-wallet system Samsung Pay is expanding “unexpectedly” fast against competitors Apple Pay and Alipay, which is owned by Alibaba Group Holding Ltd.’s finance affiliate.
“We will let software drive and lead our businesses rather than assisting the hardware,” Rhee said. “We aren’t just looking at a particular technology or area. But artificial intelligence is clearly a path to take.”
By Jungah Lee",https://www.industryweek.com/technology-and-iiot/article/21972013/samsung-looks-beyond-smartphones-to-ai,[[0.05728526]]
Researchers develop platform for scalable testing of autonomous vehicle safety,"In the race to manufacture autonomous vehicles (AVs), safety is crucial yet sometimes overlooked as exemplified by recent headline-making accidents. Researchers at the University of Illinois at Urbana-Champaign are using artificial intelligence (AI) and machine learning to improve the safety of autonomous technology through both software and hardware advances.
""Using AI to improve autonomous vehicles is extremely hard because of the complexity of the vehicle's electrical and mechanical components, as well as variability in external conditions, such as weather, road conditions, topography, traffic patterns, and lighting,"" said Ravi Iyer
""Progress is being made, but safety continues to be a significant concern.""
The group has developed a platform that enables companies to more quickly and cost-effectively address safety in the complex and ever-changing environment of autonomous technology. They are collaborating with many companies in the Bay area, including Samsung, NVIDIA, and a number of start-ups.
""We are seeing a stakeholder-wide effort across industries and universities with hundreds of startups and research teams, and are tackling a few challenges in our group,"" said Saurabh Jha, a doctoral candidate in computer science who is leading student efforts on the project. ""Solving this challenge requires a multidisciplinary effort across science, technology, and manufacturing.""
One reason this work is so challenging is that AVs are complex systems that use AI and machine learning to integrate mechanical, electronic, and computing technologies to make real-time driving decisions. A typical AV is a mini-supercomputer on wheels; they have more than 50 processors and accelerators running more than 100 million lines of code to support computer vision, planning, and other machine learning tasks.
As expected, there are concerns with the sensors and the autonomous driving stack (computing software and hardware) of these vehicles. When a car is traveling 70 mph down a highway, failures can be a significant safety risk to drivers.
""If a driver of a typical car senses a problem such as vehicle drift or pull, the driver can adjust his/her behavior and guide the car to a safe stopping point,"" Jha explained. ""However, the behavior of the autonomous vehicle may be unpredictable in such a scenario unless the autonomous vehicle is explicitly trained for such problems. In the real world, there are infinite number of such cases.""
Traditionally, when a person has trouble with software on a computer or smart phone, the most common IT response is to turn the device off and back on again. However, this type of fix is not advisable for AVs, as every millisecond impacts the outcome and a slow response could lead to death. The safety concerns of such AI-based systems has increased in the last couple of years among stakeholders due to various accidents caused by AVs.
""Current regulations require companies like Uber and Waymo, who test their vehicles on public roads to annually report to the California DMV about how safe their vehicles are,"" said Subho Banerjee, a CSL and computer science graduate student. ""We wanted to understand common safety concerns, how the cars behaved, and what the ideal safety metric is for understanding how well they are designed.""
The group analyzed all the safety reports submitted from 2014-2017, covering 144 AVs driving a cumulative 1,116,605 autonomous miles. They found that for the same number of miles driven, human-driven cars were up to 4000 times less likely than AVs to have an accident. This means that the autonomous technology failed, at an alarming rate, to appropriately handle a situation and disengaged the technology, often relying on the human driver to take over.
The problem researchers and companies have when it comes to improving those numbers is that until an autonomous vehicle system has a specific issue, it's difficult to train the software to overcome it.
Further, errors in the software and hardware stacks manifest as safety critical issues only under certain driving scenarios. In other words, tests performed on AVs on highways or empty/less crowded roadways may not be sufficient as safety violations under software/hardware faults are rare.
When errors do occur, they take place after hundreds of thousands of miles have been driven. The work that goes into testing these AVs for hundreds of thousands of miles takes considerable time, money, and energy, making the process extremely inefficient. The team is using computer simulations and artificial intelligence to speed up this process.
""We inject errors in the software and hardware stack of the autonomous vehicles in computer simulations and then collect data on the autonomous vehicle responses to these problems,"" said Jha. ""Unlike humans, AI technology today cannot reason about errors that may occur in different driving scenarios. Therefore, needing vast amounts of data to teach the software to take the right action in the face of software or hardware problems.""
The research group is currently building techniques and tools to generate driving conditions and issues that maximally impact AV safety. Using their technique, they can find a large number of safety critical scenarios where errors can lead to accidents without having to enumerate all possibilities on the road—a huge savings of time and money.
During testing of one openly available AV technology, Apollo from Baidu, the team found more than 500 examples of when the software failed to handle an issue and the failure led to an accident. Results like these are getting the group's work noticed in the industry. They are currently working on a patent for their testing technology, and plan to deploy it soon. Ideally, the researchers hope companies use this new technology to simulate the identified issue and fix the problems before the cars are deployed.
""The safety of autonomous vehicles is critical to their success in the marketplace and in society,"" said Steve Keckler, vice president of Architecture Research for NVIDIA. ""We expect that the technologies being developed by the Illinois research team will make it easier for engineers to develop safer automotive systems at lower cost. NVIDIA is excited about our collaboration with Illinois and is pleased to support their work.""
This research has been published multiple times by IEEE (article 1, article 2, article 3).
More information: Saurabh Jha et al, ML-Based Fault Injection for Autonomous Vehicles: A Case for Bayesian Fault Injection, 2019 49th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN) (2019). DOI: 10.1109/DSN.2019.00025
Provided by University of Illinois at Urbana-Champaign",https://techxplore.com/news/2019-10-platform-scalable-autonomous-vehicle-safety.html,[[0.05604304]]
"Apps could take up less space on your phone, thanks to new 'streaming' software","If you resort to deleting apps when your phone's storage space is full, researchers have a solution.
New software ""streams"" data and code resources to an app from a cloud server when necessary, allowing the app to use only the space it needs on a phone at any given time.
""It's like how Netflix movies aren't actually stored on a computer. They are streamed to you as you are watching them,"" said Saurabh Bagchi, a Purdue University professor of electrical and computer engineering, and computer science, and director of the Center for Resilient Infrastructures, Systems and Processes.
""Here the application components, like heavy video or graphics or code paths, are streaming instantly despite the errors and slowdowns that are possible on a cellular network.""
Bagchi's team showed in a study how the software, called ""AppStreamer,"" cuts down storage requirements by at least 85% for popular gaming apps on an Android.
The software seamlessly shuffles data between an app and a cloud server without stalling the game. Most study participants didn't notice any differences in their gaming experience while the app used AppStreamer.
Since AppStreamer works for these storage-hungry gaming apps, it could work for other apps that usually take up far less space, Bagchi said. The software also allows the app itself to download faster to a phone.
The researchers will present their findings Feb. 18 at the 17th International Conference on Embedded Wireless Systems and Networks in Lyon, France. Conference organizers have selected this study as one of three top papers.
AppStreamer is a type of software known as middleware, located between the apps on a device and the operating system.
The middleware automatically predicts when to fetch data from a cloud server. AT&T Labs Research provided data from cellular networks for this study to help evaluate which bandwidths AppStreamer would use and how much energy it would consume.
AppStreamer could help phones better accommodate 5G connectivity—high-speed wireless cellular networks that would allow devices to download movies in seconds and handle other data-heavy tasks much faster than the 4G networks currently available to most phones.
Using AppStreamer on a 5G network would mean that an app downloads instantly, runs faster and takes up minimal space on a phone.
The researchers also designed AppStreamer to use ""edge computing,"" which stores and sends data from edge servers. These servers, located in spots such as cellphone towers, are closer to a device compared to the cloud. The shorter distance reduces data download time.
Bagchi's lab researches ways to make edge computing more reliable. Bagchi wrote on those challenges in an article recently published in Communications of the ACM.
The researchers believe that AppStreamer could be good for more than just phones. In order for self-driving cars to respond to their surroundings more safely, they would need to reliably pull data from servers in milliseconds. Middleware such as AppStreamer could eventually supply this functionality through edge computing on a 5G network.
Provided by Purdue University",https://techxplore.com/news/2020-02-apps-space-streaming-software.html,[[0.05550179]]
"5G teamup between AT&T, Badger Technologies to boost robots in retail","DALLAS and NICHOLASVILLE, Ky. — AT&T Communications and Badger Technologies LLC today announced that they are working together to accelerate retail automation using autonomous robots with 5G wireless networking capabilities.
Badger Technologies is a product division of Jabil, which provides design, supply chain, and product management services to the manufacturing industry. Kentucky-based Badger’s autonomous mobile robots are designed to help retailers improve operational efficiencies and customer experiences by identifying out-of-stock, mispriced, or misplaced inventory, as well as store hazards.
These advanced mobile data-collection systems and Badger Retail Insight and Badger Retail Inspect can fill gaps in the collection and sharing of vital in-store data and images, but they also can tax a store’s existing Wi-Fi network.
To better enable seamless, uninterrupted network connectivity, the AT&T Foundry is testing 5G and IoT connectivity with Badger Technologies’ robots in a multi-access edge computing (MEC) environment. The goal is to demonstrate how 5G using millimeter-wave spectrum and edge computing could provide Badger Technologies with the low latency and high throughput required to process and share vast amounts of data while running concurrently with other in-store network applications.
“5G is an important next step to helping ensure shared visibility across critical inventory, POS and operational systems,” said Tim Rowland, CEO of Badger Technologies. “Working with AT&T enables us to better support our retail customers by delivering information faster to increase store efficiencies, improve customer service and boost profits.”
5G offers Badger Technologies more control over data
AT&T’s multi-access edge computing solutions could also help Badger Technologies increase hyper-local data processing by providing a more private network connection than typically associated with in-store Wi-Fi. This gives Badger Technologies more control over what data travels beyond the walls of the store and what data stays onsite, which effectively addresses mounting privacy and security concerns among retailers.
“In-building cellular solutions, including 5G, IoT, and edge computing, are critical drivers of digital transformation for retailers,” said Mo Katibeh, chief marketing officer at AT&T Business. “These technologies will eventually equip robots with both the compute power and lower latency needed to increase revenue, improve the in-store experience, and elevate employees to better assist customers.”
“Badger Technologies’ robots can help retailers make sure they have products in stock and in the right place, increasing customer satisfaction,” Katibeh said. “That leads to increased revenue. That’s the power of data.”",https://www.therobotreport.com/5g-teamup-badger-technologies-atampt-robots-retail/,[[0.05517776]]
Computer scientists design a tool to identify the source of errors caused by software updates,"We've all shared the frustration—software updates that are intended to make our applications run faster inadvertently end up doing just the opposite. These bugs, dubbed in the computer science field as performance regressions, are time-consuming to fix since locating software errors normally requires substantial human intervention.
To overcome this obstacle, researchers at Texas A&M University, in collaboration with computer scientists at Intel Labs, have now developed a complete automated way of identifying the source of errors caused by software updates. Their algorithm, based on a specialized form of machine learning called deep learning, is not only turnkey, but also quick, finding performance bugs in a matter of a few hours instead of days.
""Updating software can sometimes turn on you when errors creep in and cause slowdowns. This problem is even more exaggerated for companies that use large-scale software systems that are continuously evolving,"" said Dr. Abdullah Muzahid, assistant professor in the Department of Computer Science and Engineering. ""We have designed a convenient tool for diagnosing performance regressions that is compatible with a whole range of software and programming languages, expanding its usefulness tremendously.""
The researchers described their findings in the 32nd edition of Advances in Neural Information Processing Systems from the proceedings of the Neural Information Processing Systems conference in December.
To pinpoint the source of errors within software, debuggers often check the status of performance counters within the central processing unit. These counters are lines of code that monitor how the program is being executed on the computer's hardware in the memory, for example. So, when the software runs, counters keep track of the number of times it accesses certain memory locations, the time it stays there and when it exits, among other things. Hence, when the software's behavior goes awry, counters are again used for diagnostics.
""Performance counters give an idea of the execution health of the program,"" said Muzahid. ""So, if some program is not running as it is supposed to, these counters will usually have the telltale sign of anomalous behavior.""
However, newer desktops and servers have hundreds of performance counters, making it virtually impossible to keep track of all of their statuses manually and then look for aberrant patterns that are indicative of a performance error. That is where Muzahid's machine learning comes in.
By using deep learning, the researchers were able to monitor data coming from a large number of the counters simultaneously by reducing the size of the data, which is similar to compressing a high-resolution image to a fraction of its original size by changing its format. In the lower dimensional data, their algorithm could then look for patterns that deviate from normal.
When their algorithm was ready, the researchers tested if it could find and diagnose a performance bug in a commercially available data management software used by companies to keep track of their numbers and figures. First, they trained their algorithm to recognize normal counter data by running an older, glitch-free version of the data management software. Next, they ran their algorithm on an updated version of the software with the performance regression. They found that their algorithm located and diagnosed the bug within a few hours. Muzahid said this type of analysis could take a considerable amount of time if done manually.
In addition to diagnosing performance regressions in software, Muzahid noted that their deep learning algorithm has potential uses in other areas of research as well, such as developing the technology needed for autonomous driving.
""The basic idea is once again the same, that is being able to detect an anomalous pattern,"" said Muzahid. ""Self-driving cars must be able to detect whether a car or a human is in front of it and then act accordingly. So, it's again a form of anomaly detection and the good news is that is what our algorithm is already designed to do.""
Other contributors to the research include Dr. Mejbah Alam, Dr. Justin Gottschlich, Dr. Nesime Tatbul, Dr. Javier Turek and Dr. Timothy Mattson from Intel Labs.
Provided by Texas A&M University",https://techxplore.com/news/2020-02-scientists-tool-source-errors-software.html,[[0.05500339]]
Inroads in perception,"Google's recent acquisition of Emu Messenger is just one of many items in recent news about improvements in perception and artificial intelligence (AI).
Emu, not to be confused with the Australian ostrich-like bird nor the European Monetary Union, is a small Palo Alto start-up composed of some serious software talent with experience in machine learning, natural language processing and mashing up different data, databases and systems at Siri, Apple, AOL and Google. Perception in this case is the feeling that your words and intentions are understood and acted upon. No financial details were disclosed about the acquisition however the Emu app will be shut down next week.
Another form of perception, computer eyesight (AKA machine vision), took a giant step forward when the winners were announced for this year's Large Scale Visual Recognition Challenge. The NY Times reported the winners: the National University of Singapore, the Oxford University, Adobe Systems, the Center for Intelligent Perception and Computing at the Chinese Academy of Sciences, as well as Google in two separate categories.
Fei-Fei Li, director of the Stanford Artificial Intelligence Laboratory said, “What really excites us is that performance has taken a huge leap.”
Machine vision has been a challenge in automation and robotics but in recent years has become integral in countless applications including computer gaming, medical diagnosis and factory robotics. Carmakers too have added the ability to recognize pedestrians and bicyclists and trigger safety actions. Factory robots need much improved perception systems in order to monitor the progress of their tasks and the tasks of those around them. [A quick Google Images search produces a collage of various uses, from milking to adaptive cruise control.]
Enhanced algorithms, data libraries and faster and cheaper computing are all contributing to the increased accuracy and speed of the systems recognizing objects and identifying them by type and in 3D space, nevertheless, at their best they are still no match for human vision and perception.",https://www.therobotreport.com/inroads-in-perception/,[[0.05483992]]
Siemens Gives Clemson $357 Million in Software to Train Engineers,"Clemson University has received the largest in-kind grant in its history from global technology company Siemens with $357 million in software.
The software will be incorporated into student coursework and projects related to computer-aided-design, engineering simulation, industrial design, digital manufacturing and manufacturing management in Clemson’s College of Engineering, Computing and Applied Sciences.
“Preparing students to be highly competitive in the 21st century global economy is a central part of Clemson’s mission, and this new partnership with Siemens will provide our students with access to cutting-edge technical tools that can make them even more attractive to future employers – especially many of the world-class, advanced manufacturing companies operating in South Carolina,” Clemson President James P. Clements said in a statement.
The software will be used in junior and senior level classes in the mechanical engineering and bioengineering departments, as well as by competitive teams at Clemson, such as Formula SAE. At the graduate level, the software also will be used in the automotive engineering department.
Joerg Schulte, manager of BMW Liaison Office for Research and Innovation and adjunct professor, teaches automotive manufacturing, a required class for all master’s students in Clemson’s automotive engineering program. The class project, to design a production plant for a fictitious company, challenges the students to apply what they have learned in a simulated, yet realistic setting.
“We can’t build that up in reality,” Schulte said in a press release. “Without this software, it wouldn’t be possible for the students to really get to the detail of what it means to run a production system – from how many stations you need to what kind of cycle time each station has, to how the manufacturing plant works with suppliers.”
Approximately 500 Siemens employees work throughout South Carolina. With more than 300 employees, Siemens’ Energy Management location in Spartanburg serves as a key U.S. manufacturing hub.
Siemens designs and manufactures smart grid and energy automation technology, power supply for industrial plants, and high-voltage transmission systems.",https://www.industryweek.com/talent/education-training/article/21988080/siemens-gives-clemson-357-million-in-software-to-train-engineers,[[0.05461849]]
Honeywell releases enterprise performance management software,"June 19, 2019 – Honeywell has introduced Honeywell Forge for Industrial, an enterprise performance management software for operational technology that leverages process and asset digital twins and advanced data analytics.
Using the software, a business can use instant insights from real-time benchmarking to help make decisions that impact equipment performance, reliability, safety and profitability.
Honeywell Forge for Industrial collects and integrates information from a manufacturer’s operations, analyzes and helps determine the achievable optimal performance and augments it with predictive analytics to identify opportunities for improvement. It then provides recommendations in real-time that help industrial producers close performance gaps.
The software provides top-to-bottom visibility into how operations are performing across the enterprise through a Software-as-a-Service (SaaS) offering that is being developed to meet the highest cybersecurity protections.",https://www.automationmag.com/9404-honeywell-releases-enterprise-performance-management-software/,[[0.05452639]]
"CES 2018: Robots, AI, Massive Data, Prodigious Plans","This year’s CES was a great show for robots. “From the latest in self-driving vehicles, smart cities, AI, sports tech, robotics, health and fitness tech and more, the innovation at CES 2018 will further global business and spur new jobs and new markets around the world,” said Gary Shapiro, president and CEO, CTA.
But with that breath of coverage and an estimated 200,000 visitors, 7,000 media, 3,000 exhibitors, 900 startups, 2.75 million sq ft of floorspace at two convention centers, hospitality suites in almost every major hotel on the Las Vegas Strip, over 20,000 product announcements and 900 speakers in 200 conference sessions, comes massive traffic (humans, cars, taxis and buses), power outages, product launch snafus and humor:
The Daily Show’s Ronnie Chang pokes fun at some of what he thought to be unnecessary products.
AI, big data, Amazon, Google, Alibaba and Baidu
“It’s the year of A.I. and conversational interfaces,” said J. P. Gownder, an analyst for Forrester Research, “particularly advancing those interfaces from basic conversations to relationships.” Voice control of almost everything from robots to refrigerators was de rigueur. The growing amount of artificial intelligence software and the race between Amazon, Google and their Chinese counterparts Alibaba and Baidu to be the go-to service for integration was on full display. Signs advertised that products worked with Google Assistant or Amazon’s Alexa or both, or with Duer-OS (Baidu’s conversational operating system) but, by the sheer number of products that worked with the Alexa voice assistant, Amazon appeared to dominate.
“It’s the year when data is no long static and post processed” said Brian Krzanich, Intel’s CEO. He also said: “The rise of autonomous cars will be the most ambitious data project of our lifetime.” In his keynote presentation he demonstrated the massive volume of data involved in the real-time processing needs of autonomous cars, sports events, smart robotics, mapping data collection and a myriad other sources of data-driven technology on the horizon.
Many companies were promoting their graphics, gaming, and other types of processors. IBM had a large invite-only room to show their Quantum Computer. Their 50-qubit chip is housed in that silver canister at the bottom of the thing/computer. Not shown is the housing which keeps the device super cool. IBM is making the computer available via the cloud to 60,000 users working on 1.7 million experiments as well as commercial partners in finance, materials, automotive and chemistry. (Intel showed their 49-qubit chip code-named Tangle Lake in a segment in Krzanich’s keynote.)
Robots, robotics and startups
Robots were everywhere ranging from ag bots, tennis bots, drones, robot arms, robot prosthetics and robot wheelchairs, to smart home companions, security robots and air, land and sea drones. In this short promotional video produced by CES, one can see the range of products on display. Note the quantity of Japanese, Chinese and Korean manufacturers.
One of the remarkable features of CES is what they call Eureka Park. It’s a whole floor of over 900 startup booths with entrepreneurs eager to explain their wares and plans. The area was supported by the NSF, Techstars and a host of others. It’s a bit overwhelming but absolutely fascinating.
Because it’s such a spread-out show, locations tend to blur. But I visited all the robotics and related vendors I could find in my 28,000-step two-day exploration and the following are ones that stuck out from the pack:
LiDAR and camera vision systems providers for self-driving vehicles, robots, and automation such as Velodyne, Quanergy and Luminar were everywhere showing near and far detection ranges, wide, narrow and 360° fields of view, and solid state or other conventional as well as software to consolidate all that data and make it meaningful.
Innoviz Technologies, an Israeli startup that has already raised $82 million, showed their solid state device (Pro) available now and their low-cost automotive grade product (One) available in 2019.
Bosch-supported Chinese startup Roadstar.ai is developing Level 4 multi-sensor fusion solutions (cameras, LiDARs, radars, GPS and others).
Beijing Visum Technology, another Chinese vision system startup, but this one uses what they called ‘Natural Learning’ to continually improve what is seen by their ViEye, stereoscopic, real-time vision detection system for logistics and industrial automation.
Korean startup EyeDea displayed both a robot vision system and a smart vision module (camera and chip) for deep learning and obstacle avoidance for the auto industry.
Occipital, a Colorado startup developing depth sensing tech using twin infrared shutter cameras for indoor and outdoor for scanning and tracking.
Aeolus Robotics, a Chinese/American startup working on a $10,000 home robot with functional arms and hands and comms and interactivity that are similar to what IBM’s Watson offers, appeared to be focused toward selling their system components: object recognition, facial/pedestrian recognition, deep learning perception systems and auto safety cameras which interpret human expressions and actions such as fatigue.
SuitX, a Bay Area exoskeleton spin-off from Ekso Bionics, focused on providing modular therapeutic help for people with limited mobility rather than industrial uses of assistive devices. Ekso, which wasn’t at CES, is providing assistive systems that people strap into to make walking, lifting and stretching easier for employees and the military.
There were a few marine robots for photography, research and hull inspection:
Sublue Underwater AI, a Chinese startup, had a tank with an intelligent ROV capable of diving down to 240′ while sending back full HD camera and sensor data. They also make water tows.
RoboSea, also a Chinese startup, was showing land and sea drones for entertainment, research and rescue and photography.
QYSea, a Chinese startup making a 4k HD underwater camera robot which can go to a depth of 325′.
CCROV, a brand of the Vxfly incubater of China’s Northwestern Polytechnical University, demonstrated a 10-pound tethered camera box with thrusters that can dive more than 300′. The compact device is designed for narrow underwater areas and dangerous environments for people.
All were well-designed and packaged as consumer products.
UBTech, a Chinese startup that is doing quite well making small humanoid toy robots including their $300 StarWars StormTrooper showed that their line of robots are growing from toys to service robots. They were demonstrating the first video-enabled humanoid robot with an Amazon Alexa communication system touting its surveillance capabilities and Avatar modes for this little (17″ tall) walking robot. It not only works with Alexa but can also get apps and skills and accept controls from iOS and Android. Still, like many of the other home robots, they can’t grasp objects, consequently they can’t perform services beyond remote presence and Alexa-like skills.
My Special Aflac Duck won the CES Best Unexpected Product Award for a social robot designed to look like the white Aflac duck but also designed to help children coping with cancer. This is the second healthcare-related robotic device for kids from Sproutel, the maker of the duck. Their first product was Jerry the Bear for diabetic kids.
YYD Robo, another Chinese startup, was demonstrating a line of family companion, medical care robots (although the robot’s hands could not grasp), which also served as child care and teaching robots. This Shenzhen-based robot company says they are fully-staffed and have a million sq ft of manufacturing space, yet the robots weren’t working and their website doesn’t come up.
Hease Robotics, a French mobile kiosk startup, showed their Heasy robotic kiosk as a guide for retail stores, office facilities and public areas. At CES, there were many vending machine companies showing how they are transitioning to smart machines – and in some cases, smart and robotic as the Heasy robotic kiosk.
Haapie SAS, also a French startup, was showing their tiny interactive, social and cognitive robots – consumer entertainment and Alexa-like capabilities. Haapie also integrates their voice recognition, speech synthesis and content management into smartphone clients.
LG, the Korean consumer products conglomerate, showed an ambitious line of robot products they called CLOi. One is an industrial floor cleaner for public spaces which can also serve as a kiosk/guide; another has a build-in tray for food and drink delivery in hotels; and a third can carry luggage and will follow customers around stores, airports and hotels. During a press conference, one of the robots tipped over and another wouldn’t hear instructions. Nevertheless all three were well-designed and purposed and the floor cleaner and porter robots are going to help out at the airport for next month’s Winter Olympics.
Two Chinese companies showed follow-me luggage: 90FUN and their Puppy suitcase and ForwardX and their smart suitcases. 90FUN is using Ninebot/Segway follow-me technology for their Puppy.
Twinswheel, a French startup, was showing a prototype of their parcel delivery land drone for factories, offices and last-mile deliveries.
Dobot is a Chinese inventor/developer of a transformable robot and 3D printer for educational purposes and a multi-functional industrial robot arm. They also make a variety of vision and stabilizing systems which are incorporated into their printers and robots. It’s very clever science. They even have a laser add-on for laser cutting and/or engraving. Dobot had a very successful Kickstarter campaign in 2017.
Evolver Robots is a Chinese developer of mobile domestic service robots specifically designed for children between the ages of 4-12 offering child education, video chat, games, mobile projection and remote control via smartphone.
Although drones had their own separate area at the show, there were many locations where I found them. From the agricultural spraying drones by Yamaha, DJI and Taiwanese Geosat Aerospace to the little deck-of-cards-sized ElanSelfie or the fold-into-a-5″ X 1/2″ high AEE Aviation selfie drone from Shenzhen, nothing stood out amongst the other 40+ drone vendors to compete with the might of DJI (which had two good-sized booths in different locations).
Segway (remember Dean Kamen?) is now fully owned by Ninebot, a Beijing provider of all types of robotic-assisted self-balancing scooters and devices. They are now focused on lifestyle and recreational riders in the consumer market including the Loomo which you ride like a hoverboard and then load it up with cargo and have it follow you home or to another place in the facility. At their booth they were pushing the Loomo for logistics operations however it can’t carry much and has balance problems. They would do better having it tow a cart.
Yujin Robot, a large Korean maker of robotic vacuums, educational robots, industrial robots, mobility platforms for research and a variety of consumer products, was showing their new logistics transport system GoCart with three different configurations of autonomous point-to-point robots.
The Buddy robot from Blue Frog Robotics won CES’s Robotics and Drones Innovation Award along with Soft Robotics and their grippers and control system that can pick items of varying size, shape and weight with a single device. Jibo, the Dobot (mentioned above) and 14 others also received the Robotics and Drones Innovation Award.
[The old adage in robotics that for every service robot there is a highly-skilled engineer by its side is still true… most of the social and home robots frequently didn’t work at the show and were either idle or being repaired.]
Silly things
At a hospitality suite across from the convention center, the head of Harmony, the sex robot by San Diego area Abyss Creations (RealDoll), was available for demos and interviews. It will begin shipping this quarter at $8-$10,000.
Crowd-drawing events were everywhere but this one drew the largest audiences: Omron’s ping-pong playing robot.
FoldiMate, a laundry folding robot, requires a human to feed the robot one article at a time for it to work (for just $980 in late 2019). Who’s the robot?
And Intel’s drones flew over the Bellagio hotel fountains in sync with the water and light musical show. Very cool.
ABC’s Shark Tank, the hit business-themed funding TV show, was searching for entrepreneurs with interesting products at an open call audition area.
Bottom Line
Each time I return from a CES (I’ve been to at least six) I swear I’ll never go again. It’s exhausting as well as overwhelming. It’s impossible to get to all the places one needs to go — and it’s cold. Plus, once I get there, the products are often so new and untested, that they fail or are over-presented with too much hype. (LG’s new CLOi products failed repeatedly at their press conference; Sony’s Aibo ignored commands at the Sony press event.)
I end up asking myself “Is this technology really ready for prime time? Will it be ready by their promised delivery dates? Or was it all just a hope-fest? A search for funding and pre-orders?” I still have no answer… perhaps all are true; perhaps that’s why I keep going. My mind seems to have sifted through all the hype and chaff and ended up with what’s important: there’s no doubt this show was great for an about robotics and that Asian (particularly Chinese) vendors are the new power players. Maybe that’s why I copied down the dates for CES 2018.",https://www.therobotreport.com/ces-2018-robots-ai-massive-data-prodigious-plans/,[[0.05430269]]
Industrial Data Summit 2018: How do you gain insight at scale?,"Almost 100 executive decision-makers gathered to discuss how best to take advantage of and leverage the power of digital technology at Industrial Data Summit, which took place at Mary Ward House, London on 18 April.
Data, advanced analytics and machine learning hold a ‘Pandora’s Box’ of both opportunities and challenges, our chair for the day – Oxford Engineering’s Karim Sekkat – began.
The primary hurdle facing almost every business which is yet to start their ‘digital journey’ is knowing where to start – a deceptively ‘simple’ objective, Sekkat continued, which leads to follow-up questions such as who, what, why, when, and how.
For those who are already leveraging the value of digital technology and data, the prizes on offer are compelling: improved productivity, increased asset utilisation, preventative (even predictive) maintenance, closer customer relationships, faster innovation, heightened supply chain visibility, the creation of new revenue streams, and more agile, flexible businesses overall.
To help manufacturers see digital and data as an enabler of business growth, rather than simply an ongoing business cost, the Industrial Data Summit’s innovative format focused around a series of intimate roundtable sessions – allowing decision-makers to sit next to the experts and have their questions and concerns addressed first-hand.
Roundtables discussions took in the Internet of Things, IT/OT convergence, machine learning, data-driven sales & operations, real-time energy monitoring, supply chain insight and artificial intelligence, among other topics, and delegates were given the opportunity to sit at five tables throughout the day.
The Manufacturer has a number of upcoming ‘summits’ which follow the same interactive format:
Before the first roundtable session got underway, Chris Cameron – worldwide sales leader for IBM, took to the stage to deliver the first keynote: The New Supply Chain: Collaboration + Blockchain + Artificial Intelligence.
Panel Discussion #1
Overseen by The Manufacturer’s editorial director, Nick Peters, the first panel looked to answer, ‘Whose data is it anyway’.
It’s a very important topic, noted Nick Frank – a specialist advisor for Hennik Edge. As data ownership has ‘legal implications and complications’, before sharing data you have to first identify what value you’re going to get from doing so, ‘is it worth it?’, he cautioned.
“If there is value in sharing data, then be sure to put appropriate mechanisms – such as processes and contracts – in place ahead of time,” Frank added.
It’s also important to ask yourself whether you’re sharing quality data or nonsense, said Phillip Woodall – senior research scientist at Cambridge University. “Inaccurate, unformatted or poor-quality data could see you waste time, money and effort getting something into shape which doesn’t actually hold any value.
In any discussion of data ownership and sharing, it’s not long before the issue of cyber security and IP protection comes to the fore.
“It’s a rapidly changing world, and businesses can’t afford to be complacent,” said Hassan Khalid – data scientist at GlaxoSmithKline.
Technology and platform providers are aware of that need, however, and are very security conscious. A global software provider is almost sure to have more expertise, resource and capability than most other companies, so manufacturers just need to be upfront about their individual business needs and concerns.
If your organisation has to share data, or could create significant additional value by doing so, then don’t let latent fears or uncertainties stop you from taking proactive steps forward.
Morning Roundtable Sessions
The first roundtable I sat in on was hosted by Dell EMC and explored the business benefits the Internet of Things (IoT) can bring to a manufacturing organisation. Listening to the conversation, it seems that many manufacturers are still struggling to correlate how IoT relates to their day-to-day processes.
To help illustrate exactly that, one example given was of an India dairy farm which uses drones and sensor data to map out the most fertile fields, and the herd was moved accordingly. As a result, yields had increased by more than 25%.
Given that another key concern is how to bridge the gap between new technology and legacy equipment, another example given was that of a decades-old Bridgeport milling machine and a similarly aged Colchester lathe that were recently on display at this year’s MACH exhibition.
Both machines had been retrofitted with relatively simple, easy to install, low-cost (around £1,500 in total) sensors to communicate operational and utilisation data in the same way as any new machinery does.
Performance data is one thing; however, you need additional information to contextualise that data. If the average speed of your lorry is 75mph, but sensors show it only averaged 65mph this week, knowing just that isn’t enough. What is causing the 10mph drop?
The challenge lies in gathering enough data to make informed decisions, without having so much data that you become ‘stuck in quicksand’.
My second roundtable was hosted by SAS and explored what machine learning means for you and your business. After going around the table and hearing a dozen different definitions and use cases, it became apparent that there is no one definition, and there’s certainly no one-size fits all solution.
However, rather starting with the technology, a much better starting point is identifying what it is your business is trying to achieve? That will help to determine what data is required, from which machines, at what time, and who needs to receive it.
My final roundtable of the morning covered the cyber security challenges associated with integration operational technology (OT) with information technology (IT), and was hosted by IBM.
The discussion emphasised the importance of having cyber security on your digital agenda from the outset, rather than added as after-thought.
Almost all (99.9%) of business problems IBM comes across are easily fixable, but they can’t be fixed if they go undetected. One manufacturer noted how they had asked a ‘known, friendly hacker’ to the business to try and crack their system in an effort to highlight potential weaknesses.
Many products currently carry a ‘CE Mark’, declaring that the product complies with essential regulatory requirements. ‘In the future, will we see an equivalent or an amended CE Mark relating to cyber security?’, one delegate posed.
Following lunch, Tim Clark – head of manufacturing at SAS discussed how to unlock the value of data produced by machines in his keynote: Can you Talk to the Machine?
Panel Discussion #2
Overseen by Jonny Williamson, editor of TheManufacturer.com, the second panel attempted to address one of the most frequently heard questions of the day, ‘What data should I collect and Why?’.
Terex uses a both a targeted and open-ended approach to data collection, according to service and solution director, Matthew Skipworth. ‘Targeted for obvious reasons, but we are finding some very interesting and unexpected trends with the open data we critique,” he explained.
The business has taken an innovative approach to breaking down internal siloes – Skipworth, himself. From the outset, his focus has been to engage all functions and segments, ensuring diversity is represented across all project teams, that communication and information is both structured and frequent, and ensuring that every person fully understand how critical each function is in the business’ overall success.
Terex is also seeing significant benefits from ‘open innovation workshops’, which empowers the entire workforce – particularly those seen as lower in status but certainly closer to the front line – to share their unique knowledge, experiences and suggestions.
Real-time data insights can also strengthen and boost a manufacturer’s existing lean initiatives, noted Marco Del Seta – head of digital at industrial gas multinational, BOC.
“Continuous improvement requires straightforward measures to track and guide it; that correlates with the way metrics can offer a simple method of determining how well the business is performing,” he explained.
“For me, CI is sustainable when the feedback from any changes made is immediate, which requires data to be delivered swiftly, accurately and reliably.”
The big question for many organisations is whether to adopt a targeted or more open approach to what data to collect – with several manufacturers I’ve spoken to extolling the benefits of both methods.
Peter Bozsoki, a data scientist at GE Aviation, noted how his organisation had increasingly moved towards automating data collection – a trend he expects to only increase in the months ahead.
“The more automated the collection process, the better the data quality is,” he explained. “The timelier the gathering, i.e. live satellite feeds versus after-flight data collection, is also beneficial in providing earlier alerts to potential issues.”
Afternoon Roundtable Sessions
My first of the two afternoon roundtables was hosted by IBM and explored why gaining greater supply chain insight has become a primary focus for manufacturers – especially those seeking to exploit new business models, such as servitization.
Many organisations currently operate fragmented, disconnected supply chains which need to become more standardised and unified. However, simply investing considerable resources into gaining visibility will be wasted if you first don’t identify what additional benefit or value such visibility would bring.
One major challenge has been created by those which have outsourced logistics and distribution to third-parties. As a result, the expertise and insight is taken out of the business and yet another supplier has to be interacted with.
My last roundtable of the day discussed how to collaborate with customers, and was hosted by Marco Del Seta of BOC and Philip Woodall of Cambridge University.
‘How do you sell putting a data-capture device into customers’ equipment or facilities?’ asked one delegate. The consensus was by explaining how the information gathered could benefit both parties, i.e. by delivering ‘value’ – probably the most commonly heard word of the day.
‘Could companies afford to not have 100% accurate, quality data?’ another delegate asked. Again, the table agreed that for some applications, 100% accuracy wasn’t a prerequisite and trying to achieve optimum conditions shouldn’t hold you back from pilot projects.
Ahead of the final panel discussion of the day, Paul Brook – data analytics director for EMEA at Dell EMC, outlined The Digital Future, Fuelled by Data and Valuable Returns for Business.
Panel Discussion #3
Industrial Data Summit 2018 drew to a close with a discussion presided over by Oxford Engineering’s Karim Sekkat, with a theme of ‘Raw (data) – what is it good for?’.
Data may be the ‘new oil’, but you wouldn’t put raw oil in your engine and likewise your business shouldn’t attempt to use raw data. Like oil, data first needed to be refined, advised Unilever’s Biswaranjan Sen.
A key takeaway for many delegates was that to gain the greatest value of data, you first must ask the right questions. Though, ‘do manufacturers currently have the necessary skills and knowledge to ask the right questions?’, posed Cobham’s Dr Robert Pearson.
Drawing proceedings to close, the chairman’s closing comment perfectly summed up an insightful, lively day of conversation.
“If you always do what you’ve always done, you’re always going to get what you’ve always got. Digitalisation has opened manufacturers’ eyes to what’s possible and today has been a tremendous catalyst for executives to see what their operation could – and should – look like.
“Some businesses will use digitalisation to squeeze more juice from the lemon, others may choose to switch that lemon for an orange. The most important thing is to get involved. Engaging with and using technology isn’t scary, we’ve been successfully doing it for centuries.”",https://www.themanufacturer.com/articles/industrial-data-summit-2018-how-do-you-gain-insight-at-scale/,[[0.05405096]]
The Apple strategy and the birth of iPhone X,"technology
The 10th anniversary Apple iPhone model – the iPhone X – was revealed yesterday, and even the eye-watering price of $999 seems unlikely to hamper its inevitable march into the pockets of many.
It has been described (admittedly by the company itself) as the most innovative iPhone yet, taking away more of the phone’s iconic physical features and offering heightened levels of technology to justify the price.
Loizos Heracleous, a Professor of Strategy at Warwick Business School, researches Apple and its quantum strategy. He offered the following expert comment:
""Apple’s introduction of a $1,000 iPhone is consistent with its business strategy of differentiation and exclusivity, targeting the higher end of the market rather than just aiming for a larger base of users. Given that the iPhone accounts for the majority of the company’s revenues and profits and its demand curve is relatively inelastic – i.e. a price change has less effect on sales - this pricing strategy makes sense in terms of revenue and profit growth.
""This move is also consistent with Apple’s image in important emerging economies as an exclusive handset and as the real thing, despite the availability of much cheaper imitations. While it may constrain rapid expansion of users, it strengthens the brand's image and desirability as the mobile most people will buy when they are able to.
""Apart from removing the home button enabled by a new type of screen on the highest end model, Apple is also continuing to focus on its intense levels of efficiency in production and more broadly at the operational level, by using a largely consistent design, operating system and functions across its different iPhone models.
""People have been predicting Apple’s demise for a while, but Apple’s performance has been growing stronger since Steve Jobs’ untimely departure. This pricing move is an example of the essence of strategy: being able to make tough choices that are meaningful for company performance.
""No move is risk-free, but as things stand, this seems like a courageous move that should turn out positively for the company in terms of performance, and create some distance from competing brands in terms of exclusivity.""",https://www.manufacturingglobal.com/technology/apple-strategy-and-birth-iphone-x,[[0.05362401]]
SMEs Need More Plug-and-Play Automation Options,"The Taiwan Automation Intelligence and Robot Show is a 4-day manufacturing tech expo in Tai Pei, Taiwan. Exhibitors at this year’s show, which ran last week, included COMAU, Universal Robots and dozens of Chinese, Taiwanese and international manufacturing tech corporations.
According to the organizers, the first significant event planned for this year’s expo was an “Advanced 7-Axis Co-Robotic System” launch ceremony showcasing a robot system co-developed by Taiwanese IoT and controller company NEXCOM and American robotics and machine vision maker Energid.
The companies are responding to the needs of the rapidly growing industry 4.0 movement, and the hundreds of manufacturers who could use robotics systems, but are wary of automation’s high cost of entry. Purchasing, programming and maintaining industrial robots can be costly and intimidating for factories looking to make the leap. However, the benefits of boosting production with new technology can quickly make up the costs.
Because of this hesitation, we’re seeing companies taking advantage of the unique new market segment. By offering a little extra service that helps mitigate start-up costs, programming headaches or maintenance, robotics systems manufacturers are bringing robots to more and more manufacturing floors.
""While the robotics industry continues to explode, especially in Asia, many companies still avoid the risk of creating robotic systems because they don't know how to create software that enables the type of precise, coordinated control many industries require,” said Niel Tardella, CEO of Energid. “Turnkey commercial software to facilitate creating, controlling and intuitively programming robots is rare, creating a huge global market. With Actin, the development risk is greatly reduced, and the use of Actin results in easy robotic programming and control, even for complex tasks, to meet the needs of multiple industries.”
NEXRobo is a NEXCOM robot controller powered by Energid’s Actin software, designed to be a turnkey commercial robot control software that helps developers bring their robotic technology to market. The software can coordinate the motion of up to hundreds of axes in real-time, which is necessary for robots that will do complex tasks requiring dexterous manipulation not easily supported by traditional control software.
Energid’s control software can also use machine vision data to enable robots to dynamically avoid collisions with humans and other objects. In addition, the software supports visual servoing, enabling vision-based manipulation of objects in changing environments.
Last week in Taiwan, NEXCOM showed robotic developers how their new controller aimed to simplify complex tasks. The demonstration highlighted the software’s high-axis control, dexterity, and collaborative feature support, including teach-mode and collision stopping, with a seven-axis robot.
Traditional manufacturers across the globe are carefully following the advances in automation and robotics, waiting for the best time to make their investment. This cautious attitude is coaxing robotics systems makers into offering more plug-and-play, IoT-connected and versatile options that are more attractive to small and medium enterprises.
If you agree that robotics need to become more accessible to SME’s before they can invade the manufacturing market, leave a comment below, or hit the share buttons to post this story on Twitter or LinkedIn.",https://www.engineering.com/AdvancedManufacturing/ArticleID/15636/SMEs-Need-More-Plug-and-Play-Automation-Options.aspx,[[0.0535743]]
VIDEO: Efficient Automated Bin Picking Without CAD Reference Data,"Pick and place applications have a common problem: how do you pick unusually shaped parts from a container? This becomes even more complex in low volume, high mix applications.
Even for modern vision systems, randomly arranged parts in a container can present challenges… or do they?
In the video above we speak with Ryan Guthrie, executive VP of TM Robotics, about how modern machine vision systems can identify parts without using CAD data for reference, enabling more accurate and flexible part picking, with the TSVision3D software.
“Toshiba Machine has developed their own in-house software for 3D bin picking and one of the key features of our software is that you do not need a CAD file to learn a part,” said Guthrie. “You’re able to take a part, and present it to our vision system in multiple orientations to create a point cloud of that part. The model is then stored in the system and with that we’re able to pick the parts based on that information within minutes.”
Parts with complex shapes and the density of parts can sometimes present issues for a gripper. With the TSVision3D software, a part is analyzed by the vision system to determine optimum angles for gripping and the order in which parts are picked up.
“We can set interference areas in the image and the model to make sure a part is clear so we can grab the part cleanly,” Guthrie explained. “Our system also learns the tool and learns the box, so we can do collision avoidance, and we do that before we even send coordinates to the robot.”
For high mix applications, the software can be used to identify specific parts in a collection of other parts within a single container and only pick those parts. It can even identify different containers.
The software is currently optimized for 5kg and lighter types of parts and smaller containers, for electronics assembly and similar applications, Guthrie explained.
For more information about how the TSVision3D software works, watch the video above and visit the TM Robotics website.",https://www.engineering.com/AdvancedManufacturing/ArticleID/14862/VIDEO-Efficient-Automated-Bin-Picking-Without-CAD-Reference-Data.aspx,[[0.0533242]]
VW Streamlines Tech Operations in $8B Plan,"Volkswagen AG is bundling its software operations with an investment plan of as much as 7 billion euro ($8 billion), another step in the electric and connected-car shift that’s heralding massive change across the entire industry.
Unifying VW’s fragmented IT units will boost efficiency as the world’s biggest auto manufacturer steps up sharing of parts and key technology across 12 automotive brands. VW employs some 650,000 workers globally, with the labor force steeling for cutbacks across the traditional carmaking business.
The streamlined operations will have a workforce of as many as 10,000 developers, Christian Senger, head of digital car and services for the VW brand, said in a presentation at the Frankfurt auto show.
The manufacturer had earlier outlined a plan to pool about 5,000 digital experts into a single unit that will develop “vw.os,” a uniform software operating system across all new models.
VW Chief Executive Officer Herbert Diess has mapped out a massive expansion in software and digital investments, and earlier this year started the rollout of the industry’s biggest automotive cloud with strategic partner Microsoft Corp. With the creation of the Car.Software unit, Volkswagen’s in-house tech development will rise to at least 60% by 2025 from less than 10% now, the carmaker said earlier this year.
Accompanying the changes is a 2016 pact to cut 30,000 jobs worldwide at the VW brand through voluntary measures like early retirement and attrition. Net headcount is down 6,900 people as of July this year while the carmaker added about 3,400 new jobs in areas like software development of car connectivity, according to an investor presentation. VW has achieved 2.5 billion euros in related cost savings to far, freeing up funds it can plow into future technologies.
“There is a huge transformation going on,” Senger said during a discussion in Frankfurt with Microsoft Corp.’s executive vice president for cloud computing, Scott Guthrie. VW’s convoluted IT supplier structure with short-term contracts and a low re-usage of code will be turned into long-term partnerships that may last as long as a decade.
The first vehicle based on vw.os is the electric ID.3 hatchback VW unveiled in Frankfurt this week. Production starts in November and the vehicles will hit showrooms next year. From 2025, all new models will use the system. Currently, as many as 70 control units with operating software from 200 different suppliers need to be integrated into VW brand vehicles, rendered even more complex by using different systems for similar functions, such as for infotainment and navigation.
VW embarked on a broad overhaul plan through 2025, including sweeping efforts to slash complexity and make the sprawling industrial giant more agile. Boosting software operations is a critical part of this shift.",https://www.industryweek.com/technology-and-iiot/article/22028230/vw-streamlines-tech-operations-in-8b-plan,[[0.05289938]]
How Can Big Data Enhance Quality in Manufacturing?,"You’ve probably heard of big data and like many of us you may be wondering whether it’s a fad, a trend or the next revolution in manufacturing. A recent report by the American Society for Quality (ASQ) attempted to answer that question.
What Is Big Data and What Can It Do?
Citing the research and technology firm Gartner, Inc., the report defines big data as “high-volume, high-velocity and/or high-variety information assets that demand cost-effective, innovative forms of information processing that enable enhanced insight, decision making and process automation.”
To take a simple example, the terabytes of information comprising Wikipedia constitute big data.
According to the report, when used as a part of quality and continuous improvement efforts, big data can be leveraged in a number of ways to improve organizational performance. These include:
Correlating performance metrics
Predictive modeling
Understanding supplier network performance
Forecasting
Developing unexpected insights
Analyzing real-time data for real-time decisions
However, the report also states that manufacturers are not utilizing big data as much as they could or should be. Of the 1,600 respondents to a survey conducted by Global State of Quality 2 researchers, only 20 percent believe their organization is using big data to gain a competitive advantage.
Moreover, the effectiveness of big data usage remains controversial, as illustrated by this chart.
Advice from Big Data Experts
In order to understand the challenges and opportunities big data affords, ASQ interviewed two experts: Elmer Corbin, directive and project executive of client success at IBM Watson & Watson Health and Silvia Veronese, director of big data solutions at Hewlett Packard Enterprise Co.
To give a sense of scale, Corbin offered the following illustration: “If you were to take a snapshot of all the data created and stored from the beginning of time until three years ago, that amount of data would pale in comparison to the amount of data that has been generated and stored over the last three years.”
Properly utilized, this staggering amount of information can be used to a quality professional’s advantage. “Quality is improved because the data analyzed can be reveal data inconsistency and conflicts coming from multiple sources,” said Veronese.
Corbin gave an example from his days at IBM’s semiconductor manufacturing business: “We used big data and analytics there to predict early indications of deviations from the standard process and potential excursions. This would also provide us with information on possible next steps if an alert was received.”
“The tools would give us that early indication that something could potentially go wrong before something actually happened, which allowed us to do proactive maintenance rather than costly and time-consuming reactive repairs after a critical error occurred,” Corbin added.
Avoiding critical errors before they occur is the dream of every quality assurance engineer, but using big data in this way is no mean feat.
For manufacturers looking into leveraging big data, Veronese offered the following advice: “Internal alignment within the organization is a key factor for success. Big data touches everything, literally everything within an organization. This is not a project that is undertaken in just one business unit.”
For more information, access the full ASQ Global State of Quality 2 Reports here.",https://www.engineering.com/AdvancedManufacturing/ArticleID/12069/How-Can-Big-Data-Enhance-Quality-in-Manufacturing.aspx,[[0.05278734]]
3 Cloud ERP Myths Busted,"Cloud computing is one of the most disruptive technologies to hit the manufacturing industry in years, which opens the door to misconceptions or myths. Anything new is a big unknown. Ignoring the transformation that cloud has delivered to manufacturing, however, could be a bigger risk.
It’s worth your time to dig deeper into the biggest questions and myths about cloud ERP because it represents a huge opportunity to your business—unprecedented scalability, affordability, and flexibility to grow. The advantages of cloud ERP don’t come from the hosting platform, the licensing scheme, or the marketing label. They come from a development model that capitalizes on a shared code base: real, native cloud.
Myth #1: Cloud isn’t secure or reliable.
Cloud vendors specialize in security and reliability as core competencies—with an intentional focus to do it right because it is core to their business. Legacy ERP vendors appeal to security fears by telling manufacturers that managing the software themselves provides greater levels of security. The reality is you are in the business of manufacturing, not IT management. To do a credible job of supporting a secure ERP system, you must dedicate the resources it requires. For manufacturing companies, that kind of investment is not viable.
A few highly publicized cloud interruptions (though not cloud ERP) have escalated the myth that all cloud is not reliable. The average business experiences more than an hour of unplanned IT downtime per month. In contrast, best-of-breed cloud ERP systems built for manufacturing average downtime of less than 2.5 minutes—reliability supported by a contractually guaranteed 99.9 percent SLA.
Myth #2: Cloud is more expensive in the long run.
Legacy ERP purchases involve large upfront capital costs with incremental increases as companies add users and modules. There is also an annual maintenance cost, typically 20-30 percent of the total value of the software which increases as the number of user licenses and modules increase. This means that you will pay double for the software in four years or so—once up front and again in annual maintenance costs. And this doesn't even include the time and costs of service-impacting, periodic upgrades.
The often-neglected consideration with ERP is opportunity costs—the lost value when choosing legacy ERP over cloud ERP. Software loses value if it’s not routinely upgraded, and most manufacturers don’t upgrade with every new release, falling behind a few revisions. They miss out on any new features until that next upgrade, which could be years down the road.
Cloud ERP delivers a new model, eliminating the headaches of the past. Versionless (always current), subscription-based cloud ERP software includes all hardware and software maintenance, scale, data, and system redundancy. This adds constant value with real-time enhancements which manufacturers use immediately. Cloud ERP frees technical resources for use in more strategic data and business analyst roles, creating new processes and driving efficiencies.
Myth #3: All cloud solutions are the same.
Old software, even when hosted “in the cloud,” requires the same upgrades and maintenance it always did. Heavy customizations make each instance unique, so every upgrade and integration to your version of the software then requires some kind of new coding project. Over time, your unique instance becomes more complicated and more brittle.
In contrast, a modern cloud ERP solution is designed to run a single code line—every customer is on the same version, with their individual instances configured to fit their business. The software is updated constantly, like a consumer website. Upgrades are eliminated and new features are opt-in; managing new capabilities and the retirement of old software is the responsibility of the vendor. All that, and it runs on a reliable cloud infrastructure as well.
Get the truth on more common cloud ERP myths by downloading the white paper: 6 Common Myths About Cloud ERP for Manufacturers.",https://www.industryweek.com/cloud-computing/article/21983546/3-cloud-erp-myths-busted,[[0.05226029]]
"July fundings, acquisitions and failures","Despite all the high-profile billion-dollar acquisitions, eg: ARM by SoftBank, KUKA by Midea and Uber China by Didi Chuxing, M&A are down 19% this year according to both Forbes and CB Insights.
Buyers are buying, but they are seeking cash-positive market-realistic targets. Values (both monetary and vanity) are taking a hit. What’s a startup to do? According to CB Insights, startups can (1) get bought at a lower valuation and take the hit; (2) lower their cash burn rate and play the long game; or, (3), if they already have strong fundamentals and good growth, continue on.
Nevertheless, July's fundings and acquisitions were substantial, and this month we've added a new ancillary category (Related fundings) to give an indication of the level of funding in AI and deep learning startups.
Acquisitions
Update: When General Motors announced in March that it was buying Cruise Automation, Forbes reported that the undisclosed purchase price was just over $1 billion. GM chief financial officer Chuck Stevens said in a recent earnings call that it only paid out approximately $600 million (split between cash and stock). Payouts above the $600 million ― including earn-outs related to commercial or technological milestones which are estimated by Forbes to be around $400 million ― are being considered by the company to be employment costs instead of acquisition costs.
5D Robotics acquired Time Domain, a provider in Ultra-Wideband (UWB) product development and services, for an undisclosed amount. 5D has partnered with Time Domain since 2012, adapting the latter's PulsON® ranging radios into precision autonomous navigation and positioning solutions for a wide variety of air and ground vehicles. The transaction strengthens the combined entity's position in vehicle autonomy through a combination of products, intellectual property (over 100 patents), and a staff of over 50 people.
In a move similar to the 2015 deal where Uber hired almost the complete staff of CMU's NREC, Toyota hired the entire 16-member software engineering staff of Jaybridge Robotics, the company providing software automation of industrial vehicles across a range of industrial applications including agriculture, mining, marine, and rail. Jaybridge-engineered autonomous systems have logged thousands of hours in the hands of end-users. Jaybridge Robotics, Inc. remains an independent company and will continue to provide support for existing clients.
Permira, a European private equity firm and the owner of Intelligrated, a Mason, Ohio-based provider of fulfillment solutions, sold its shares to Honeywell for $1.5 billion in cash. Toyota Industries was also bidding on the deal. Permira acquired the company in 2012 for approximately $500 million.
Voith agreed to sell its 25.1% stake in German robot maker Kuka to China's Midea thereby cinching the takeover even before the close of the initial tender offer. KUKA and Midea negotiated an agreement whereby KUKA got assurances that jobs and plants in Germany will be protected until the end of 2023 and Midea agreed not to pursue a domination agreement or de-listing of KUKA’s shares. As a result, KUKA's management endorsed the arrangement and their two biggest shareholders (Voith being one) tendered their shares to Midea. The public tender, plus the two big shareholders, gave Midea 72.18% of the shares. Combined with what they already owned, Midea has 85.69% ownership. From July 21, through August 3, Midea announced another tender offer – with the same valuation and share price – to acquire as many more of the shares as possible. Read more.
Google bought French Moodstocks, a visual recognition machine learning technology company for an undisclosed amount. Moodstocks' engineers and researchers have been developing new algorithms for visual recognition of objects, particularly those viewed by cameras in mobile devices.
Fundings
Wonder Workshop, a Sunnyvale, CA-based maker of robots that teach kids computer science and coding fundamentals, raised $20 million in Series B funding. WI Harper Group and Idea Bulb Ventures co-led the round, and were joined by Learn Capital, Charles River Ventures, Madrona Venture Group and TCL.
UBTech (Union Brother Technology), a Shenzhen startup developing small consumer humanoid robots, got $100 million in a Series B funding round led by CDH Investments with CITIC Securities. UBTech's new $1,300 Alpha2 robot is getting lots of media attention and is going on sale in time for Christmas.
Cambridge Medical Robotics, a UK developer of a robotic system for keyhole surgery, has raised $20 million in Series A funding. Backers include LGT Global Invest, ABB Technology Ventures and Cambridge Innovation Capital.
Civil Maps, an Albany, CA developer of high definition 3D maps and centimeter-level localization, got $6.6 million in a seed round from Ford, Motus Ventures and three others.
Autonomous Marine Systems got $1.6 million in a seed round (in February) that enabled a $1.9 match-grant funding with all the funds going towards fulfilling DoD contracts to provide long duration ocean observation.
Flyability, got $4.3 million from a Series A funding from MKS Alternative Investments, Go Beyond Investing, and Environmental Technologies Fund. Flyability, a Swiss startup, develops Gimball, a collision-proof drone. Flyability hopes to enable new applications in inspection, rescue and security.
According to TechSci Research, the artificial intelligence (AI) industry is projected to grow at a CAGR of around 75% during 2016-2021. Continuous research and development in healthcare, autonomous vehicles, security and access control, robotics-as-a-service, agriculture, cyber security, and other verticals are expected to fuel the growth as are smart wearables, and the head-up display screen market. Frost & Sullivan’s report about deep learning enabling the unraveling of layers of patterns in data is also propelling the AI boom. This is where it becomes really interesting both users and makers of robotics. Frank Chen, a partner at Andreessen Horowitz, the Silicon Valley venture capital and private equity firm, said of deep learning:
It is absolutely non-controversial that deep learning is the most fundamental advance in A.I. research since the start [of A.I.] in 1956. We [Andreessen Horowitz] think A.I. and deep learning can be a fundamental and technology platform shift as mobile and cloud have been in the last 5-10 years… All the serious applications from here on out need to have deep learning and AI inside in exactly the same way that all serious computing systems needed to have Intel chips inside of them. I think now about the startups that we see, that deep learning needs to be inside these new systems as a fundamental technique that we expect to see in all serious applications moving forward.
Read and view more about deep learning. With Frank Chen's words in mind, the following companies which got funded recently are blurring the line between robots, robotics and bots powered by AI, cloud computing, and deep learning analytics:
Prospera is an Israeli startup collecting and providing tools to help growers understand newly available data using computer vision, data science, and machine learning to monitor and analyze crops. Prospera raised $6.75 million in Series A funding in a round led by Israeli VC Bessemer Venture Partners.
Kimera Systems, a Oregon-based developer of an embedded learning AI, got an undisclosed amount of seed funding. Kimera’s Nigel fuses together a broad range of soft and hard sensor data, achieving moment-to-moment contextual awareness, allowing it to learn and apply what it understands to real-world situations, much like a human does.
FiveAI, a UK start-up using artificial intelligence and machine learning to accelerate the arrival of fully autonomous vehicles, got $2.7 million of equity funding in a round led by Amadeus Capital Partners.
Vision Labs, a Russian vision systems startup, raised $5.5 million in a Series A round from Sistema Venture Capital. VisionLabs will use the funds to improve its face recognition technology, ramp up sales and expand into new markets including the US, Europe and Asia. The company’s core product is a recognition platform – VisionLabs LUNA – which allows near real-time recognition of millions of faces from video and photo streams in order to identify people.
FogHorn Systems, a developer of IoT software for industrial and commercial vertical markets, got $14.5 million in Seed and Series A fundings from March Capital, GE Ventures, The Hive and the VC arms of Bosch, Darling and Yokogawa Electric. FogHorn is developing edge intelligence AKA “fog computing”. The company's fog computing platform is a critical enabler for a new class of powerful real-time analytics, machine learning models and edge computing applications in a wide variety of industrial and enterprise use cases.
Failures
NavCPU, a Russian mobile robotics startup",https://www.therobotreport.com/july-fundings-acquisitions-and-failures/,[[0.05218501]]
Bosch Rexroth updates MTX CNC system for additive manufacturing,"March 19, 2019 – Bosch Rexroth has released a new version of its MTX CNC system for the additive manufacturing process.
From reading in the CAD data and simulations to the actual printing process, the system offers minimal cycle times as well as enough computing power for dynamic, coordinated movements – including complete process monitoring. With the Open Core Interface software solution, users can implement other IT applications. The integrated OPC UA server allows for communication with higher-level systems.
The Version 14.0 MTX CNC system features a control system that is scalable in terms of power and function. With a Dual Core processor and decentralized intelligence, the high-performance version platforms its tasks with an internal cycle time of 0.25 ms.
The shorter these cycle times are, the faster the control system calculates the 3D data, thus speeding up the actual printing process. At the same time, it has sufficient reserves to record process data in real time and to use these data for process optimization.
NC functions already integrated into the control software deposit the additive material layer precisely and optimize the process, e.g. with intelligent temperature control. The standardized G code for movement control is supported by any slicer software. Integrated NC encoding systems protect manufacturer-specific know-how.
The MTX CNC system also features a 3D online simulation with collision recognition. It automatically visualizes the construction time, positioning and printing head travel, allowing users to intervene proactively before the production process. The CNC system fits seamlessly into simulation environments as “hardware in the loop” and generates realistic images of the subsequent processes.",https://www.automationmag.com/9190-bosch-rexroth-updates-mtx-cnc-system-for-additive-manufacturing/,[[0.05216498]]
The Five Most Important Manufacturing Trends,"Countless predictions have been made about what 2019 will bring. But are manufacturers’ looking a decade down the road? These trends need to be on leaders’ radar not just over the next 12 months, but in the coming years.
1. Global Virtual Workforce: Merging Extended Reality with the Internet
U.S. manufacturers have struggled to find STEM-educated employees to staff their increasingly technologically advanced workplaces. But on the horizon lies a solution that will benefit businesses worldwide: the merging of extended reality—from virtual reality and augmented reality to mixed reality and augmented virtuality—with global interconnectivity.
Manufacturers are already benefiting from the use of computer-generated environments that merge the real world with visual and audio aids. Within a decade a company will be able to tap skilled workers across the globe to design products, work with engineers, and operate and maintain U.S.-based machines and equipment virtually through XR. In other words, a worldwide workforce will staff globally connected virtual-actual shop floors.
2. Linking the Human Brain to Machines
The concept of connecting human brains to machines has gained publicity due to the interest of Elon Musk, who famously prophesied that the advancement in AI means humans must eventually merge with computers or become irrelevant. Not one to just make predictions, he founded a company (Neuralink) to develop implantable brain-computer interfaces (BCIs), with the short-term goal of treating serious brain disease and brain damage caused by a stroke.
The implications loom large for manufacturers. The biggest challenge of AI, as MIT economist David Autor has observed, is that humans know more than we can describe. If you can't explain the use of judgment, common sense, or imagination, you can't program a computer to mimic your ability. A mind-machine interface (MMI) will allow humans and machines to complement each other in what they do best, in real time. Cyborgs may be part of our distant future, but in the next decade machines and humans will literally join each other to help manufacturers make better designed, better-produced goods.
3. Nano-Based Preventive Maintenance
In the 1966 film “Fantastic Voyage,” the government shrinks a submarine crew to microscopic size, then shoots them into the body of an injured scientist to repair his damaged brain. Now sci-fi has become a reality, as quantum physics combines with the digital world in medicine. For example, engineers at UC-San Diego have developed a nanobot, less than 5 millionths of a meter long, that can “swim” in the bloodstream and eventually will be used to remove particles and repair tissue.
Can the ability to place microscopic AI-enabled robots into factory systems and equipment be far behind? Already, engine maker Rolls-Royce is using miniature robots 10mm in diameter for predictive maintenance within the combustion chamber of its engines. While not by definition nanotechnology – nanoparticles are measured in nanometers, which are 1 millionth the length of a meter – it demonstrates how we’re closing in on the use of nanobots not only for predictive maintenance but for preventive maintenance, to detect flaws and actually repair equipment before it breaks down.
4. Internet of Goods: Local Production and Local Distribution
In a study published by MAPI in 2018, author Dr. Michael Mandel provides a new vision for how the Internet of Things will affect manufacturing. Mandel sees the rise of ecommerce fulfillment centers and the digitization of distribution, pioneered by Amazon, opening up new ways for manufacturers to shift from a warehouse model to a more flexible distribution process. Along with more customization made possible with robots and 3D printing, and the use of cloud computing enabling even small factories to tap into new technologies, this “Internet of Goods” will allow the creation of new business models capable of expanding the market and changing the geography of production.
5. The Exponential Generation of Leadership
All eyes are justifiably on the millennial generation (born 1980-1999), as the oldest of them prepare to take over leadership roles in the business world. But it’s the following generation – whom I labeled the ""exponentials"" a few years ago – that manufacturers need to put on their radar. This cohort, with birthdates starting around the turn of the millennia, is just starting to populate college campuses and technical schools around the country. They have never known a world without smartphones, the internet, virtual reality, and artificial intelligence. Their knowledge of and capabilities with technology will easily surpass that of the millennials—and their skillsets and 21st-century leadership style will be needed to help U.S. manufacturers compete globally in the coming decades.
Stephen Gold is president and CEO of MAPI, the Manufacturer's Alliance for Productivity and Innovation.",https://www.industryweek.com/leadership/article/22027007/the-five-most-important-manufacturing-trends,[[0.05214065]]
Open vs. Closed Robot Systems,"To be able to choose between proprietary software packages is to be able to choose your master. Freedom means not having a master. Freedom means not using proprietary software. – Richard Stallman, open systems advocate
Certainly robotics has its share of proprietary software and control systems. Each robot manufacturer markets their products based on the need for secure, proprietary and un-shared systems so that they can insure stability and control. Whole industries have been set up to bridge those proprietary barriers so that multi-vendor solutions can happen.
Two prominent people in the robotics industry had a discussion on the subject last year. In a spirited cocktail party debate in Lyon, France at InnoRobo 2012, an innovation forum and trade show for service robotics, Colin Angle and Robert Bauer argued their points of view.
Angle suggested that freely providing such a key and critical component as the robotic operating and simulation system – and the extensive libraries that go with it – as the Open Source Robotics Foundation (previously Willow Garage) does with their open source and unprotected robotic operating system (ROS) – was tantamount to letting the biggest consumer giant(s) gobble up any mass market applications and re-market them globally at low cost because they already have (or could easily reverse-engineer) the hardware and could produce it cheaply, the operating system was free courtesy of ROS, and the only real cost was the acquisition of the application(s).
Angle thought that it was dangerous and led to losing a potentially American/European market to offshore commodity conglomerates and said:
Robotics innovation represents a tremendous opportunity for economic growth akin to automobiles, aerospace and information technology. If we are to freely share our ‘intellectual capital’ on the open market we risk losing the economic engine that will advance our economies and send growth and jobs overseas.
The issue of losing trade secrets to foreign conglomerates has been a continuing focus at Bloomberg Businessweek magazine.
In November, 14 U.S. intelligence agencies issued a report describing a far-reaching industrial espionage campaign by Chinese spy agencies. This campaign has been in the works for years and targets a swath of industries: biotechnology, telecommunications, and nanotechnology, as well as clean energy.
“It’s the greatest transfer of wealth in history,” said General Keith Alexander, director of the National Security Agency.
Bauer said that Willow Garage’s objectives with ROS was to stimulate the industry by enabling participants to not have to reinvent the many cross-science elements of robotics ventures; to reuse software because it saves developer time and allows researchers to focus on research. By giving them free access to the tools, libraries and simulation capabilities of ROS, and access to the PR2s that are available for testing and experimentation, Willow Garage hoped to advance the state-of-the-art in autonomous robotics technologies.
Bauer also said that, once a successful app was developed, at that point the new endeavor would likely lock down the operating system and application software in order to protect their invention.
Angle suggested that what the robotic industry needs for inspiration is successful robotics companies – profitable companies with millionaire employees selling in-demand products; not more notches on the oversized belts of big offshore conglomerates. Further, he said that unless ROS is protected and made stable and secure, it could never be used for sensitive (defense, space, security) solutions, and until it became rugged, secure and stable, it could never be used in factories which cannot afford down time from either their robots or software.
Since that time, solutions that bridge the open vs. shut debate are showing up in many sectors:
Willow Garage has transitioned ROS to two different non-profit foundations to continue development of ROS and ROS-Industrial: The Open Source Robotics Foundation and the ROSIndustrial.org.
ROS-Industrial is a new effort to enable closed industrial systems to at least have a “front end” to make available the introduction of new sensors, make robot programing and simulation easier, and take advantage of the wealth of new talent exposed to ROS in academia.
Start-up companies selling co-robots are using ROS and beginning to share application software. Danish Universal Robots and Rod Brooks’ Rethink Robotics both use ROS for software development but not for control systems. Rethink Robotics plans to offer an SDK capability with an app store for robotics applications shared by other Baxter users sometime in 2014. The SDK is already available in the academic version of Baxter.
Industrial robot makers are beginning to provide ROS-like capabilities in the form of updated software and simulation suites, e.g., ABB Robotics recently introduced RobotStudio which is a GIS interface to ABB’s proprietary internals for robot simulation and programming.
Thus as the debate rages on, so too do the very pragmatic solutions that are necessary to make things move forward and work.
The best solutions often involve multiple vendors. Look at the Tesla factory. Integrating their software and control systems into the larger manufacturing system or just between different systems on a line involves serious talented programming — a process which everyone agrees needs to be simplified and made less costly.
ROS-like products are fine for development and simulation and because they are prevalent in most of academia, new hires are familiar with what it does and how it works. But that’s when those new hires are confronted with the complexities of proprietary software and teaching pendants. I’ve heard it said that it’s like going back to the mainframe era of computing. At the least, it involves learning old-style coding languages.
Most of the big robot manufacturers are beginning to make an effort to improve their training and programming methods, get them onto more practical tablets, and provide offline simulation. But the going is slow, hence the argument for open source rages on. The truth appears to be in the middle: older systems need to be updated yet still retain their proprietary nature. Mix and match between vendors is a fact of life and needs to be accommodated either by the use of ROS-Industrial or by the robot manufacturers themselves in the form of a new set of standards and interfaces.",https://www.therobotreport.com/open-vs-closed-robot-systems/,[[0.05145312]]
“On Par with the cPDm Leaders” – Why Aras is Recognized as a New Member of the PLM Elite,"In the PLM business, being named to the ""PLM Mind Share Leaders"" list by analyst firm CIMdata, is a big step.
This exclusive group contains the major players in this fairly static world. So far, only Dassault Systèmes, Siemens PLM, Autodesk, SAP, PTC, IBM and Oracle have passed through the eye of the needle.
But there is still room for the occasional surprise. In late June, when CIMdata released their 2017 series of annual reports on the state on the PLM market, it turned out that the small PLM developer Aras has managed to battle its way into this elite group. Their inclusion is not because their Innovator solution is generating huge revenues, but because of the company’s achievements in regard to CIMdata’s criteria: size and scope of PLM implementations, technology and thought leadership in the PLM market and impact on the PLM market.
No doubt, recent wins including General Motors (50,000 seats) and global automotive supplier Schaeffler Group (20,000 seats) were important reasons for Aras’ promotion — in the latter case, Aras notably won over PTC’s Windchill. However, their open source business model, marketing strategy and architecture technology were also decisive reasons.
“Aras is ideally positioned as a PLM platform with a flexible, scalable and upgradeable architecture, and an open approach that delivers the long-term resilience that companies require. As a result, big corporations like GM and Schaeffler are turning to the Aras PLM platform because it simply works,” commented Aras’ CEO, Peter Schroer.
In terms of revenue, no Aras numbers are publicly disclosed.
We can only speculate where Aras is on the scale. Schroer gave some indication in an interview three years ago, where he said to ENGINEERING.com that company revenues were less than $50 million.
Still, Aras is a fast-growing company, said Peter Schroer:
“Yes, it’s true we don’t disclose company revenue. But I can say that our bookings growth has increased more than 65 percent each of the last three years. We are looking to accelerate that growth in 2017 as more companies awaken to the fact that Aras Innovator provides a real alternative to their legacy PDM.”
Schroer continued, “Our largest new subscriptions in 2016 were GM (50,000 users), Schaeffler (20,000 users) and Huntington Ingalls (2,500 users). In all, 2016 was a great year for Aras, where we built on the 2015 momentum of winning Airbus (30,000), Microsoft (5,000 users), Hitachi and others.”
Aras Addresses Big Problems in PLM
These are all impressive company names and subscription numbers, but even more importantly, they are all installations that one would normally connect to high-end PLM/PDM solutions such as Siemens’ Teamcenter, Dassault’s ENOVIA, or PTC’s Windchill suites.
Aras has managed to produce a solution that effectively covers what tend to be weak spots in large corporation’s PLM environments: supplier collaboration and simplicity to upgrade. Add in the fact that there are no license fees (Aras is free to download) and it becomes obvious that the solution has a couple very hard-to-resist advantages.
When I had an interview last year with European air craft manufacturer Airbus’ PLM representative, Anders Romare, these points were the main arguments for investing in 30,000 Aras seats back in 2015. “Generally, our view is that PDM/PLM systems are too expensive,” was one of Romare’s statements.
He also said that Airbus doesn’t use Aras as its core enterprise PDM system. “Due to size and complexity, we have many small and light PDM systems. There can be various types of systems integrating the supply chains, and a test environment where we need light PDM functionality. We have tested and proven the Aras solutions with good results, flexibility and quick turnaround time to develop and deploy applications.”
In general, Peter Schroer agrees that these arguments are significant, but he downplays the importance of supplier collaboration as the main reason for choosing Aras.
“While generally true, I would not single out supplier collaboration as the main driver in this. Aras Innovator is being chosen as the PLM platform to solve a wide range of complicated engineering business processes: full BOM (Bill of Materials) and configuration management, change workflows, NPDI (New Product Development and Introduction), Phase-Gate Program management, quality planning, quality control, manufacturing process definition/planning, technical publications and, of course, supply chain collaboration. When we look at the primary reason companies have picked Aras in the last three to four years, it’s been enterprise change management much more than supplier collaboration.”
Mission Critical for Digital Twin Configuration
He also points out system-level BOM management and Change Management as mission critical capabilities – especially for digital twin product configuration and digital thread traceability – that are not well supported by the legacy PDM vendors.
“We view the other vendor offerings as PDM rather than true PLM because they are CAD-oriented systems and do not enable true through-life product management,” Shroer stated. He added that each company brings in Aras to solve their most complex problems:
“We have earned our reputation solving PLM projects quickly and permanently. The challenges we solve for companies range from multi-CAD data management in an agnostic manner (integrating to Dassault, PTC, Siemens, Cadence, Mentor, Zuken and ALM -Application Lifecycle Management - tools), to ECO Change, to BOM and configuration management and others.
Futhermore, the Aras chief explained that there are some specific challenges that they often hear from their customers:
“First and foremost, our customers express general frustration with their existing legacy PDM systems – whether it’s lack of flexibility, lack of upgradeability, product roadmaps that are dead ends, or the fact that the other major providers have not met the vision of enterprise PLM and only reliably manage MCAD data; which, by the way, has been validated by CIMdata studies.”
The Pain of Legacy PDM Systems
These problems with legacy PDM systems, said Schroer, have created a significant amount of “pain” for global product teams and IT groups, hindering their ability to truly transform product development to meet the complex challenges of tomorrow’s next generation products.
“Oftentimes, companies have undertaken multi-year, multi-million Euro/Dollar projects to expand, upgrade or replace their PDM system, but it doesn’t work,” asserted Shroer, referring to my earlier article on the problems at British automotive company Jaguar Land Rover, which he said describes examples of this type of slow and complex process.
“Historically, companies have endured this frustration due to the lack of choices, but with today’s business challenges – connected products, IoT-enablement, digital thread, digital twin, or converged software/hardware processes – they are realizing that they can no longer rely on their existing MCAD-focused PDM infrastructure.”
Schroer’s conclusion is, “that companies are now demanding a PLM platform that has true cross-discipline, through lifecycle capabilities that can enable a complete digital thread and comprehensive digital twin and, importantly, that can overlay existing systems like legacy MCAD PDMs, ECAD PDMs and application lifecycle management (ALMs) – as opposed to the rip and replace approach required by the legacy monolithic PDM systems.”
VISION & ROAD MAP. Aras chief architect, Rob McAveney, discussed Aras’ Vision & Road map during the company’s ACE event. According to Aras, they are one of the very few actors in the PLM market that publicly reveals this road map, including areas such as digital twin and digital thread, full lifecycle tractability, Configuration Management with connected devices, upcoming integration tools for MBSE (Model Based Systems Engineering) and more.
Aras’ Breakthrough Journey Started in 2007
Generally, Aras Innovator can be characterized as a competent and competitive cPDm (collaborative Product Definition management) software. But the company worked hard to add functionalities over the course of a number of years to make Innovator able to support PLM issues across multiple segments.
Founded in 2000, the breakthrough for Aras came in 2007, when they established an open source model. A consequence of this was that the core of Aras Innovator became available for free download. The “bread and butter” of the business became the sale of optional enterprise subscriptions paired with support and customization services.
According to Aras’ VP of strategy, Marc Lind, consulting for customization, education and other services make up less than a third of the company’s revenues. Futhermore, he said that they, “do not consider the services revenues key to growth,” making the point that licenses for separate add-ons–such as MCAD integrations–and maintenance charges represents the major income sources.
As an open source company, product development is mainly done within the framework of the customer community in combination with internally executed realization of customer suggestions.
Altogether, this resulted in what CIMdata describes as “a competitive offering on par with the leaders in the cPDm segment.”
“While their solution is in the cPDm segment, Aras has worked hard to support PLM issues across multiple segments. Electronics companies can license IHS parts catalogs for use directly in Aras Innovator. Their work with IBM on supporting requirements traceability using OSLC protocols was innovative and led to their deepening relationship with IBM around the reselling of Innovator. Aras is also white-labeled to Infor, who is offering it as Infor Accelerate to fill a gap in their PLM portfolio,” CIMdata concluded in their 2017 annual reports.
The architecture of Aras has proven valuable. Unlike traditional object-based systems with static data models, the Aras architecture is built around a modeling engine coupled to a web services catalog of PLM services. The modeling engine allows dynamic creation and maintenance of business objects which are linked as required to the appropriate web services.
""This creates a clear separation between business logic and the web services, enabling real-time, drag and drop changes to applications — no coding required, and it means our PLM can be easily upgraded without impacting previous customizations,"" explained Schroer.
From the CASE BOOK of Aras: GM, Schaeffler, Huntington Ingalls and Microsoft
All in all, Aras’ chosen path has worked out well and, as mentioned above, has resulted in a number of large commercial successes during the last couple of years.
Here is a list of companies and their major reasons for the choice to invest in Aras:
General Motors
At General Motors, Aras closed a 50,000-seat deal in 2016 to support enterprise change management, vehicle bill of materials (EBOM & MBOM), variants and options, and other lifecycle processes. Aras was selected because of its technical capabilities, business model, and the architecture’s ability to support complex configuration management, which was an important use case.
“In the case of GM, Aras was chosen as a single solution to manage enterprise change across all brands worldwide – Buick, Cadillac, Chevrolet, GMC and others,” explained Peter Schroer.
When it comes to the GM deal, IBM is partnering up with Aras, leveraging it for IT Integrated Systems Management with requirements management, full visibility and traceability from project deliverables right up to corporate business objectives and reporting.
Schaeffler Group
Earlier this year, global automotive and industrial supplier, Schaeffler Group (85,000 employees), selected the Innovator platform to support its Engineering Cockpit application. This, in turn, provides up to 20,000 users with role-based access to information across multiple disciplines, interfaces, systems and authoring tools. The Schaeffler deal was the first result of the partnership between Aras and IBM that was announced in December 2016.
“With Aras, we are entering a new sphere of data integration. At Schaeffler, we want to digitally optimize processes and procedures as well as create new service-oriented processes. The next logical step is a deeper integration of our current systems and the data exchange related to that company-wide,” says Dirk Spindler, senior VP of R&D at Schaeffler.
“The Engineering Cockpit is a key piece of Schaeffler’s digital transformation strategy,” Schroer commented.
Notably, the Schaeffler win over PTC was a combined Aras/IBM effort based on the partnership announced this past November.
Huntington-Ingalls
Huntington Ingalls Industries, America’s largest military shipbuilding company, bet on up to 3,000 Innovator seats to support the complex engineering processes in the development of technologically advanced warships for the U.S. Navy and the U.S. Coast Guard. They chose Innovator to streamline and standardize processes on a single platform and remove the bottlenecks that occur because of numerous stand-alone systems and databases. Some key areas addressed by Aras are concurrent engineering, configuration management of entire warships and rules-based design and planning.
“We needed to simplify our architecture in order to execute process improvement at its finest,” said Mike Deutsch at Huntington Ingalls, adding that, “What’s happening now is that our team is engaging and embracing the processes that we want to execute. Not only are they doing that, but we’ve also set up this process and its tool set for one program, and the other programs that are doing business differently are all on board now about coming in and having a single common process for the shipyard in the way we do planning, engineering and material processes.”
Microsoft
Back in 2015, Microsoft invested in 5,000 Innovator seats and in this caseAras no longer served only in a complementary role. In fact, the solution was chosen to be the foundation of the entire PLM support. This is an excellent example of a deeper establishment of Aras, even replacing high-end PDM systems such as Dassault Systèmes’ Matrix and SmartTeam.
What Microsoft did was migrate to a new unified platform, OnePDM, built on Aras. Generally, Microsoft aimed at managing product data, including CAD, for the hardware division responsible for Surface computers, Xbox, HoloLens and accessories.
Some reported benefits include: reduced development and deployment times, improved interoperability across engineering, manufacturing and the supply chain, and reduced time-to-release product data from the PDM system to upstream and downstream systems.
“Bottom line,” commented Microsoft senior evangelist Mike Opal, “is that OnePDM saved a million dollars in only its first two years of operation, just by eliminating the operating expenses of multiple old PDM systems.”
A SURPRISING MOVE. When former Siemens PLM CEO, Tony Affuso, decided to join the Aras board of directors earlier this year, his ex-employer wasn’t very happy about it, but with no ties to Siemens, Affuso of course is free to join any company of his choice. “I was attracted to Aras because of their disruptive technology, open-source customer engagement model, and the fact that their technology has recently been selected over that of their competitors by several of the world’s leading engineering and manufacturing companies,” said Affuso (above together with Aras CEO, Peter Schroer, on stage during the recent ACE event).
2016 Software Improvements
Right now, things look bright for Aras. The business is going well, the recognition as one of the cPDm leaders by CIMdata and the way they are continuously improving the Innovator solution has created a strong belief in the future of the company.
In the latter case, 2016 was one of their most active years for new releases.
Architecturally, Aras has a clean separation between the platform and the suite of applications. This means that they are able to continuously release updates and improvements without introducing upgrade issues.
“In 2016, we introduced new innovations in the platform around visual collaboration, search, and scalability while simultaneously releasing major enhancements to our Manufacturing Process Planning (MPP) and Quality Management System (QMS) applications,” said Schroer. “We also provided new capabilities in our Microsoft Office connector and mobile apps.”
Others include IBM’s new version of the ALM/PLM connector between Aras and the IBM Continuous Engineering suite, and numerous other partner product releases.
“But we have also made significant progress with our open reference architecture for MBSE (Model Based Systems Engineering) integration to PLM in our work with both No Magic and IBM,” says Schroer. He continued, “From our perspective, the key here is that in an SaaS world–whether on-premise, in the cloud, or hybrid– there are no more gigantic system releases where everything comes at once. Our mission is to release both new platform capabilities and new applications all the time, versus large events which may be disruptive. This ability is what we call resilient PLM.”
Aras’ Path to the Future
What about the future? What role will Aras play when new technologies such as IoT, additive manufacturing or mobility quickly change the product manufacturing world?
First of all, the solution can live up to one of the basic requirements of today: Aras is a cloud-ready architecture which can be deployed on-premise, in the cloud or in hybrid scenarios – with the same customization capabilities and integrations, same codebase, same subscription – and companies can switch how they run Aras anytime, without data loss or process compromise.
That’s clearly important, but this is far from everything that makes Aras’ CEO optimistic about the company’s ability to meet the future.
“The underlying PLM architecture matters,” Schroer said. “What we have done that is unique – our breakthrough – is to create a single platform which is highly flexible, scalable and upgradable, even when heavily customized.”
As a result, the platform can adapt to any workflow or product development process without creating support or upgrade issues. Nothing is hard coded like in legacy systems, but instead is able to be modified as needed.
“The Aras PLM Platform is therefore ideal for handling traditionally complex requirements such as PDM data, as well as new and emerging requirements such as IoT processes, Industry 4.0 / Industrial Internet of Things (IIoT) scenarios and additive manufacturing support,” Schroer concludes.
WHAT IS A DIGITAL TWIN? “It’s one of those topics where if you ask three people, you’ll get five answers,” said Aras’ VP of strategy, Marc Lind. But he has drilled deeper into the matter, concluding that as products move to include connectivity, sensors and intelligence, “we can’t just think about the data streaming back from the field. Without accurate context – the digital twin – time series data generated during production and ongoing operation is difficult or even impossible to understand and analyze.”
Digital Twins in the Eyes of Aras
The Digital Twin is clearly a hot topic, and a PLM market actor that wants to be an alternative of choice must have good solutions.
According to analyst firm Gartner, digital twins are one of 2017’s Top 10 Strategies Technology Trends. And IDC – another highly respected analyst – predicts that by 2018 companies which invest in this type of technology will see a 30 percent improvement in critical processes.
Aras’ VP of strategy, Marc Lind, has interesting views, “It’s one of those topics where if you ask 3 people, you’ll get 5 answers,” Lind said.
But he has drilled deeper into the matter. “The term Digital Twin was coined back in 2002 by Dr. Michael Grieves while at University of Michigan. He obviously thought about The Digital Twin Concept extensively back then, which shows in his definition. Of course, the practical application of Internet of Things (IoT) technologies was still in its infancy, so it’s a bit academic.
More recently, Prof. Dr.-Ing. Martin Eigner at Technische Universität Kaiserslautern in Germany has expanded on the Digital Twin in the context of the IoT, Industry 4.0 and IIoT. Effectively, this comes down to the idea that the Digital Twin is an exact virtual representation of a physical thing. It’s as if the physical product or system was looking in a virtual mirror.”
It contains all the informational sets of the physical ‘thing,’ meaning it is cross-discipline – not just a mechanical or geometric representation, but also including the electronics, wiring, software, firmware and other components.
That said, why is the digital twin so important?
“Well, many people talk about digital twins in the context of monitoring, simulation and predictive maintenance, which are all incredibly valuable and potentially transformative in their own right. However, there would seem to be much more to it,” Lind asserted.
His point is that as products move to include connectivity, sensors and intelligence, “we can’t just think about the data streaming back from the field. Without accurate context – the digital twin – time series data generated during production and ongoing operation is difficult or even impossible to understand and analyze.”
In addition, the ability to interpret and act upon these data often require traceability to prior information from related revisions – the Digital Thread.
“To complicate matters further, as artificial intelligence and cognitive computing is introduced, the necessity for the digital twin becomes even greater. If Knowledge = Information in Context, then without a digital twin, machine learning won’t work as intended, and will be rendered ineffective or worse, potentially leading to risky misinterpretations or misdirected actions. Because without context – the digital twin – the IoT-enabled value proposition is severely limited and could introduce real liability.”
These are a few of the obvious points they’ve been thinking about at Aras.
“Moreover, with our ability to manage product configurations through the lifecycle, we provide the all-important digital twin context for interpreting IoT data. Our Manufacturing Process Planning application can be used to support additive manufacturing as well as traditional production processes.”
My Take: Not Trembling, But a Bit Bothered
So, Aras is on the move and they’ve been rocking the cPDm parts of the PLM arena for at least the last couple of years. Even though the top players of PLM in terms of revenue remain pretty static year after year, Aras represents both a technical and commercial movement beneath the surface; a movement that is getting stronger.
Clearly Aras is not alone in trying to make an impact in this complex arena. Autodesk’s bet on cloud PLM via their Fusion Lifecycle is one good example. Other competitors include Arena’s cloud-based PLM solution and newcomers to the game, such as Propel PLM, the first cloud-based PLM offering built using the salesforce.com Software Development Kit (SDK).
However, none of these players have landed PLM/collaborative PDM orders as big as Aras’. Maybe developers like Dassault Systèmes, Siemens and PTC aren’t trembling, but I bet they are a bit bothered.",https://www.engineering.com/PLMERP/ArticleID/15513/On-Par-with-the-cPDm-Leaders-Why-Aras-is-Recognized-as-a-New-Member-of-the-PLM-Elite.aspx,[[0.05140716]]
Are robots closing in on your factory?,"Roboticstechnology
The word ‘robot’ often conjures up a negative image in people’s minds. The rampaging android from the Terminator movies, or the menacing battle droids of Star Wars. Popular opinion holds that in a few decades, we’ll be overrun by artificially-intelligent robots, operating our machinery and encroaching on our jobs, all while plotting our downfall.
Apart from being fairly well divorced from reality, that attitude ignores the fact that most advances in robotisation today are software-based, rather than embodied in a humanoid metal figure. For manufacturers looking to assess the impact of robotisation on their facilities in the near future, that’s an important distinction.
Manufacturing is, of course, one of the industries that has led the deployment of physical robots to great effect. Robots have brought many benefits including longer operating hours, greater efficiency and output and reduced room for error. The question now is ‘what’s next?’. How will the increasing sophistication of software-based automation and artificial intelligence engines translate into the factory?
Software & data analysis
The same applies to robots that essentially consist of software. There’s a clear business case for bots that can execute jobs more efficiently than people. For example, software can handle large volumes of information on system status faster and more accurately than people in order to help floor managers predict and prevent system failures. Similarly, manufacturers can discover potential areas for improved efficiency by using software to conduct digital reviews of the production line and identify processes that are underperforming.
Data analysis is a key aspect of all software robotisation - by running analyses of information coming in from IoT sensors and connected robots on the floor and throughout the supply chain, software bots can help companies get a deeper insight into trends in their business, conditions around the plant and efficiency at all levels. As more and more machines begin to generate analysable data, it’s essential to have bots in place that can turn it into useful insight.
Automated assembly
We’re also starting to see test runs of the first fully automated assembly lines, where everything from order entry to manufacturing to stock processing is conducted by automated software. Such automation makes it possible for orders placed via a webstore in the middle of the night to be automatically processed so that the product rolls off the line an hour later, ready to be despatched first thing in the morning. Intelligent business software can help manage this process from start to finish.
Visual scheduling is a key part of this, enabling drastic reductions in the time spent on shop floor planning. This functionality can come from third party software, or from an integrated part of a full suite ERP system. By integrating graphical planning boards and automatic planning, capacity bottlenecks can be immediately resolved. Full integration of automated planning with the production line ensures the entire ERP system is automatically aligned to any order changes made.
Quality control
Robotisation can also help manufacturers improve their quality control. Effective QC now involves the registry of large volumes of data. Automating these processes prevents a lot of time-consuming hassle and helps significantly reduce errors. Rather than completing paper documentation, employees can enter test results on the spot via a mobile device. This can then be centrally processed, providing a real-time view of the situation.
Real time processing of test results leads to real time reporting on quality issues, which can then be identified and acted upon much faster. Data integrity is ensured, with employees restricted to enter a certain range of data. And storing quality data in your central system offers other functional benefits as well, such as the ability to track back to the test data of a certain product batch. With these processes supported by automation, manufacturers can benefit from increased responsiveness, more effective reporting and improved customer service.
Back-office functionality
The use of robots isn’t just limited to the factory floor, either. In finance, robotisation can be used for automatic approval and processing of invoices, for example. However, this is just the beginning. If we can teach a bot to process invoices, it’s not such a big step to help it understand the rules that govern financial processes, using machine learning software. This ensures that software bots can work with a degree of autonomy. People will only be called upon when exceptions arise that the robot cannot assess.
Should you invest?
There is a great deal of speculation today regarding what jobs will or will not be taken over by bots. With a little imagination, you can see how ultimately the majority of human work could be performed by robots. Therefore, it is interesting to look at the short and medium-term impact for manufacturing firms.
In the coming years, it is expected that tasks in which people are the main bottleneck will be taken over by robots, on a large scale. Prime candidates are anything that takes a relatively long time to complete, for which we lack the mental capacity, or which is too dangerous (or boring).
For example, manufacturers could benefit from increased robot supervision of areas such as the supply chain. Robotic systems could automatically resolve issues as they arise and reorder regular shipments on a rolling schedule, with the intelligence to stop the order if the production line undergoes a scheduled – or unscheduled – stop.
The same is true of accounting, which is typically governed by extensive structures and rules, allowing tasks to be standardised and harmonised. A few years ago, it made sense to allow people to process and record invoices, but today’s software is smart enough to allow this to be easily automated.
Key points to consider
As a manufacturer, before you decide to invest in advanced robot technology, it’s advisable to consider the following four questions.
1. What is your need?
Robotisation for the sake of technology alone is never a good idea. There must be a clear advantage to using robots: for example, because the work that needs to be done is too demanding for people, or too boring and repetitive, or because machines can perform certain tasks more efficiently or qualitatively.
2. Where do you start?
Review your processes and find out where large amounts of repetitive standard operations are hidden.
3. What are the costs?
This is where the business case comes in: how do you justify the investment? When does a robot pay back the amount it cost? How do you incorporate hidden expenses, such as unemployment and retraining, into the business case?
4. Who will take responsibility?
Properly implementing and maintaining bots is a task that should not be underestimated. Make clear arrangements regarding the responsibilities this brings – is the department using the robots responsible or will it fall to the IT department?
Consider the fact that robotisation is not just a matter of technological development. Successful implementation also has important social and corporate culture aspects. In addition, you’ll also need to reconsider employees’ tasks once part of their work has been handed over to robots.
Where does that leave us?
For now, as a manufacturer, you need to focus on tasks in which people are the biggest bottleneck. Once you’ve done that, the next step is easily made: the development of a business case.
The more effective and efficient robots become, the sooner that business case can be made. Even if you don’t develop this for your business, one of your competitors definitely will, and that means they’ll eventually take the lead. It is not a question of 'whether' you’ll need to look into robotisation, but 'when'.
By Gavin Fell, General Manager UK, Exact",https://www.manufacturingglobal.com/technology/are-robots-closing-your-factory,[[0.05082522]]
